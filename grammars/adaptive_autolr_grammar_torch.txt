<start> ::= alpha_func, beta_func, sigma_func, grad_func = lambda size, alpha, grad: <alpha_expr>, lambda size, alpha, beta, grad: <beta_expr>, lambda size, alpha, beta, sigma, grad: <sigma_expr>, lambda size, alpha, beta, sigma, grad: <grad_expr>
<alpha_expr> ::= <alpha_func> | <alpha_terminal>
<alpha_func> ::= torch.negative(<alpha_expr>) | torch.subtract(<alpha_expr>, <alpha_expr>) | torch.add(<alpha_expr>, <alpha_expr>) | torch.multiply(<alpha_expr>, <alpha_expr>)  | torch.pow(<alpha_expr>, <alpha_expr>) | torch.square(<alpha_expr>) | torch.divide(<alpha_expr>, <alpha_expr>) | torch.add(<alpha_expr>, <alpha_expr>) | torch.sqrt(<alpha_expr>) | torch.full(size=size, fill_value = <alpha_const>, dtype=torch.float32) 
<alpha_terminal> ::= torch.full(size=size, fill_value = <alpha_const>, dtype=torch.float32) | alpha | grad | grad
<alpha_const> ::= 0.0 | 5.55606489e-05 | 6.79983174e-05 | 8.32200197e-05 | 1.01848815e-04 | 1.24647146e-04 | 1.52547986e-04 | 1.86692945e-04 | 2.28478855e-04 | 2.79614739e-04 | 3.42191434e-04 | 4.18766684e-04 | 5.12469082e-04 | 6.27124987e-04 | 7.67413430e-04 | 9.39055039e-04 | 1.14904229e-03 | 1.40591988e-03 | 1.72012560e-03 | 2.10440443e-03 | 2.57431039e-03 | 3.14881358e-03 | 3.85103236e-03 | 4.70911357e-03 | 5.75728612e-03 | 7.03711536e-03 | 8.59898661e-03 | 1.05038445e-02 | 1.28252101e-02 | 1.56514861e-02 | 1.90885420e-02 | 2.32625358e-02 | 2.83228820e-02 | 3.44451957e-02 | 4.18339400e-02 | 5.07243606e-02 | 6.13831074e-02 | 7.41067363e-02 | 8.92170603e-02 | 1.07052146e-01 | 1.27951705e-01 | 1.52235823e-01 | 1.80176593e-01 | 2.11963334e-01 | 2.47663801e-01 | 2.87185901e-01 | 3.30246430e-01 | 3.76354517e-01 | 4.24816868e-01 | 4.74768924e-01 | 5.25231076e-01 | 5.75183132e-01 | 6.23645483e-01 | 6.69753570e-01 | 7.12814099e-01 | 7.52336199e-01 | 7.88036666e-01 | 8.19823407e-01 | 8.47764177e-01 | 8.72048295e-01 | 8.92947854e-01 | 9.10782940e-01 | 9.25893264e-01 | 9.38616893e-01 | 9.49275639e-01 | 9.58166060e-01 | 9.65554804e-01 | 9.71677118e-01 | 9.76737464e-01 | 9.80911458e-01 | 9.84348514e-01 | 9.87174790e-01 | 9.89496155e-01 | 9.91401013e-01 | 9.92962885e-01 | 9.94242714e-01 | 9.95290886e-01 | 9.96148968e-01 | 9.96851186e-01 | 9.97425690e-01 | 9.97895596e-01 | 9.98279874e-01 | 9.98594080e-01 | 9.98850958e-01 | 9.99060945e-01 | 9.99232587e-01 | 9.99372875e-01 | 9.99487531e-01 | 9.99581233e-01 | 9.99657809e-01 | 9.99720385e-01 | 9.99771521e-01 | 9.99813307e-01 | 9.99847452e-01 | 9.99875353e-01 | 9.99898151e-01 | 9.99916780e-01 | 9.99932002e-01 | 9.99944439e-01 | 1.0
<beta_expr> ::= <beta_func> | <beta_terminal>
<beta_func> ::= torch.negative(<beta_expr>) | torch.subtract(<beta_expr>, <beta_expr>) | torch.add(<beta_expr>, <beta_expr>) | torch.multiply(<beta_expr>, <beta_expr>)  | torch.pow(<beta_expr>, <beta_expr>) | torch.square(<beta_expr>) | torch.divide(<beta_expr>, <beta_expr>) | torch.add(<beta_expr>, <beta_expr>) | torch.sqrt(<beta_expr>) | torch.full(size=size, fill_value = <beta_const>, dtype=torch.float32) 
<beta_terminal> ::= torch.full(size=size, fill_value = <beta_const>, dtype=torch.float32) | alpha | beta | grad | grad | grad
<beta_const> ::= 0.0 | 5.55606489e-05 | 6.79983174e-05 | 8.32200197e-05 | 1.01848815e-04 | 1.24647146e-04 | 1.52547986e-04 | 1.86692945e-04 | 2.28478855e-04 | 2.79614739e-04 | 3.42191434e-04 | 4.18766684e-04 | 5.12469082e-04 | 6.27124987e-04 | 7.67413430e-04 | 9.39055039e-04 | 1.14904229e-03 | 1.40591988e-03 | 1.72012560e-03 | 2.10440443e-03 | 2.57431039e-03 | 3.14881358e-03 | 3.85103236e-03 | 4.70911357e-03 | 5.75728612e-03 | 7.03711536e-03 | 8.59898661e-03 | 1.05038445e-02 | 1.28252101e-02 | 1.56514861e-02 | 1.90885420e-02 | 2.32625358e-02 | 2.83228820e-02 | 3.44451957e-02 | 4.18339400e-02 | 5.07243606e-02 | 6.13831074e-02 | 7.41067363e-02 | 8.92170603e-02 | 1.07052146e-01 | 1.27951705e-01 | 1.52235823e-01 | 1.80176593e-01 | 2.11963334e-01 | 2.47663801e-01 | 2.87185901e-01 | 3.30246430e-01 | 3.76354517e-01 | 4.24816868e-01 | 4.74768924e-01 | 5.25231076e-01 | 5.75183132e-01 | 6.23645483e-01 | 6.69753570e-01 | 7.12814099e-01 | 7.52336199e-01 | 7.88036666e-01 | 8.19823407e-01 | 8.47764177e-01 | 8.72048295e-01 | 8.92947854e-01 | 9.10782940e-01 | 9.25893264e-01 | 9.38616893e-01 | 9.49275639e-01 | 9.58166060e-01 | 9.65554804e-01 | 9.71677118e-01 | 9.76737464e-01 | 9.80911458e-01 | 9.84348514e-01 | 9.87174790e-01 | 9.89496155e-01 | 9.91401013e-01 | 9.92962885e-01 | 9.94242714e-01 | 9.95290886e-01 | 9.96148968e-01 | 9.96851186e-01 | 9.97425690e-01 | 9.97895596e-01 | 9.98279874e-01 | 9.98594080e-01 | 9.98850958e-01 | 9.99060945e-01 | 9.99232587e-01 | 9.99372875e-01 | 9.99487531e-01 | 9.99581233e-01 | 9.99657809e-01 | 9.99720385e-01 | 9.99771521e-01 | 9.99813307e-01 | 9.99847452e-01 | 9.99875353e-01 | 9.99898151e-01 | 9.99916780e-01 | 9.99932002e-01 | 9.99944439e-01 | 1.0
<sigma_expr> ::= <sigma_func> | <sigma_terminal>
<sigma_func> ::= torch.negative(<sigma_expr>) | torch.subtract(<sigma_expr>, <sigma_expr>) | torch.add(<sigma_expr>, <sigma_expr>) | torch.multiply(<sigma_expr>, <sigma_expr>)  | torch.pow(<sigma_expr>, <sigma_expr>) | torch.square(<sigma_expr>) | torch.divide(<sigma_expr>, <sigma_expr>) | torch.add(<sigma_expr>, <sigma_expr>) | torch.sqrt(<sigma_expr>) | torch.full(size=size, fill_value = <sigma_const>, dtype=torch.float32) 
<sigma_terminal> ::= torch.full(size=size, fill_value = <sigma_const>, dtype=torch.float32) | alpha | beta | sigma | grad | grad | grad | grad
<sigma_const> ::= 0.0 | 5.55606489e-05 | 6.79983174e-05 | 8.32200197e-05 | 1.01848815e-04 | 1.24647146e-04 | 1.52547986e-04 | 1.86692945e-04 | 2.28478855e-04 | 2.79614739e-04 | 3.42191434e-04 | 4.18766684e-04 | 5.12469082e-04 | 6.27124987e-04 | 7.67413430e-04 | 9.39055039e-04 | 1.14904229e-03 | 1.40591988e-03 | 1.72012560e-03 | 2.10440443e-03 | 2.57431039e-03 | 3.14881358e-03 | 3.85103236e-03 | 4.70911357e-03 | 5.75728612e-03 | 7.03711536e-03 | 8.59898661e-03 | 1.05038445e-02 | 1.28252101e-02 | 1.56514861e-02 | 1.90885420e-02 | 2.32625358e-02 | 2.83228820e-02 | 3.44451957e-02 | 4.18339400e-02 | 5.07243606e-02 | 6.13831074e-02 | 7.41067363e-02 | 8.92170603e-02 | 1.07052146e-01 | 1.27951705e-01 | 1.52235823e-01 | 1.80176593e-01 | 2.11963334e-01 | 2.47663801e-01 | 2.87185901e-01 | 3.30246430e-01 | 3.76354517e-01 | 4.24816868e-01 | 4.74768924e-01 | 5.25231076e-01 | 5.75183132e-01 | 6.23645483e-01 | 6.69753570e-01 | 7.12814099e-01 | 7.52336199e-01 | 7.88036666e-01 | 8.19823407e-01 | 8.47764177e-01 | 8.72048295e-01 | 8.92947854e-01 | 9.10782940e-01 | 9.25893264e-01 | 9.38616893e-01 | 9.49275639e-01 | 9.58166060e-01 | 9.65554804e-01 | 9.71677118e-01 | 9.76737464e-01 | 9.80911458e-01 | 9.84348514e-01 | 9.87174790e-01 | 9.89496155e-01 | 9.91401013e-01 | 9.92962885e-01 | 9.94242714e-01 | 9.95290886e-01 | 9.96148968e-01 | 9.96851186e-01 | 9.97425690e-01 | 9.97895596e-01 | 9.98279874e-01 | 9.98594080e-01 | 9.98850958e-01 | 9.99060945e-01 | 9.99232587e-01 | 9.99372875e-01 | 9.99487531e-01 | 9.99581233e-01 | 9.99657809e-01 | 9.99720385e-01 | 9.99771521e-01 | 9.99813307e-01 | 9.99847452e-01 | 9.99875353e-01 | 9.99898151e-01 | 9.99916780e-01 | 9.99932002e-01 | 9.99944439e-01 | 1.0
<grad_expr> ::= <grad_func> | <grad_terminal>
<grad_func> ::= torch.negative(<grad_expr>) | torch.subtract(<grad_expr>, <grad_expr>) | torch.add(<grad_expr>, <grad_expr>) | torch.multiply(<grad_expr>, <grad_expr>)  | torch.pow(<grad_expr>, <grad_expr>) | torch.square(<grad_expr>) | torch.divide(<grad_expr>, <grad_expr>) | torch.add(<grad_expr>, <grad_expr>) | torch.sqrt(<grad_expr>) | torch.full(size=size, fill_value = <grad_const>, dtype=torch.float32) 
<grad_terminal> ::= torch.full(size=size, fill_value = <grad_const>, dtype=torch.float32) | alpha | beta | sigma | grad | grad | grad | grad
<grad_const> ::=  0.0 | 5.55606489e-05 | 6.79983174e-05 | 8.32200197e-05 | 1.01848815e-04 | 1.24647146e-04 | 1.52547986e-04 | 1.86692945e-04 | 2.28478855e-04 | 2.79614739e-04 | 3.42191434e-04 | 4.18766684e-04 | 5.12469082e-04 | 6.27124987e-04 | 7.67413430e-04 | 9.39055039e-04 | 1.14904229e-03 | 1.40591988e-03 | 1.72012560e-03 | 2.10440443e-03 | 2.57431039e-03 | 3.14881358e-03 | 3.85103236e-03 | 4.70911357e-03 | 5.75728612e-03 | 7.03711536e-03 | 8.59898661e-03 | 1.05038445e-02 | 1.28252101e-02 | 1.56514861e-02 | 1.90885420e-02 | 2.32625358e-02 | 2.83228820e-02 | 3.44451957e-02 | 4.18339400e-02 | 5.07243606e-02 | 6.13831074e-02 | 7.41067363e-02 | 8.92170603e-02 | 1.07052146e-01 | 1.27951705e-01 | 1.52235823e-01 | 1.80176593e-01 | 2.11963334e-01 | 2.47663801e-01 | 2.87185901e-01 | 3.30246430e-01 | 3.76354517e-01 | 4.24816868e-01 | 4.74768924e-01 | 5.25231076e-01 | 5.75183132e-01 | 6.23645483e-01 | 6.69753570e-01 | 7.12814099e-01 | 7.52336199e-01 | 7.88036666e-01 | 8.19823407e-01 | 8.47764177e-01 | 8.72048295e-01 | 8.92947854e-01 | 9.10782940e-01 | 9.25893264e-01 | 9.38616893e-01 | 9.49275639e-01 | 9.58166060e-01 | 9.65554804e-01 | 9.71677118e-01 | 9.76737464e-01 | 9.80911458e-01 | 9.84348514e-01 | 9.87174790e-01 | 9.89496155e-01 | 9.91401013e-01 | 9.92962885e-01 | 9.94242714e-01 | 9.95290886e-01 | 9.96148968e-01 | 9.96851186e-01 | 9.97425690e-01 | 9.97895596e-01 | 9.98279874e-01 | 9.98594080e-01 | 9.98850958e-01 | 9.99060945e-01 | 9.99232587e-01 | 9.99372875e-01 | 9.99487531e-01 | 9.99581233e-01 | 9.99657809e-01 | 9.99720385e-01 | 9.99771521e-01 | 9.99813307e-01 | 9.99847452e-01 | 9.99875353e-01 | 9.99898151e-01 | 9.99916780e-01 | 9.99932002e-01 | 9.99944439e-01 | 1.0

