[{"genotype": [[0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1], [0, 6, 3, 1, 3, 2, 3, 8, 0], [0, 0, 1, 0, 2, 3, 0], [0, 39, 39, 79], [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1], [0, 2, 3, 1, 6, 3, 8, 2, 8], [0, 0, 2, 0, 3, 1, 0], [0, 76, 16, 0], [1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 2, 1, 5, 8, 8], [2, 0, 1], [43], [1], [0], [2], [0]], "fitness": -0.8645714521408081, "mapping_values": [1, 16, 9, 7, 4, 16, 9, 7, 4, 1, 0, 1, 0, 1, 0, 1, 0], "tree_depth": 19, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.divide_no_nan(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.math.multiply(tf.math.add(tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.sqrt(alpha)), tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), grad)), tf.math.negative(grad)), tf.constant(9.97425690e-01, shape=shape, dtype=tf.float32))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(9.95290886e-01, shape=shape, dtype=tf.float32)), beta), tf.math.divide_no_nan(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), grad), tf.math.sqrt(tf.math.add(alpha, tf.math.sqrt(tf.constant(0.0, shape=shape, dtype=tf.float32))))))), lambda shape,  alpha, beta, sigma, grad: beta, lambda shape,  alpha, beta, sigma, grad: beta", "other_info": {"loss": [1.5996499061584473, 0.8963034152984619, 0.7220701575279236, 0.6599181890487671, 0.6117212772369385, 0.5813512802124023, 0.5569454431533813, 0.5365417003631592, 0.5087707042694092, 0.4917945861816406, 0.47812631726264954, 0.4605651795864105, 0.44874972105026245, 0.4400193393230438, 0.43779417872428894, 0.4308006167411804, 0.410349041223526, 0.41637176275253296, 0.4079860746860504, 0.3887026607990265, 0.3867568373680115, 0.38235998153686523, 0.37016916275024414, 0.3759779632091522, 0.36263343691825867, 0.36390671133995056, 0.35775408148765564, 0.3582010567188263, 0.34751665592193604, 0.3454747498035431, 0.33561578392982483, 0.3293773829936981, 0.3330575227737427, 0.33356955647468567, 0.3197841942310333, 0.317922979593277, 0.3141796290874481], "accuracy": [0.4344208240509033, 0.693831741809845, 0.7408532500267029, 0.7621186375617981, 0.7812706232070923, 0.789988100528717, 0.798309326171875, 0.8080834746360779, 0.8190463781356812, 0.8239334225654602, 0.8284242749214172, 0.8381983637809753, 0.8393871188163757, 0.8438779711723328, 0.8424250483512878, 0.8471800088882446, 0.8518029451370239, 0.8551049828529358, 0.8562937378883362, 0.8614450097084045, 0.86118084192276, 0.8648791313171387, 0.8652753829956055, 0.8638224601745605, 0.871879518032074, 0.8706908226013184, 0.8742570281028748, 0.8741249442100525, 0.8770307898521423, 0.8800686597824097, 0.8831065893173218, 0.8820499181747437, 0.8844274282455444, 0.8837670087814331, 0.8854840993881226, 0.8878615498542786, 0.8849557638168335], "val_loss": [0.9074334502220154, 0.6312552690505981, 0.5734075307846069, 0.5567192435264587, 0.5288919806480408, 0.4919843375682831, 0.4923982620239258, 0.45666512846946716, 0.44777172803878784, 0.4637279808521271, 0.4387747347354889, 0.42249178886413574, 0.40985700488090515, 0.4169467091560364, 0.40243181586265564, 0.40890640020370483, 0.4021371603012085, 0.39806509017944336, 0.38484784960746765, 0.3780273497104645, 0.3902437388896942, 0.383583128452301, 0.3724820017814636, 0.37258344888687134, 0.3665012717247009, 0.3681011199951172, 0.3710932731628418, 0.3715391755104065, 0.36342278122901917, 0.36375880241394043, 0.36184266209602356, 0.3562510907649994, 0.3617759048938751, 0.3614536225795746, 0.3587040901184082, 0.35285934805870056, 0.361244261264801], "val_accuracy": [0.6930000185966492, 0.7760000228881836, 0.7873333096504211, 0.793666660785675, 0.8016666769981384, 0.8213333487510681, 0.8230000138282776, 0.8389999866485596, 0.8393333554267883, 0.8336666822433472, 0.8429999947547913, 0.8473333120346069, 0.8560000061988831, 0.8496666550636292, 0.859333336353302, 0.8553333282470703, 0.8576666712760925, 0.8576666712760925, 0.8643333315849304, 0.8669999837875366, 0.862666666507721, 0.8656666874885559, 0.8706666827201843, 0.8703333139419556, 0.8703333139419556, 0.8666666746139526, 0.8693333268165588, 0.8730000257492065, 0.8740000128746033, 0.871666669845581, 0.875333309173584, 0.878000020980835, 0.8740000128746033, 0.8763333559036255, 0.874666690826416, 0.8759999871253967, 0.8700000047683716]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1], [0, 2, 3, 1, 3, 5], [0, 0, 1, 0, 2], [0, 39, 39], [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1], [0, 2, 3, 1, 6, 3, 8, 2], [0, 0, 2, 0, 3, 1, 0], [0, 27, 16, 0], [0, 0, 0, 1, 0, 1, 0, 0, 1], [0, 2, 1, 5, 8, 8], [0, 6, 1], [0], [1], [0], [2], [0]], "fitness": -0.833142876625061, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(1.05038445e-02, shape=shape, dtype=tf.float32)), beta), tf.math.divide_no_nan(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), grad), tf.math.sqrt(tf.math.add(alpha, tf.constant(0.0, shape=shape, dtype=tf.float32)))))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.math.add(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.math.square(grad)), tf.math.sqrt(tf.math.sqrt(alpha)))), lambda shape,  alpha, beta, sigma, grad: beta", "other_info": {"loss": [1.6777064800262451, 0.9027087688446045, 0.7107985615730286, 0.6273976564407349, 0.586471438407898, 0.5444753170013428, 0.5102006793022156, 0.5376177430152893, 0.5118488669395447, 0.524860143661499, 0.4994308650493622, 0.4849531650543213, 0.48620477318763733, 0.48742061853408813, 0.4735722243785858, 0.4961800277233124, 0.48962175846099854, 0.5061031579971313, 0.5186342597007751, 0.5139700770378113, 0.5251986384391785, 0.521271824836731, 0.5524990558624268, 0.6169418692588806, 0.5786958336830139, 0.5981733202934265], "accuracy": [0.4507991075515747, 0.6783780455589294, 0.7442874312400818, 0.759080708026886, 0.7786290049552917, 0.8000264167785645, 0.8082155585289001, 0.8035926818847656, 0.8181217908859253, 0.8161405324935913, 0.819442629814148, 0.8234050869941711, 0.8315942287445068, 0.8232730031013489, 0.8245938420295715, 0.8236692547798157, 0.8381983637809753, 0.8261788487434387, 0.8186501264572144, 0.8372738361358643, 0.8359529972076416, 0.8430854678153992, 0.8212917447090149, 0.8079513907432556, 0.807158887386322, 0.8165367841720581], "val_loss": [0.8471586108207703, 0.6542267799377441, 0.5714804530143738, 0.5140438675880432, 0.49527186155319214, 0.4892807602882385, 0.4933910369873047, 0.5326969623565674, 0.5046977400779724, 0.49644455313682556, 0.5064144134521484, 0.5548091530799866, 0.5081228613853455, 0.4740801453590393, 0.5254464745521545, 0.49058476090431213, 0.6084712147712708, 0.5628682971000671, 0.560449481010437, 0.7113783955574036, 0.5731450915336609, 0.5972239375114441, 0.6352079510688782, 0.5528322458267212, 0.5934339761734009, 0.6231126189231873], "val_accuracy": [0.6899999976158142, 0.7673333287239075, 0.7760000228881836, 0.7993333339691162, 0.8096666932106018, 0.8199999928474426, 0.824999988079071, 0.8190000057220459, 0.8230000138282776, 0.8213333487510681, 0.8330000042915344, 0.8360000252723694, 0.8423333168029785, 0.8356666564941406, 0.8396666646003723, 0.8410000205039978, 0.843999981880188, 0.8386666774749756, 0.8306666612625122, 0.8463333249092102, 0.8493333458900452, 0.8373333215713501, 0.8336666822433472, 0.8323333263397217, 0.8273333311080933, 0.8370000123977661]}, "mapping_values": [1, 11, 6, 5, 3, 15, 8, 7, 4, 9, 6, 3, 1, 1, 0, 1, 0], "tree_depth": 14}, {"genotype": [[0], [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1], [0, 2, 9, 1, 3, 2, 6, 8, 3], [0, 0, 1, 1, 2, 3, 1], [41, 39, 39, 79], [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1], [0, 2, 3, 1, 6, 3, 8, 2, 8], [0, 0, 2, 0, 3, 1, 0], [0, 76, 16, 0], [0, 0, 0, 1, 0, 1, 0, 0, 1], [0, 2, 1, 5, 8, 8], [2, 0, 1], [43], [1], [0], [2], [0]], "fitness": -0.1817142814397812, "mapping_values": [1, 13, 8, 5, 3, 16, 9, 7, 4, 9, 6, 3, 1, 1, 0, 1, 0], "tree_depth": 17, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.constant(1.52235823e-01, shape=shape, dtype=tf.float32), tf.math.subtract(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.multiply(tf.math.add(tf.math.divide_no_nan(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.sqrt(alpha)), alpha), grad)))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(9.95290886e-01, shape=shape, dtype=tf.float32)), beta), tf.math.divide_no_nan(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), grad), tf.math.sqrt(tf.math.add(alpha, tf.math.sqrt(tf.constant(0.0, shape=shape, dtype=tf.float32))))))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.math.add(tf.math.subtract(beta, tf.math.square(tf.constant(2.11963334e-01, shape=shape, dtype=tf.float32))), tf.math.sqrt(tf.math.sqrt(alpha)))), lambda shape,  alpha, beta, sigma, grad: beta", "other_info": {"loss": [2.3098814487457275, 2.306989908218384, 2.306771993637085, 2.3065621852874756, 2.3066325187683105, 2.304682970046997, 2.3049328327178955, 2.3045201301574707, 2.304295778274536, 2.3032078742980957, 2.303248405456543, 2.303006649017334, 2.3031980991363525, 2.3022162914276123, 2.300173759460449, 2.3012807369232178, 2.300974130630493, 2.3003056049346924, 2.3013975620269775, 2.2996644973754883, 2.3004000186920166, 2.3007259368896484, 2.2990474700927734, 2.2999954223632812, 2.2980380058288574, 2.2991113662719727, 2.298208713531494, 2.299215078353882, 2.2979345321655273, 2.2979629039764404, 2.298383951187134, 2.2980642318725586, 2.2975058555603027, 2.29669451713562, 2.2967281341552734, 2.2961411476135254, 2.297085762023926, 2.2970662117004395, 2.296767473220825, 2.296043872833252, 2.295389413833618, 2.2959415912628174, 2.2957494258880615, 2.2955098152160645, 2.295403480529785, 2.2962892055511475, 2.296109914779663, 2.2947769165039062, 2.2938084602355957, 2.2942237854003906, 2.2946386337280273, 2.2948436737060547, 2.293546199798584, 2.294163465499878, 2.2943532466888428, 2.2946653366088867, 2.2937846183776855, 2.2943389415740967, 2.2944955825805664, 2.2923595905303955, 2.292548179626465, 2.2923667430877686, 2.292870044708252, 2.293414354324341, 2.292421340942383, 2.2925524711608887, 2.2929821014404297, 2.292196273803711, 2.2920610904693604, 2.291764974594116, 2.2919530868530273, 2.2911057472229004, 2.292080879211426, 2.291625738143921, 2.2913408279418945, 2.291015148162842, 2.290499210357666, 2.2902302742004395, 2.2906315326690674, 2.2904398441314697, 2.290919542312622, 2.2903475761413574, 2.29038405418396, 2.2907140254974365, 2.290311098098755, 2.290173053741455, 2.2893621921539307, 2.28889536857605, 2.290527820587158, 2.290217876434326, 2.290658950805664, 2.2900450229644775, 2.289069414138794, 2.289140462875366, 2.290123462677002, 2.288806676864624, 2.288696527481079, 2.289336919784546, 2.2884597778320312, 2.2893741130828857, 2.2880005836486816, 2.2883613109588623, 2.287440776824951, 2.289754867553711, 2.2894904613494873, 2.2881619930267334, 2.2878527641296387, 2.287071943283081, 2.2872564792633057, 2.2871031761169434, 2.2877633571624756, 2.2869985103607178, 2.287928342819214, 2.2874748706817627, 2.2878262996673584, 2.287275552749634, 2.287079334259033, 2.2863521575927734, 2.2863783836364746, 2.2857718467712402, 2.287524461746216, 2.2863991260528564, 2.285385847091675, 2.287034749984741, 2.2868378162384033, 2.285989284515381, 2.2858920097351074, 2.285142421722412, 2.285407781600952, 2.2856709957122803, 2.284771203994751, 2.2853033542633057, 2.28595232963562, 2.2850148677825928, 2.2857449054718018, 2.28560733795166, 2.2854719161987305, 2.285287857055664, 2.2854530811309814, 2.2851405143737793, 2.2859482765197754, 2.285233736038208, 2.285064935684204, 2.2847304344177246, 2.2843613624572754, 2.284548759460449, 2.283669948577881, 2.2843375205993652, 2.283661127090454, 2.2838900089263916, 2.2837562561035156, 2.2830944061279297, 2.2850520610809326, 2.283353805541992, 2.2839441299438477, 2.2840752601623535, 2.284379005432129, 2.2838821411132812, 2.284076690673828, 2.2836880683898926, 2.2837376594543457, 2.283640146255493, 2.282848834991455], "accuracy": [0.09430722147226334, 0.09589222073554993, 0.09853387624025345, 0.09536388516426086, 0.10210011899471283, 0.10170386731624603, 0.09800554811954498, 0.09853387624025345, 0.09893012791872025, 0.10672302544116974, 0.09813763201236725, 0.10579843819141388, 0.10976093262434006, 0.10606260597705841, 0.10606260597705841, 0.10632677376270294, 0.10447761416435242, 0.10896842926740646, 0.09932637959718704, 0.11042134463787079, 0.10791176557540894, 0.10566636174917221, 0.11438383162021637, 0.10949676483869553, 0.11345925182104111, 0.10685510188341141, 0.11121384054422379, 0.10751552134752274, 0.10936468094587326, 0.11253467202186584, 0.10632677376270294, 0.11068551242351532, 0.11570466309785843, 0.11187426000833511, 0.11332716792821884, 0.11649715900421143, 0.12032756209373474, 0.11808215826749802, 0.11795007437467575, 0.11834631860256195, 0.11821424216032028, 0.1154404953122139, 0.11953506618738174, 0.1216483935713768, 0.11728965491056442, 0.1146479994058609, 0.11517632752656937, 0.11610091477632523, 0.12138422578573227, 0.1154404953122139, 0.11478008329868317, 0.11940298229455948, 0.12362963706254959, 0.11966715008020401, 0.12429005652666092, 0.11887465417385101, 0.12230881303548813, 0.11993131786584854, 0.12270505726337433, 0.12178047746419907, 0.12310130894184113, 0.11979923397302628, 0.12468630075454712, 0.12349755316972733, 0.1282525360584259, 0.11940298229455948, 0.11993131786584854, 0.13115836679935455, 0.1258750557899475, 0.12574297189712524, 0.12534672021865845, 0.12732796370983124, 0.12679962813854218, 0.12693171203136444, 0.12759213149547577, 0.12957337498664856, 0.13261127471923828, 0.13234710693359375, 0.1258750557899475, 0.1282525360584259, 0.12891295552253723, 0.1286487877368927, 0.1282525360584259, 0.13221503794193268, 0.12481838464736938, 0.13089419901371002, 0.1356491893529892, 0.1340641975402832, 0.13221503794193268, 0.12653546035289764, 0.12917712330818176, 0.13459251821041107, 0.1294412910938263, 0.12891295552253723, 0.13089419901371002, 0.13670584559440613, 0.1332716941833496, 0.13498876988887787, 0.1364416927099228, 0.13670584559440613, 0.1406683325767517, 0.13512085378170013, 0.14436666667461395, 0.13393211364746094, 0.13419628143310547, 0.13789460062980652, 0.1402720957994461, 0.14053626358509064, 0.13961167633533478, 0.13115836679935455, 0.14000792801380157, 0.1394795924425125, 0.14317791163921356, 0.1368379294872284, 0.13472460210323334, 0.1340641975402832, 0.14014001190662384, 0.1422533392906189, 0.14595165848731995, 0.1450270712375641, 0.13630960881710052, 0.1426495909690857, 0.1442345827817917, 0.13670584559440613, 0.13974376022815704, 0.14159291982650757, 0.1368379294872284, 0.14463083446025848, 0.13736626505851746, 0.14278165996074677, 0.14000792801380157, 0.1434420794248581, 0.1430458277463913, 0.14700831472873688, 0.14476291835308075, 0.13789460062980652, 0.1398758441209793, 0.15057456493377686, 0.14542332291603088, 0.1450270712375641, 0.1410645842552185, 0.13961167633533478, 0.14819706976413727, 0.14000792801380157, 0.14515915513038635, 0.14529123902320862, 0.1460837423801422, 0.1488574892282486, 0.15532954037189484, 0.14436666667461395, 0.14819706976413727, 0.14832915365695953, 0.1450270712375641, 0.1516312211751938, 0.15031039714813232, 0.14661207795143127, 0.14397041499614716, 0.14793290197849274, 0.1438383311033249, 0.1562541276216507, 0.15057456493377686, 0.14581957459449768, 0.15255580842494965], "val_loss": [2.3073439598083496, 2.306326150894165, 2.3055312633514404, 2.3048744201660156, 2.304286241531372, 2.303755760192871, 2.3032665252685547, 2.3028132915496826, 2.3023898601531982, 2.3019847869873047, 2.301607370376587, 2.301248788833618, 2.3008971214294434, 2.3005592823028564, 2.300234317779541, 2.2999207973480225, 2.299618721008301, 2.299323558807373, 2.2990384101867676, 2.2987611293792725, 2.2984914779663086, 2.2982258796691895, 2.2979705333709717, 2.2977232933044434, 2.2974817752838135, 2.2972445487976074, 2.297011137008667, 2.2967827320098877, 2.2965619564056396, 2.296346426010132, 2.296132802963257, 2.295921564102173, 2.2957115173339844, 2.2955071926116943, 2.2953062057495117, 2.295107364654541, 2.2949113845825195, 2.2947165966033936, 2.2945282459259033, 2.2943389415740967, 2.2941555976867676, 2.2939743995666504, 2.293793201446533, 2.2936153411865234, 2.293440341949463, 2.2932660579681396, 2.293093204498291, 2.292922258377075, 2.292752981185913, 2.2925865650177, 2.292421340942383, 2.292257070541382, 2.2920992374420166, 2.291940450668335, 2.2917838096618652, 2.2916276454925537, 2.291473388671875, 2.2913219928741455, 2.2911736965179443, 2.2910265922546387, 2.290881633758545, 2.2907376289367676, 2.290595769882202, 2.290454864501953, 2.2903177738189697, 2.290179491043091, 2.2900445461273193, 2.289907932281494, 2.289774179458618, 2.289642333984375, 2.28951096534729, 2.289381742477417, 2.2892534732818604, 2.289123773574829, 2.2889955043792725, 2.2888691425323486, 2.288745880126953, 2.2886226177215576, 2.288499593734741, 2.288377285003662, 2.2882566452026367, 2.2881364822387695, 2.2880170345306396, 2.2878973484039307, 2.287778854370117, 2.287658929824829, 2.287541627883911, 2.2874257564544678, 2.2873101234436035, 2.2871949672698975, 2.2870802879333496, 2.2869670391082764, 2.2868547439575195, 2.286742925643921, 2.286632537841797, 2.28652286529541, 2.2864155769348145, 2.286308526992798, 2.2862024307250977, 2.2860960960388184, 2.2859909534454346, 2.2858850955963135, 2.2857816219329834, 2.2856781482696533, 2.285573959350586, 2.2854716777801514, 2.2853691577911377, 2.2852678298950195, 2.285167694091797, 2.285067319869995, 2.2849667072296143, 2.28486704826355, 2.2847676277160645, 2.2846691608428955, 2.2845711708068848, 2.2844736576080322, 2.2843778133392334, 2.284283399581909, 2.284187078475952, 2.2840921878814697, 2.2839975357055664, 2.2839040756225586, 2.283811092376709, 2.283717393875122, 2.2836244106292725, 2.283534288406372, 2.283442497253418, 2.2833518981933594, 2.283261775970459, 2.283170461654663, 2.2830820083618164, 2.2829928398132324, 2.2829031944274902, 2.2828145027160645, 2.2827258110046387, 2.282637357711792, 2.2825491428375244, 2.282460927963257, 2.2823734283447266, 2.2822868824005127, 2.282200574874878, 2.282114028930664, 2.2820301055908203, 2.281944513320923, 2.281860113143921, 2.28177547454834, 2.281691789627075, 2.2816078662872314, 2.281524181365967, 2.2814407348632812, 2.281358003616333, 2.281275749206543, 2.281193256378174, 2.281111717224121, 2.281031608581543, 2.2809507846832275, 2.280869960784912, 2.280790090560913, 2.280710458755493, 2.2806308269500732, 2.280552387237549, 2.2804739475250244, 2.280395746231079], "val_accuracy": [0.09533333033323288, 0.0963333323597908, 0.0963333323597908, 0.09733333438634872, 0.09833333641290665, 0.09866666793823242, 0.1003333330154419, 0.10100000351667404, 0.10199999809265137, 0.10233332961797714, 0.10233332961797714, 0.10300000011920929, 0.10433333367109299, 0.10499999672174454, 0.10533333569765091, 0.10599999874830246, 0.10599999874830246, 0.10566666722297668, 0.10533333569765091, 0.10533333569765091, 0.10733333230018616, 0.10899999737739563, 0.10999999940395355, 0.11166666448116302, 0.11233333498239517, 0.11233333498239517, 0.11233333498239517, 0.1133333370089531, 0.11299999803304672, 0.1133333370089531, 0.11366666853427887, 0.11299999803304672, 0.11299999803304672, 0.11533333361148834, 0.11599999666213989, 0.11699999868869781, 0.11766666918992996, 0.11933333426713943, 0.12066666781902313, 0.12099999934434891, 0.12200000137090683, 0.12200000137090683, 0.12166666984558105, 0.1223333328962326, 0.12200000137090683, 0.12266666442155838, 0.12333333492279053, 0.1236666664481163, 0.12433333694934845, 0.12533333897590637, 0.12466666847467422, 0.12466666847467422, 0.12433333694934845, 0.12566666305065155, 0.12666666507720947, 0.1263333261013031, 0.12700000405311584, 0.12833333015441895, 0.12866666913032532, 0.13066667318344116, 0.13099999725818634, 0.13199999928474426, 0.13233333826065063, 0.13366666436195374, 0.13433332741260529, 0.1353333294391632, 0.13500000536441803, 0.13500000536441803, 0.13566666841506958, 0.1353333294391632, 0.13566666841506958, 0.13633333146572113, 0.13633333146572113, 0.13733333349227905, 0.13766667246818542, 0.13766667246818542, 0.1379999965429306, 0.1379999965429306, 0.13833333551883698, 0.1393333375453949, 0.13899999856948853, 0.1393333375453949, 0.14100000262260437, 0.1420000046491623, 0.14233332872390747, 0.14366666972637177, 0.14366666972637177, 0.14433333277702332, 0.14499999582767487, 0.14633333683013916, 0.1469999998807907, 0.14733333885669708, 0.14766666293144226, 0.14866666495800018, 0.14900000393390656, 0.14933332800865173, 0.1496666669845581, 0.15000000596046448, 0.1509999930858612, 0.1509999930858612, 0.1509999930858612, 0.15199999511241913, 0.15199999511241913, 0.15266667306423187, 0.15299999713897705, 0.15466666221618652, 0.15533334016799927, 0.1550000011920929, 0.15566666424274445, 0.156333327293396, 0.156333327293396, 0.156333327293396, 0.15700000524520874, 0.15700000524520874, 0.1576666682958603, 0.1576666682958603, 0.15833333134651184, 0.1586666703224182, 0.15966667234897614, 0.15966667234897614, 0.15966667234897614, 0.16066665947437286, 0.16099999845027924, 0.1613333374261856, 0.16233333945274353, 0.1626666635274887, 0.16333332657814026, 0.164000004529953, 0.16433332860469818, 0.16500000655651093, 0.1653333306312561, 0.16566666960716248, 0.16566666960716248, 0.1653333306312561, 0.1653333306312561, 0.16633333265781403, 0.1666666716337204, 0.1666666716337204, 0.1679999977350235, 0.16833333671092987, 0.16866666078567505, 0.16966666281223297, 0.17033334076404572, 0.17100000381469727, 0.17233332991600037, 0.1733333319425583, 0.1733333319425583, 0.17399999499320984, 0.1743333339691162, 0.17499999701976776, 0.1756666600704193, 0.17633333802223206, 0.17666666209697723, 0.1770000010728836, 0.17666666209697723, 0.17733334004878998, 0.17666666209697723, 0.17800000309944153, 0.17733334004878998, 0.1770000010728836, 0.1770000010728836, 0.17766666412353516, 0.17800000309944153]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1], [0, 6, 3, 1, 3, 2, 3, 8, 1, 7, 8], [0, 0, 1, 0, 2, 1, 0, 2, 1], [0, 39, 39, 97], [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], [0, 2, 3, 1, 6, 3, 8, 2, 8, 5, 2, 7, 8, 0, 8], [0, 0, 0, 0, 3, 1, 0, 1, 0], [0, 76, 16, 0, 41, 91], [1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 2, 1, 5, 8, 8], [2, 0, 1], [43], [1], [0], [2], [0]], "fitness": -0.10000000149011612, "mapping_values": [1, 20, 11, 9, 4, 24, 15, 9, 6, 1, 0, 1, 0, 1, 0, 1, 0], "tree_depth": 22, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.divide_no_nan(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.math.multiply(tf.math.add(tf.math.multiply(tf.math.sqrt(tf.math.subtract(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), alpha)), tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), tf.math.add(grad, alpha)), tf.math.sqrt(tf.constant(9.99932002e-01, shape=shape, dtype=tf.float32)))), grad), alpha)), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(9.95290886e-01, shape=shape, dtype=tf.float32)), tf.math.divide_no_nan(tf.math.multiply(tf.math.sqrt(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), tf.constant(0.0, shape=shape, dtype=tf.float32)), tf.math.add(tf.math.sqrt(grad), tf.math.square(alpha)))), tf.math.add(tf.math.add(tf.math.sqrt(tf.math.negative(tf.math.sqrt(tf.constant(1.52235823e-01, shape=shape, dtype=tf.float32)))), alpha), tf.constant(9.99771521e-01, shape=shape, dtype=tf.float32)))), lambda shape,  alpha, beta, sigma, grad: beta, lambda shape,  alpha, beta, sigma, grad: beta", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.1006472036242485, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246, 0.10599999874830246]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1], [0, 6, 3, 1, 3, 2, 3, 2, 0, 0, 0], [0, 0, 0, 0, 2, 2, 1, 2], [0, 39, 39, 8], [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1], [0, 2, 4, 1, 6, 3, 8, 2, 8, 3], [0, 0, 2, 0, 3, 1, 0, 1], [82, 27, 16, 0], [1, 0, 0, 1, 0, 1, 0, 0, 1], [0, 2, 1, 5, 8, 8], [2, 0, 1], [43], [1], [0], [2], [0]], "fitness": -0.10000000149011612, "mapping_values": [1, 19, 11, 8, 4, 18, 10, 8, 4, 1, 0, 1, 0, 1, 0, 1, 0], "tree_depth": 16, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.divide_no_nan(tf.math.multiply(tf.math.subtract(tf.constant(0.0, shape=shape, dtype=tf.float32), tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), tf.math.multiply(tf.math.add(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.multiply(tf.constant(2.28478855e-04, shape=shape, dtype=tf.float32), grad)), grad)), tf.math.add(alpha, tf.math.negative(tf.math.negative(tf.math.negative(grad)))))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.pow(tf.math.subtract(tf.constant(9.98594080e-01, shape=shape, dtype=tf.float32), tf.constant(1.05038445e-02, shape=shape, dtype=tf.float32)), tf.math.divide_no_nan(tf.math.multiply(tf.math.sqrt(beta), tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), tf.math.add(tf.math.sqrt(grad), tf.math.multiply(alpha, tf.constant(0.0, shape=shape, dtype=tf.float32))))), alpha)), lambda shape,  alpha, beta, sigma, grad: beta, lambda shape,  alpha, beta, sigma, grad: beta", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.09668471664190292, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.0976666659116745, 0.0976666659116745, 0.0976666659116745, 0.0976666659116745, 0.0976666659116745, 0.0976666659116745]}}, {"genotype": [[0], [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1], [0, 2, 3, 1, 3, 5, 6, 7, 8], [0, 0, 1, 1, 1, 2, 2], [84, 39, 39, 79], [1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1], [0, 2, 3, 1, 6, 3, 8, 2, 8], [0, 3, 2, 0, 3, 3, 0], [0, 27, 16, 0], [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1], [0, 2, 1, 5, 8, 8, 2], [2, 0, 1, 0], [88, 15], [1], [0], [4], [0]], "fitness": -0.10000000149011612, "mapping_values": [1, 2, 1, 1, 1, 1, 0, 1, 1, 11, 7, 4, 2, 1, 0, 1, 0], "tree_depth": 18, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.constant(9.99060945e-01, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, grad: tf.constant(0.0, shape=shape, dtype=tf.float32), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.math.add(tf.math.subtract(beta, tf.math.square(tf.math.sqrt(tf.math.sqrt(tf.math.add(tf.constant(9.99581233e-01, shape=shape, dtype=tf.float32), alpha))))), tf.constant(9.39055039e-04, shape=shape, dtype=tf.float32))), lambda shape,  alpha, beta, sigma, grad: grad", "other_info": {"loss": [30.660686492919922, 2.350567579269409, 2.308290481567383, 2.3042070865631104, 2.303194999694824, 2.303016424179077], "accuracy": [0.17236824333667755, 0.10130762308835983, 0.09536388516426086, 0.0952318087220192, 0.09549596905708313, 0.09906221181154251], "val_loss": [2.473325252532959, 2.3123741149902344, 2.304745674133301, 2.303218364715576, 2.3027632236480713, 2.3027005195617676], "val_accuracy": [0.09966666996479034, 0.09799999743700027, 0.09966666996479034, 0.09966666996479034, 0.09966666996479034, 0.09966666996479034]}}]