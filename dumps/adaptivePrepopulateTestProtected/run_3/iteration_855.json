[{"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 0, 2], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 3, 3, 6, 8, 1, 4, 1, 4, 2, 8], [0, 0, 0, 3, 0, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.8822857141494751, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), grad))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma))), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), tf.math.add(tf.math.sqrt(beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [2.221585750579834, 1.8655762672424316, 1.394430160522461, 1.0773245096206665, 0.9378393888473511, 0.8425824046134949, 0.7776632308959961, 0.736241340637207, 0.6971188187599182, 0.6732122302055359, 0.644855797290802, 0.6276965141296387, 0.6100340485572815, 0.5899673104286194, 0.5746485590934753, 0.5484329462051392, 0.5425268411636353, 0.5357900857925415, 0.5214410424232483, 0.5127171874046326, 0.4895091950893402, 0.4932740032672882, 0.48551443219184875, 0.47113916277885437, 0.46571049094200134, 0.450914591550827, 0.438728004693985, 0.4414178729057312, 0.4245515465736389, 0.4182806611061096, 0.4126766324043274, 0.41352686285972595, 0.4031256139278412, 0.40064555406570435, 0.3982388377189636, 0.38566267490386963, 0.38400527834892273, 0.3741128146648407, 0.36422181129455566, 0.36170411109924316, 0.35991787910461426, 0.35666367411613464, 0.3521813750267029, 0.34583958983421326, 0.34736087918281555, 0.34181836247444153, 0.33650368452072144, 0.33141741156578064, 0.3230496346950531, 0.3225416839122772, 0.315096914768219, 0.3059031665325165, 0.3058394491672516, 0.3017319440841675, 0.29568877816200256, 0.2933836281299591, 0.28774771094322205, 0.2856961190700531, 0.2802303731441498, 0.2779994010925293, 0.274711549282074, 0.2719985842704773, 0.2586328387260437, 0.2598455548286438, 0.2622571289539337, 0.25739434361457825, 0.2502012252807617, 0.2544722855091095, 0.24556587636470795, 0.24580754339694977, 0.23948103189468384, 0.23949603736400604, 0.23484042286872864, 0.22871272265911102, 0.2256491780281067, 0.22479403018951416, 0.21744707226753235, 0.21390178799629211, 0.21272219717502594], "accuracy": [0.2785629332065582, 0.49451854825019836, 0.559899628162384, 0.6215823292732239, 0.6654338836669922, 0.6950204968452454, 0.7181349992752075, 0.7322678565979004, 0.7441553473472595, 0.7483819723129272, 0.7627789974212646, 0.7717606425285339, 0.7728173136711121, 0.78113853931427, 0.7882710099220276, 0.7993659973144531, 0.7976489067077637, 0.8074230551719666, 0.8128384351730347, 0.8198388814926147, 0.8212917447090149, 0.819970965385437, 0.8272355198860168, 0.8350284099578857, 0.8305375576019287, 0.8387266993522644, 0.846387505531311, 0.8433496356010437, 0.8504821062088013, 0.8524633646011353, 0.8535200357437134, 0.854708731174469, 0.856689989566803, 0.8551049828529358, 0.8593316674232483, 0.8615770936012268, 0.8628978729248047, 0.8702945709228516, 0.8691058158874512, 0.871879518032074, 0.8722757697105408, 0.8691058158874512, 0.8733324408531189, 0.8800686597824097, 0.8795403242111206, 0.8755778670310974, 0.8768987059593201, 0.8829745054244995, 0.8824461698532104, 0.8823140859603882, 0.887201189994812, 0.8897107243537903, 0.8889182209968567, 0.8927486538887024, 0.8902390599250793, 0.8953903317451477, 0.8980319499969482, 0.8976356983184814, 0.900409460067749, 0.89552241563797, 0.9025228023529053, 0.8989565372467041, 0.9056927561759949, 0.9085986018180847, 0.9030511379241943, 0.9066173434257507, 0.9101836085319519, 0.9083344340324402, 0.909259021282196, 0.9099194407463074, 0.9126931428909302, 0.9140139818191528, 0.9119006991386414, 0.9171839952468872, 0.9169198274612427, 0.9185048341751099, 0.9218068718910217, 0.9185048341751099, 0.9196935892105103], "val_loss": [2.033445358276367, 1.5042319297790527, 1.0271512269973755, 0.8147247433662415, 0.7278039455413818, 0.68117356300354, 0.6306353211402893, 0.5966841578483582, 0.5751398801803589, 0.5460951328277588, 0.5314993858337402, 0.509799063205719, 0.4957965612411499, 0.4792602062225342, 0.46671679615974426, 0.45267683267593384, 0.4441072940826416, 0.4356139600276947, 0.42943108081817627, 0.4255247414112091, 0.41811680793762207, 0.4163394272327423, 0.39929893612861633, 0.3969916105270386, 0.39089226722717285, 0.387652188539505, 0.3844633102416992, 0.3824205696582794, 0.3749690353870392, 0.3701930642127991, 0.36967378854751587, 0.36689504981040955, 0.3585263788700104, 0.3587398827075958, 0.36267170310020447, 0.3561091423034668, 0.35379692912101746, 0.3499273955821991, 0.34701839089393616, 0.3467637896537781, 0.3424672484397888, 0.33951225876808167, 0.3386255204677582, 0.34044384956359863, 0.33945050835609436, 0.33684298396110535, 0.3322163224220276, 0.33181649446487427, 0.32827115058898926, 0.3312568664550781, 0.3297465741634369, 0.3256674110889435, 0.3234780728816986, 0.32119208574295044, 0.3232716917991638, 0.3209094703197479, 0.31944912672042847, 0.3157532513141632, 0.3144265413284302, 0.31676045060157776, 0.31425556540489197, 0.3131799101829529, 0.3147056996822357, 0.3154993951320648, 0.31771615147590637, 0.31545644998550415, 0.3127000629901886, 0.31382524967193604, 0.31026333570480347, 0.3147730529308319, 0.30829918384552, 0.3107443153858185, 0.31316936016082764, 0.30297672748565674, 0.30325081944465637, 0.30436232686042786, 0.3072424829006195, 0.30681705474853516, 0.3061434030532837], "val_accuracy": [0.5526666641235352, 0.6666666865348816, 0.687333345413208, 0.7083333134651184, 0.731333315372467, 0.7446666955947876, 0.7606666684150696, 0.762666642665863, 0.7873333096504211, 0.7889999747276306, 0.7973333597183228, 0.8056666851043701, 0.8193333148956299, 0.8259999752044678, 0.8289999961853027, 0.8410000205039978, 0.8453333377838135, 0.8450000286102295, 0.8489999771118164, 0.847000002861023, 0.8516666889190674, 0.856333315372467, 0.859333336353302, 0.856333315372467, 0.8633333444595337, 0.8640000224113464, 0.8656666874885559, 0.8646666407585144, 0.8679999709129333, 0.8696666955947876, 0.8640000224113464, 0.8686666488647461, 0.8713333606719971, 0.8709999918937683, 0.8703333139419556, 0.8723333477973938, 0.871999979019165, 0.874666690826416, 0.8723333477973938, 0.8759999871253967, 0.8726666569709778, 0.875333309173584, 0.8790000081062317, 0.8756666779518127, 0.8726666569709778, 0.8769999742507935, 0.8796666860580444, 0.8796666860580444, 0.8806666731834412, 0.8793333172798157, 0.8813333511352539, 0.8840000033378601, 0.8840000033378601, 0.8843333125114441, 0.8809999823570251, 0.8856666684150696, 0.8866666555404663, 0.8833333253860474, 0.8866666555404663, 0.8843333125114441, 0.8856666684150696, 0.8880000114440918, 0.887333333492279, 0.8883333206176758, 0.8866666555404663, 0.8896666765213013, 0.8863333463668823, 0.8853333592414856, 0.890999972820282, 0.8870000243186951, 0.8883333206176758, 0.8883333206176758, 0.8916666507720947, 0.8939999938011169, 0.8896666765213013, 0.8916666507720947, 0.890999972820282, 0.8926666378974915, 0.8913333415985107]}, "mapping_values": [1, 9, 5, 4, 2, 10, 6, 4, 2, 2, 1, 1, 1, 21, 11, 10, 6], "tree_depth": 18}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 0, 2], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 3, 3, 6, 8, 1, 4, 1, 4, 2, 8], [0, 0, 0, 3, 0, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.8411428332328796, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), grad))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma))), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), tf.math.add(tf.math.sqrt(beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [2.2204642295837402, 1.8634474277496338, 1.3946988582611084, 1.0964983701705933, 0.9447709918022156, 0.8422807455062866, 0.7730602025985718, 0.7284019589424133, 0.6987776160240173, 0.6678225994110107, 0.6408907175064087, 0.6131806969642639, 0.5979712605476379, 0.5764649510383606, 0.5695537328720093, 0.5540521144866943, 0.5400431156158447, 0.5247713327407837, 0.5104837417602539, 0.5072107911109924, 0.4936470687389374, 0.48704150319099426, 0.46724098920822144, 0.4573417007923126, 0.4530077874660492, 0.4452309012413025, 0.43983757495880127, 0.4277762174606323, 0.42826271057128906, 0.41124656796455383, 0.4106709063053131, 0.40287065505981445, 0.3941679298877716, 0.3848540484905243, 0.3800601065158844, 0.3838157057762146, 0.37780842185020447], "accuracy": [0.2818650007247925, 0.4803856909275055, 0.5663716793060303, 0.6124686598777771, 0.6596222519874573, 0.6972658634185791, 0.7190595865249634, 0.735041618347168, 0.7441553473472595, 0.7543256878852844, 0.763967752456665, 0.7757231593132019, 0.7849689722061157, 0.7924976944923401, 0.7921014428138733, 0.7988376617431641, 0.8025360107421875, 0.8133667707443237, 0.8148196935653687, 0.817461371421814, 0.8211596608161926, 0.8271034359931946, 0.8368775844573975, 0.8338396549224854, 0.8363492488861084, 0.844010055065155, 0.8428213000297546, 0.8519350290298462, 0.8481045961380005, 0.8576145768165588, 0.8553691506385803, 0.8558974862098694, 0.860652506351471, 0.8625016212463379, 0.8648791313171387, 0.8663320541381836, 0.8665962219238281], "val_loss": [2.0373926162719727, 1.5168787240982056, 1.0542449951171875, 0.8580164313316345, 0.7618102431297302, 0.7081283926963806, 0.654941737651825, 0.620164692401886, 0.5949755311012268, 0.5683022141456604, 0.5572265386581421, 0.5355048775672913, 0.5165846943855286, 0.506654679775238, 0.4994596242904663, 0.4878422021865845, 0.4742763638496399, 0.468962162733078, 0.4591525197029114, 0.4555134177207947, 0.4465857744216919, 0.43750178813934326, 0.4299021065235138, 0.42613106966018677, 0.4208851456642151, 0.41359326243400574, 0.4073968231678009, 0.4121575951576233, 0.4017452001571655, 0.39477360248565674, 0.3928059935569763, 0.3875041604042053, 0.38758546113967896, 0.390922486782074, 0.38379576802253723, 0.38014736771583557, 0.37598004937171936], "val_accuracy": [0.515999972820282, 0.6473333239555359, 0.6776666641235352, 0.7009999752044678, 0.7263333201408386, 0.7459999918937683, 0.762333333492279, 0.7749999761581421, 0.7803333401679993, 0.7926666736602783, 0.800000011920929, 0.8063333630561829, 0.8116666674613953, 0.8193333148956299, 0.8193333148956299, 0.8266666531562805, 0.8296666741371155, 0.8276666402816772, 0.8373333215713501, 0.8353333473205566, 0.8370000123977661, 0.8416666388511658, 0.8486666679382324, 0.8486666679382324, 0.8510000109672546, 0.8533333539962769, 0.8553333282470703, 0.8526666760444641, 0.859000027179718, 0.8603333234786987, 0.8610000014305115, 0.8669999837875366, 0.8606666922569275, 0.8600000143051147, 0.8633333444595337, 0.8616666793823242, 0.8666666746139526]}, "mapping_values": [1, 9, 5, 4, 2, 10, 6, 4, 2, 2, 1, 1, 1, 21, 11, 10, 6], "tree_depth": 18}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 0, 0, 3], [2, 0, 0, 2], [36, 39], [0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1], [0, 1, 3, 0, 3, 5, 1], [0, 2, 0, 3, 2], [77, 16], [0, 1], [0], [4], [72], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0], [6, 3, 2, 6, 6, 1, 4, 1, 4, 2, 9, 0, 9], [0, 0, 0, 3, 1, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.10000000149011612, "mapping_values": [1, 6, 4, 2, 1, 12, 7, 5, 2, 2, 1, 1, 0, 22, 13, 9, 6], "tree_depth": 24, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.negative(tf.math.negative(grad)), tf.constant(6.13831074e-02, shape=shape, dtype=tf.float32))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.subtract(tf.math.multiply(tf.math.negative(tf.math.multiply(tf.constant(9.96148968e-01, shape=shape, dtype=tf.float32), tf.math.square(beta))), tf.math.subtract(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), grad)), beta)), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(grad), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.add(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.divide_no_nan(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.math.subtract(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), tf.math.pow(sigma, tf.math.add(alpha, tf.constant(1.0, shape=shape, dtype=tf.float32)))), sigma)), tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32)), tf.math.negative(alpha))), beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32))", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.10328886657953262, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.0989999994635582, 0.0989999994635582, 0.0989999994635582, 0.0989999994635582, 0.0989999994635582, 0.0989999994635582]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 0, 2], [39, 91], [1, 1, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 1, 0, 3], [16, 16], [0, 0], [0, 9], [4], [99], [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], [6, 3, 3, 6, 8, 1, 4, 1, 2, 2, 8], [0, 0, 3, 3, 0, 2, 3, 1, 4, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.10000000149011612, "mapping_values": [1, 9, 5, 4, 2, 1, 0, 1, 1, 2, 2, 0, 1, 20, 10, 10, 4], "tree_depth": 20, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(9.99771521e-01, shape=shape, dtype=tf.float32), grad))), lambda shape,  alpha, beta, grad: tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.math.pow(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), sigma), sigma), tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32))), tf.math.add(beta, sigma))), alpha), tf.math.add(grad, tf.constant(1.0, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.10117553919553757, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.1003333330154419, 0.1003333330154419, 0.1003333330154419, 0.1003333330154419, 0.1003333330154419, 0.1003333330154419]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3, 0, 5, 6, 4, 9, 6, 4], [0, 1, 0, 2, 1, 0, 0], [39, 39, 24, 6, 37], [0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], [0, 2, 3, 0, 3, 5, 7, 1, 9, 3, 6, 9, 0, 2, 3, 9, 9], [2, 2, 2, 3, 3, 3], [16, 16, 51, 34], [0, 1], [0], [0], [99], [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1], [2, 3, 3, 6, 3, 2, 4, 1, 4, 2, 8, 0, 2, 2, 4, 1, 1, 7, 2, 7, 0, 6, 0, 3, 3, 2, 3, 7, 9, 5, 9], [0, 2, 0, 3, 0, 0, 3, 1, 2, 0, 6, 0, 4, 1, 4, 5, 7, 0, 7, 2, 4, 2, 3], [16, 99, 96, 99, 61, 6, 22, 64, 96]], "fitness": -0.10000000149011612, "mapping_values": [1, 19, 12, 7, 5, 23, 17, 6, 4, 2, 1, 1, 1, 54, 31, 23, 9], "tree_depth": 25, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), tf.math.multiply(tf.math.negative(alpha), tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32))), tf.math.square(tf.math.divide_no_nan(tf.math.pow(tf.constant(5.75728612e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(grad, alpha)), tf.math.pow(tf.constant(1.52547986e-04, shape=shape, dtype=tf.float32), tf.constant(7.41067363e-02, shape=shape, dtype=tf.float32)))))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(beta), beta), tf.math.multiply(tf.math.square(tf.math.add(beta, tf.math.subtract(grad, tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)))), tf.math.multiply(grad, tf.math.divide_no_nan(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.negative(tf.math.add(tf.math.multiply(tf.constant(5.75183132e-01, shape=shape, dtype=tf.float32), grad), tf.constant(4.18339400e-02, shape=shape, dtype=tf.float32)))))))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.add(tf.math.multiply(tf.math.multiply(tf.math.divide_no_nan(tf.math.multiply(tf.math.add(tf.math.pow(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.subtract(beta, tf.constant(1.0, shape=shape, dtype=tf.float32))), tf.math.pow(sigma, tf.math.add(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), tf.constant(1.0, shape=shape, dtype=tf.float32)))), sigma), tf.math.sqrt(tf.math.negative(alpha))), beta), tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32)), tf.math.add(tf.math.add(grad, tf.math.pow(tf.math.subtract(tf.math.subtract(tf.math.add(tf.math.add(tf.constant(1.52547986e-04, shape=shape, dtype=tf.float32), grad), tf.math.add(tf.math.negative(alpha), tf.math.divide_no_nan(grad, tf.math.negative(tf.math.multiply(grad, grad))))), tf.math.multiply(tf.math.add(tf.math.multiply(tf.constant(3.85103236e-03, shape=shape, dtype=tf.float32), tf.math.add(grad, tf.constant(9.49275639e-01, shape=shape, dtype=tf.float32))), tf.math.square(beta)), tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32))), grad), beta)), sigma))", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.09919429570436478, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.0963333323597908, 0.0963333323597908, 0.0963333323597908, 0.0963333323597908, 0.0963333323597908, 0.0963333323597908]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 8, 0, 3], [1, 1, 0, 0], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 5, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 3, 3, 6, 8, 1, 4, 1, 4, 2, 8], [0, 0, 0, 1, 0, 0, 3, 1, 2, 0], [88, 99, 42, 99, 61, 1]], "fitness": -0.0925714299082756, "mapping_values": [1, 6, 4, 2, 0, 10, 6, 4, 2, 2, 1, 1, 1, 21, 11, 10, 6], "tree_depth": 18, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.sqrt(tf.math.negative(alpha)), alpha)), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.square(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(9.99581233e-01, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(1.80176593e-01, shape=shape, dtype=tf.float32), alpha))), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), tf.math.add(tf.math.sqrt(beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [2.310647964477539, 2.309094190597534, 2.3104615211486816, 2.30946683883667, 2.3104846477508545, 2.3106229305267334], "accuracy": [0.08928807079792023, 0.09430722147226334, 0.09060890227556229, 0.08889182657003403, 0.09206181764602661, 0.0948355570435524], "val_loss": [2.3084630966186523, 2.3084630966186523, 2.3084630966186523, 2.3084630966186523, 2.3084630966186523, 2.3084630966186523], "val_accuracy": [0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186]}}]