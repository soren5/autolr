[{"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 0, 2], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 3, 3, 6, 8, 1, 4, 1, 4, 2, 8], [0, 0, 0, 3, 0, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.878000020980835, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), grad))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma))), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), tf.math.add(tf.math.sqrt(beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [2.223759174346924, 1.8681567907333374, 1.3971633911132812, 1.1021500825881958, 0.9438490867614746, 0.8268281817436218, 0.7700234055519104, 0.7182450890541077, 0.6839274764060974, 0.655160665512085, 0.6316797733306885, 0.6046612858772278, 0.586663544178009, 0.5732303261756897, 0.5552444458007812, 0.5382086634635925, 0.5205084085464478, 0.5141545534133911, 0.49866363406181335, 0.4905571937561035, 0.48713892698287964, 0.4630949795246124, 0.46493759751319885, 0.4510720372200012, 0.4456666111946106, 0.4411585330963135, 0.43109801411628723, 0.4194287657737732, 0.41647717356681824, 0.4177640676498413, 0.39898860454559326, 0.3982110619544983, 0.3941095173358917, 0.3838343918323517, 0.38270825147628784, 0.38132011890411377, 0.3706604242324829, 0.3630581796169281, 0.35970449447631836, 0.3585955500602722, 0.3488880693912506, 0.3406795859336853, 0.3434852361679077, 0.34305644035339355, 0.32770219445228577, 0.3274216949939728, 0.3164256513118744, 0.31487780809402466, 0.31453031301498413, 0.3020377457141876, 0.3013147711753845, 0.29238083958625793, 0.30650538206100464, 0.2886098325252533, 0.28784143924713135, 0.28922179341316223, 0.27991431951522827, 0.27731093764305115, 0.27029022574424744, 0.2677718997001648, 0.2672445476055145], "accuracy": [0.27182671427726746, 0.4913485646247864, 0.5609562993049622, 0.6095628142356873, 0.6618676781654358, 0.6997754573822021, 0.7215691208839417, 0.7407211661338806, 0.7508915662765503, 0.7592127919197083, 0.7656848430633545, 0.7798177003860474, 0.7849689722061157, 0.789459764957428, 0.7991018295288086, 0.806630551815033, 0.81112140417099, 0.8088759779930115, 0.8210275769233704, 0.8181217908859253, 0.826310932636261, 0.8333113193511963, 0.8294808864593506, 0.8401796221733093, 0.8409721255302429, 0.8436138033866882, 0.8459912538528442, 0.8519350290298462, 0.8485008478164673, 0.8490291833877563, 0.856689989566803, 0.8573504090309143, 0.8615770936012268, 0.8644828796386719, 0.8605204224586487, 0.8614450097084045, 0.8671245574951172, 0.8726720213890076, 0.8732003569602966, 0.8689737319946289, 0.8762382864952087, 0.8798044919967651, 0.8717474341392517, 0.8825782537460327, 0.8840311765670776, 0.8845595121383667, 0.8885219693183899, 0.8865407705307007, 0.8887861371040344, 0.894069492816925, 0.8918240666389465, 0.8953903317451477, 0.8860124349594116, 0.8988244533538818, 0.8992207050323486, 0.8956544995307922, 0.9014661312103271, 0.89988112449646, 0.900409460067749, 0.9046360850334167, 0.9033153057098389], "val_loss": [2.0386126041412354, 1.5089809894561768, 1.0396978855133057, 0.8277255296707153, 0.7414798736572266, 0.6867381930351257, 0.6452507376670837, 0.6096968054771423, 0.5920496582984924, 0.5695558786392212, 0.550778865814209, 0.5315823554992676, 0.5166425704956055, 0.5040237307548523, 0.4927339255809784, 0.48035380244255066, 0.4752146899700165, 0.4640548527240753, 0.45926037430763245, 0.4498494863510132, 0.44989997148513794, 0.43486902117729187, 0.4302854835987091, 0.42699891328811646, 0.4222937822341919, 0.4179273545742035, 0.4156407117843628, 0.40615877509117126, 0.40567347407341003, 0.40483561158180237, 0.4008205533027649, 0.3957735300064087, 0.3910598158836365, 0.39842313528060913, 0.38378071784973145, 0.3824272155761719, 0.37983548641204834, 0.3832281529903412, 0.37993335723876953, 0.37290528416633606, 0.37028563022613525, 0.3697679340839386, 0.369826078414917, 0.3630952835083008, 0.3613884747028351, 0.3612003028392792, 0.3630628287792206, 0.35836127400398254, 0.35707563161849976, 0.3544061779975891, 0.35439038276672363, 0.35541149973869324, 0.34793493151664734, 0.355723112821579, 0.3566884696483612, 0.3480426073074341, 0.35176366567611694, 0.34468159079551697, 0.3469727337360382, 0.34757280349731445, 0.34379008412361145], "val_accuracy": [0.546999990940094, 0.6536666750907898, 0.6856666803359985, 0.7066666483879089, 0.7366666793823242, 0.7536666393280029, 0.7599999904632568, 0.7720000147819519, 0.7706666588783264, 0.7926666736602783, 0.7963333129882812, 0.7956666946411133, 0.8103333115577698, 0.809333324432373, 0.8220000267028809, 0.8226666450500488, 0.8243333101272583, 0.8330000042915344, 0.8349999785423279, 0.8370000123977661, 0.8333333134651184, 0.8429999947547913, 0.8463333249092102, 0.8446666598320007, 0.8476666808128357, 0.8479999899864197, 0.8450000286102295, 0.8506666421890259, 0.8496666550636292, 0.8529999852180481, 0.8556666374206543, 0.8556666374206543, 0.8586666584014893, 0.8526666760444641, 0.8576666712760925, 0.8610000014305115, 0.859000027179718, 0.8616666793823242, 0.8653333187103271, 0.8673333525657654, 0.8673333525657654, 0.8659999966621399, 0.8693333268165588, 0.8690000176429749, 0.8726666569709778, 0.8726666569709778, 0.8740000128746033, 0.8730000257492065, 0.871999979019165, 0.8759999871253967, 0.874666690826416, 0.871999979019165, 0.8806666731834412, 0.8776666522026062, 0.8706666827201843, 0.8820000290870667, 0.878333330154419, 0.878000020980835, 0.8806666731834412, 0.8793333172798157, 0.878333330154419]}, "mapping_values": [1, 9, 5, 4, 2, 10, 6, 4, 2, 2, 1, 1, 1, 21, 11, 10, 6], "tree_depth": 18}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 0, 2], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 3, 3, 6, 8, 1, 4, 1, 4, 2, 8], [0, 0, 0, 3, 0, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.8482857346534729, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), grad))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma))), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), tf.math.add(tf.math.sqrt(beta), tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32)))", "other_info": {"loss": [2.22167706489563, 1.8606246709823608, 1.381543755531311, 1.080888032913208, 0.9303297400474548, 0.8318873643875122, 0.7687501311302185, 0.722256600856781, 0.6851663589477539, 0.6559861302375793, 0.6308757662773132, 0.6105526685714722, 0.5879340171813965, 0.5688386559486389, 0.5587790608406067, 0.5391172170639038, 0.528182864189148, 0.5162765979766846, 0.5035620331764221, 0.4991503059864044, 0.4929787218570709, 0.4734407365322113, 0.46772411465644836, 0.4585813581943512, 0.44825977087020874, 0.4395873546600342, 0.43765661120414734, 0.42857563495635986, 0.42148664593696594, 0.4102593660354614, 0.4095189571380615, 0.403943806886673, 0.40106886625289917, 0.39402174949645996, 0.3856483995914459, 0.3801901638507843, 0.3738064765930176, 0.365608811378479, 0.3754698634147644, 0.36635592579841614, 0.3545590043067932, 0.351645290851593, 0.3455052375793457, 0.3489551246166229, 0.34359756112098694, 0.3392859399318695, 0.3217741847038269, 0.3220372498035431, 0.3165372908115387, 0.3171999156475067], "accuracy": [0.27222296595573425, 0.4912164807319641, 0.5683529376983643, 0.6196011304855347, 0.6690001487731934, 0.6997754573822021, 0.7257958054542542, 0.7375511527061462, 0.7495707273483276, 0.7592127919197083, 0.7656848430633545, 0.778761088848114, 0.7829877138137817, 0.7886672616004944, 0.7972526550292969, 0.8082155585289001, 0.8109893202781677, 0.8171972036361694, 0.8232730031013489, 0.8272355198860168, 0.8238013386726379, 0.8274996876716614, 0.8293488025665283, 0.8363492488861084, 0.8422929644584656, 0.8449346423149109, 0.8442742228507996, 0.8473120927810669, 0.8494254350662231, 0.8565579056739807, 0.854708731174469, 0.8569541573524475, 0.8576145768165588, 0.8590674996376038, 0.8640866279602051, 0.8676528930664062, 0.86553955078125, 0.8697662353515625, 0.8661999702453613, 0.8669924736022949, 0.8720116019248962, 0.8704266548156738, 0.8742570281028748, 0.8750495314598083, 0.8721436858177185, 0.8747853636741638, 0.8837670087814331, 0.8812574148178101, 0.8840311765670776, 0.8790120482444763], "val_loss": [2.0381064414978027, 1.5103408098220825, 1.0408698320388794, 0.8401956558227539, 0.7554631233215332, 0.7036611437797546, 0.6596428155899048, 0.6287024617195129, 0.6044614911079407, 0.5840694308280945, 0.5688208937644958, 0.5504533052444458, 0.531732976436615, 0.5215092301368713, 0.5111705660820007, 0.5037232041358948, 0.4961789846420288, 0.48840054869651794, 0.48602354526519775, 0.4743761420249939, 0.46562281250953674, 0.4584217965602875, 0.45320239663124084, 0.44924601912498474, 0.4452739655971527, 0.4389966130256653, 0.4361697733402252, 0.4276525378227234, 0.43228304386138916, 0.4199095070362091, 0.4202253520488739, 0.4181778132915497, 0.4111804664134979, 0.40848734974861145, 0.4042399525642395, 0.40644311904907227, 0.3981805741786957, 0.39628252387046814, 0.40090617537498474, 0.3888489603996277, 0.3882131278514862, 0.3851148188114166, 0.3841511905193329, 0.378084272146225, 0.3816499710083008, 0.38161975145339966, 0.37644392251968384, 0.3764704167842865, 0.38262492418289185, 0.371069997549057], "val_accuracy": [0.5806666612625122, 0.6603333353996277, 0.6826666593551636, 0.703000009059906, 0.7300000190734863, 0.7476666569709778, 0.7593333125114441, 0.7713333368301392, 0.7770000100135803, 0.7833333611488342, 0.7963333129882812, 0.7896666526794434, 0.8053333163261414, 0.8086666464805603, 0.8169999718666077, 0.815666675567627, 0.8149999976158142, 0.8190000057220459, 0.8213333487510681, 0.82833331823349, 0.8293333053588867, 0.8363333344459534, 0.8306666612625122, 0.8396666646003723, 0.8343333601951599, 0.8420000076293945, 0.8403333425521851, 0.8416666388511658, 0.8393333554267883, 0.843999981880188, 0.8500000238418579, 0.8506666421890259, 0.8513333201408386, 0.8463333249092102, 0.8516666889190674, 0.8506666421890259, 0.8489999771118164, 0.8539999723434448, 0.8546666502952576, 0.8583333492279053, 0.8556666374206543, 0.8603333234786987, 0.8600000143051147, 0.8636666536331177, 0.8643333315849304, 0.862333357334137, 0.8643333315849304, 0.8643333315849304, 0.8603333234786987, 0.8633333444595337]}, "mapping_values": [1, 9, 5, 4, 2, 10, 6, 4, 2, 2, 1, 1, 1, 21, 11, 10, 6], "tree_depth": 18}, {"genotype": [[0], [0, 0, 0, 0, 0, 1, 0, 1, 1], [0, 9, 3, 0, 0], [0, 1, 0, 2], [60, 39], [0, 0, 0, 1, 1, 1, 0, 0, 0, 1], [8, 2, 3, 4, 3, 5], [0, 2, 0, 3], [16, 16], [1, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1], [4, 3, 3, 6, 6, 1, 4, 1, 4, 0, 8, 5, 4], [0, 0, 0, 2, 0, 0, 3, 1, 2, 0, 2], [16, 25, 96, 99, 61, 1]], "fitness": -0.10000000149011612, "mapping_values": [1, 2, 2, 0, 1, 6, 3, 3, 2, 1, 0, 1, 1, 24, 13, 11, 6], "tree_depth": 20, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.constant(8.92947854e-01, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, grad: tf.math.sqrt(tf.math.add(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), beta), tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32))), lambda shape,  alpha, beta, sigma, grad: tf.constant(1.0, shape=shape, dtype=tf.float32), lambda shape,  alpha, beta, sigma, grad: tf.math.pow(tf.math.multiply(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.divide_no_nan(tf.math.subtract(tf.constant(7.03711536e-03, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), beta)), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.math.negative(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32)), sigma))), tf.math.sqrt(tf.math.square(alpha)))), beta), tf.math.pow(tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32), beta))", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.09628847241401672, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.09733333438634872, 0.09733333438634872, 0.09733333438634872, 0.09733333438634872, 0.09733333438634872, 0.09733333438634872]}}, {"genotype": [[0], [0, 0, 0, 0, 1, 1, 0, 1, 1], [0, 2, 3, 0, 3], [0, 1, 2, 2], [39, 39], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [98, 16], [0, 1], [0], [4], [89], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1], [6, 6, 3, 6, 8, 1, 4, 1, 4, 2, 8], [4, 0, 0, 3, 2, 0, 3, 1, 2, 4], [16, 99, 96, 99, 61, 1]], "fitness": -0.10000000149011612, "mapping_values": [1, 9, 5, 4, 1, 10, 6, 4, 2, 2, 1, 1, 0, 18, 9, 9, 3], "tree_depth": 18, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32)), alpha), tf.math.multiply(grad, grad))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(9.99944439e-01, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(grad), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.divide_no_nan(tf.math.multiply(grad, tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(1.0, shape=shape, dtype=tf.float32), sigma))), tf.math.subtract(beta, tf.math.pow(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma)))), alpha), beta)", "other_info": {"loss": [NaN, NaN, NaN, NaN, NaN, NaN], "accuracy": [0.09734513610601425, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777, 0.09998679161071777], "val_loss": [NaN, NaN, NaN, NaN, NaN, NaN], "val_accuracy": [0.10100000351667404, 0.10100000351667404, 0.10100000351667404, 0.10100000351667404, 0.10100000351667404, 0.10100000351667404]}}, {"genotype": [[0], [1, 0, 1, 1, 1, 0, 0, 1, 1], [0, 2, 3, 2, 3], [0, 1, 0, 2], [39, 39], [1, 0, 0, 0, 1, 1, 1, 1, 0, 1], [0, 2, 3, 0, 3, 5], [3, 2, 0, 3], [16, 16], [0, 1], [5], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1], [6, 2, 3, 6, 8, 1, 9, 4, 4, 2, 8], [0, 0, 0, 4, 0, 0, 3, 1, 2, 0], [16, 99, 96, 99, 61, 1]], "fitness": -0.09228571504354477, "mapping_values": [1, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 16, 9, 7, 6], "tree_depth": 16, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), lambda shape,  alpha, beta, grad: grad, lambda shape,  alpha, beta, sigma, grad: tf.math.square(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.add(tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.sqrt(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32))), tf.constant(1.0, shape=shape, dtype=tf.float32))), grad), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(5.55606489e-05, shape=shape, dtype=tf.float32), sigma)))", "other_info": {"loss": [2.3089587688446045, 2.309307813644409, 2.309265375137329, 2.3101978302001953, 2.309816360473633, 2.310035467147827], "accuracy": [0.08902391046285629, 0.09153348207473755, 0.09774138033390045, 0.09047681838274002, 0.09285431355237961, 0.09074098616838455], "val_loss": [2.309359312057495, 2.309359312057495, 2.309359312057495, 2.309359312057495, 2.309359312057495, 2.309359312057495], "val_accuracy": [0.08866667002439499, 0.08866667002439499, 0.08866667002439499, 0.08866667002439499, 0.08866667002439499, 0.08866667002439499]}}, {"genotype": [[0], [0, 0, 1, 0, 1, 1, 0, 1, 0], [0, 6, 3, 0, 3], [0, 1, 0, 2], [39, 4], [0, 0, 0, 0, 1, 1, 0, 1, 0, 1], [0, 2, 3, 0, 3, 5], [0, 2, 0, 3], [16, 16], [0, 1], [0], [0], [99], [0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1], [6, 3, 4, 6, 6, 1, 3, 1, 4, 2, 8, 6], [0, 0, 0, 3, 0, 0, 3, 1, 2, 1, 7, 1], [28, 99, 96, 99, 61, 1]], "fitness": -0.08828571438789368, "mapping_values": [1, 6, 3, 3, 2, 10, 6, 4, 2, 2, 1, 1, 1, 24, 12, 12, 5], "tree_depth": 18, "phenotype": "alpha_func, beta_func, sigma_func, grad_func = lambda shape,  alpha, grad: tf.math.negative(tf.math.divide_no_nan(tf.constant(1.07052146e-01, shape=shape, dtype=tf.float32), tf.math.multiply(alpha, tf.constant(1.01848815e-04, shape=shape, dtype=tf.float32)))), lambda shape,  alpha, beta, grad: tf.math.negative(tf.math.add(tf.math.multiply(tf.math.negative(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32)), beta), tf.math.multiply(tf.constant(1.14904229e-03, shape=shape, dtype=tf.float32), tf.math.square(grad)))), lambda shape,  alpha, beta, sigma, grad: tf.math.negative(tf.constant(1.0, shape=shape, dtype=tf.float32)), lambda shape,  alpha, beta, sigma, grad: tf.math.divide_no_nan(tf.math.multiply(tf.math.pow(tf.constant(1.28252101e-02, shape=shape, dtype=tf.float32), tf.math.divide_no_nan(tf.math.divide_no_nan(tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.multiply(tf.constant(9.99916780e-01, shape=shape, dtype=tf.float32), sigma)), tf.math.subtract(tf.constant(1.0, shape=shape, dtype=tf.float32), tf.math.pow(tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32), sigma))), alpha)), tf.math.add(tf.math.sqrt(tf.math.divide_no_nan(beta, alpha)), grad)), alpha)", "other_info": {"loss": [2.309910774230957, 2.3093082904815674, 2.310304880142212, 2.3089797496795654, 2.3097481727600098, 2.3087449073791504], "accuracy": [0.08506141602993011, 0.09034473448991776, 0.09325055778026581, 0.08942015469074249, 0.09642054885625839, 0.0956280529499054], "val_loss": [2.308351755142212, 2.308351755142212, 2.308351755142212, 2.308351755142212, 2.308351755142212, 2.308351755142212], "val_accuracy": [0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186, 0.09300000220537186]}}]