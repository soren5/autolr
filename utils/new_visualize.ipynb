{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS IS A LAYER TYPE GRAMMAR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['alpha_func, beta_func, sigma_func, grad_func = ',\n",
       " ', grad: subtract(grad, divide_no_nan(subtract(add(grad, multiply(is_dense, units)), grad), constant(9.10782940e-01))), ',\n",
       " ', beta, grad: add(multiply(grad, multiply(is_dense, units)), pow(layer_count, multiply(is_conv, kernel_size))), ',\n",
       " ', beta, sigma, grad: grad, ',\n",
       " ', beta, sigma, grad: divide_no_nan(sigma, add(divide_no_nan(constant(9.95290886e-01), add(negative(constant(1.24647146e-04)), multiply(multiply(is_pool, pool_size), sqrt(subtract(sigma, pow(beta, add(constant(9.38616893e-01), multiply(layer_num, square(layer_count))))))))), beta))']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from visualization_tools import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "params = {\"GRAMMAR\": 'architecture_layer_type'}\n",
    "def trim_phenotype(phenotype):\n",
    "    if \"shape\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", shape=shape, dtype=tf.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.math.\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.\", \"\")\n",
    "        if 'architecture_layer_type' in params['GRAMMAR']:\n",
    "            print(\"THIS IS A LAYER TYPE GRAMMAR\")\n",
    "            functions = phenotype.split(r'lambda is_dense, units, is_pool, pool_size, is_conv, kernel_size, filters, stride, layer_count, layer_num, shape, alpha')\n",
    "        elif 'architecture' in params['GRAMMAR']:\n",
    "            print(\"THIS IS AN ARCHITECTURAL GRAMMAR\")\n",
    "            functions = phenotype.split(r'lambda layer_count, layer_num, shape, alpha')\n",
    "        else:\n",
    "            print(\"THIS IS NOT AN ARCHITECTURAL GRAMMAR\")\n",
    "            functions = phenotype.split(r'lambda shape, alpha')\n",
    "\n",
    "    elif \"size\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", size=size, dtype=torch.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"torch.\", \"\")        \n",
    "        functions = phenotype.split(r'lambda size, alpha')\n",
    "    \n",
    "    #else:\n",
    "    #    raise Exception()\n",
    "\n",
    "    return functions \n",
    "def make_latex(string):\n",
    "    string.replace()\n",
    "phen = \"alpha_func, beta_func, sigma_func, grad_func = lambda is_dense, units, is_pool, pool_size, is_conv, kernel_size, filters, stride, layer_count, layer_num, shape, alpha, grad: tf.math.subtract(grad, tf.math.divide_no_nan(tf.math.subtract(tf.math.add(grad, tf.math.multiply(is_dense, units)), grad), tf.constant(9.10782940e-01, shape=shape, dtype=tf.float32))), lambda is_dense, units, is_pool, pool_size, is_conv, kernel_size, filters, stride, layer_count, layer_num, shape, alpha, beta, grad: tf.math.add(tf.math.multiply(grad, tf.math.multiply(is_dense, units)), tf.math.pow(layer_count, tf.math.multiply(is_conv, kernel_size))), lambda is_dense, units, is_pool, pool_size, is_conv, kernel_size, filters, stride, layer_count, layer_num, shape, alpha, beta, sigma, grad: grad, lambda is_dense, units, is_pool, pool_size, is_conv, kernel_size, filters, stride, layer_count, layer_num, shape, alpha, beta, sigma, grad: tf.math.divide_no_nan(sigma, tf.math.add(tf.math.divide_no_nan(tf.constant(9.95290886e-01, shape=shape, dtype=tf.float32), tf.math.add(tf.math.negative(tf.constant(1.24647146e-04, shape=shape, dtype=tf.float32)), tf.math.multiply(tf.math.multiply(is_pool, pool_size), tf.math.sqrt(tf.math.subtract(sigma, tf.math.pow(beta, tf.math.add(tf.constant(9.38616893e-01, shape=shape, dtype=tf.float32), tf.math.multiply(layer_num, tf.math.square(layer_count))))))))), beta))\"\n",
    "trim_phenotype(phen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfolder = \"C:\\\\Users\\\\lamec\\\\WORK\\\\journal\\\\tensorflow\"\\nnew_folder = \"C:\\\\Users\\\\lamec\\\\WORK\\\\journal\\\\SMX\"\\njson_files, experiment_names, run_numbers = get_all_json_files(folder)\\nchunk_size = 200\\n\\nchunks = [json_files[i:i + chunk_size] for i in range(0, len(json_files), chunk_size)]\\n\\ncombined_data = []\\n\\nfor i, chunk in enumerate(chunks):\\n    for j, file_path in enumerate(chunk):\\n        experiment_name = experiment_names[i * chunk_size + j]\\n        run_number = run_numbers[i * chunk_size + j]\\n        #extract_second_json(file_path, file_path.replace(folder, new_folder))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "folder = \"C:\\\\Users\\\\lamec\\\\WORK\\\\journal\\\\tensorflow\"\n",
    "new_folder = \"C:\\\\Users\\\\lamec\\\\WORK\\\\journal\\\\SMX\"\n",
    "json_files, experiment_names, run_numbers = get_all_json_files(folder)\n",
    "chunk_size = 200\n",
    "\n",
    "chunks = [json_files[i:i + chunk_size] for i in range(0, len(json_files), chunk_size)]\n",
    "\n",
    "combined_data = []\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    for j, file_path in enumerate(chunk):\n",
    "        experiment_name = experiment_names[i * chunk_size + j]\n",
    "        run_number = run_numbers[i * chunk_size + j]\n",
    "        #extract_second_json(file_path, file_path.replace(folder, new_folder))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamec\\WORK\\autolr\\results\\arch_optimizers_results\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#run_number = range(5)\n",
    "run_number = [5]\n",
    "task = \"tensorflow\"\n",
    "folder = \"C:\\\\Users\\\\lamec\\\\WORK\\\\autolr\\\\results\\\\arch_optimizers_results\"\n",
    "#folder = '~/autolr/dumps/evolutionary_optimization'\n",
    "\n",
    "# Create the DataFrame with specified columns and data types\n",
    "df = pd.DataFrame({\n",
    "    'Experiment name': pd.Series(dtype='string'),\n",
    "    'Run number': pd.Series(dtype='string'),\n",
    "    'Individual number': pd.Series(dtype='int64'),\n",
    "    'Phenotype': pd.Series(dtype='string'),\n",
    "    'Smart Phenotype': pd.Series(dtype='string'),\n",
    "    'Fitness': pd.Series(dtype='float64')\n",
    "})\n",
    "\n",
    "\n",
    "df = load_results(folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Experiment name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you already have the DataFrame, let's call it 'df'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Group by 'Experiment name' and 'Run number', then count the entries in each group\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m individual_counts \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExperiment name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRun number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndividual number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;241m.\u001b[39mreset_index(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnique Individual Count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFitness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m individual_counts\n",
      "File \u001b[1;32mc:\\Users\\lamec\\anaconda3\\envs\\sge\\lib\\site-packages\\pandas\\core\\frame.py:7631\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   7627\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   7629\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   7630\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> 7631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   7632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7634\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7639\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   7642\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lamec\\anaconda3\\envs\\sge\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:889\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 889\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\lamec\\anaconda3\\envs\\sge\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:862\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    860\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    865\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Experiment name'"
     ]
    }
   ],
   "source": [
    " # Assuming you already have the DataFrame, let's call it 'df'\n",
    "\n",
    "# Group by 'Experiment name' and 'Run number', then count the entries in each group\n",
    "individual_counts = df.groupby(['Experiment name', 'Run number'])['Individual number'].nunique().reset_index(name='Unique Individual Count')\n",
    "df['Fitness'] = df['Fitness'] * -1\n",
    "individual_counts\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'Generation', 'Fitness', 'Experiment name', and 'Run number'\n",
    "\n",
    "# Step 1: Group by 'Experiment name', 'Run number', and 'Generation', and compute the mean and max fitness for each group\n",
    "fitness_data = df.groupby(['Experiment name', 'Run number', 'Generation'])['Fitness'].agg(['mean', 'max']).reset_index()\n",
    "\n",
    "# Step 2: Group by 'Generation' and compute the overall mean and max fitness for each generation\n",
    "generation_stats = fitness_data.groupby('Generation').agg({'mean': 'mean', 'max': 'mean', 'Run number': 'nunique'}).reset_index()\n",
    "generation_stats.rename(columns={'Run number': 'Unique Runs'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate highest and lowest fitness across all runs per generation from the max fitness data\n",
    "highest_fitness = fitness_data.groupby('Generation')['max'].max().reset_index()\n",
    "lowest_fitness = fitness_data.groupby('Generation')['max'].min().reset_index()\n",
    "\n",
    "# Step 4: Plot the average fitness, best fitness, and the shadow for the range between highest and lowest fitness\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot average fitness on the first y-axis\n",
    "ax1.plot(generation_stats['Generation'], generation_stats['mean'], marker='o', linestyle='-', color='b', label='Average Fitness')\n",
    "ax1.plot(generation_stats['Generation'], generation_stats['max'], marker='s', linestyle='-', color='g', label='Best Fitness')\n",
    "ax1.fill_between(generation_stats['Generation'], lowest_fitness['max'], highest_fitness['max'], alpha=0.3, color='g')\n",
    "\n",
    "ax1.set_xlabel('Generation')\n",
    "ax1.set_ylabel('Fitness')\n",
    "ax1.set_title('Fitness Across Generations')\n",
    "\n",
    "# Create a secondary y-axis for the histogram\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot transparent histogram for unique runs on the secondary y-axis\n",
    "ax2.hist(generation_stats['Generation'], bins=len(generation_stats), alpha=0.3, color='gray', edgecolor='black',\n",
    "         weights=generation_stats['Unique Runs'], label='Unique Runs')\n",
    "ax2.set_ylabel('Unique Runs')\n",
    "\n",
    "# Combine the legends from both y-axes\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 100]\n",
    "# Assuming you have a DataFrame 'df' with columns 'Generation', 'Fitness', 'Experiment name', and 'Run number'\n",
    "\n",
    "# Step 1: Group by 'Experiment name', 'Run number', and 'Generation', and compute the mean and max fitness for each group\n",
    "#fitness_data = df.groupby(['Experiment name', 'Run number', 'Generation'])['Fitness'].agg(['mean', 'max']).reset_index()\n",
    "\n",
    "# Step 2: Group by 'Generation' and compute the overall mean and max fitness for each generation\n",
    "#generation_stats = fitness_data.groupby(['Experiment name', 'Generation']).agg({'mean': 'mean', 'max': 'mean', 'Run number': 'nunique'}).reset_index()\n",
    "#generation_stats.rename(columns={'Run number': 'Unique Runs'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate highest and lowest fitness across all runs per generation from the max fitness data\n",
    "#highest_fitness = fitness_data.groupby(['Experiment name', 'Generation'])['max'].max().reset_index()\n",
    "#lowest_fitness = fitness_data.groupby(['Experiment name', 'Generation'])['max'].min().reset_index()\n",
    "\n",
    "# Step 4: Create subplots for each experiment with a shared y-axis\n",
    "experiment_names = df['Experiment name'].unique()\n",
    "fig, axs = plt.subplots(len(experiment_names), figsize=(20, 20), sharey=True)  # sharey=True ensures shared y-axis\n",
    "\n",
    "for i, experiment_name in enumerate(experiment_names):\n",
    "    df_i = df[df['Experiment name'] == experiment_name]\n",
    "    ax = axs[i]\n",
    "\n",
    "    mean_fitness_generation = df_i.groupby(['Generation']).agg({'Fitness': 'mean'}).reset_index()\n",
    "    max_fitness_generation = df_i.groupby(['Generation']).agg({'Fitness': 'max'}).reset_index()\n",
    "    count_runs_generation = df_i.groupby(['Generation']).agg({'Run number': 'count'}).reset_index()\n",
    "    # Plot average fitness on the first y-axis\n",
    "    ax.plot(mean_fitness_generation['Generation'], mean_fitness_generation['Fitness'], marker='o', linestyle='-', color='b', label='Average Fitness')\n",
    "    ax.plot(max_fitness_generation['Generation'], max_fitness_generation['Fitness'], marker='s', linestyle='-', color='g', label='Best Fitness')\n",
    "    #ax.fill_between(experiment_data['Generation'], experiment_lowest['max'], experiment_highest['max'], alpha=0.3, color='g')\n",
    "    \n",
    "    ax.set_xlabel('Generation')\n",
    "    ax.set_ylabel('Fitness')\n",
    "    ax.set_title(f'Fitness Across Generations - Experiment: {experiment_name}')\n",
    "    \n",
    "    # Create a secondary y-axis for the histogram\n",
    "    ax2 = ax.twinx()\n",
    "    \n",
    "    # Plot transparent histogram for unique runs on the secondary y-axis\n",
    "    ax2.hist(count_runs_generation['Generation'], bins=len(count_runs_generation), alpha=0.3, color='gray', edgecolor='black',\n",
    "             weights=count_runs_generation['Run number'], label='Unique Runs')\n",
    "    ax2.set_ylabel('Unique Runs')\n",
    "    \n",
    "    # Combine the legends from both y-axes\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "df_mean_fitness = df.groupby(['Experiment name', 'Run number']).agg({'Generation': 'max'}).reset_index()\n",
    "\n",
    "last_gen_stats = {'Experiment name': [], \"Fitness\": [], \"Generation\": []}\n",
    "for i, data in df_mean_fitness.iterrows():\n",
    "    #print(data)\n",
    "    last_gen_stats['Experiment name'].append(data['Experiment name'])\n",
    "    last_gen_stats['Fitness'].append(np.mean(df[(df['Generation'] == data['Generation']) & (df['Experiment name'] == data['Experiment name']) & (df['Run number'] == data['Run number'])]['Fitness']))\n",
    "    last_gen_stats['Generation'].append(data['Generation'])\n",
    "\n",
    "df_mean_fitness = pd.DataFrame(last_gen_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Create a box plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Use seaborn to create a box plot, specifying 'x' as 'Experiment name' and 'y' as 'Fitness'\n",
    "sns.boxplot(data=df_mean_fitness, x='Experiment name', y='Fitness')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Population Fitness per Experiment')\n",
    "plt.xlabel('Experiment Name')\n",
    "plt.ylabel('Population Fitness')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Set custom y-axis limits (adjust these values as needed)\n",
    "#plt.ylim(0.8, 0.93)  # Example: set the y-axis limits from 0 to 100\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for i, experiment_name in enumerate(experiment_names):\n",
    "    df_i = df_mean_fitness[df_mean_fitness['Experiment name'] == experiment_name]\n",
    "    print(f\"Experiment: {experiment_name} {np.mean(df_i['Fitness'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with columns 'Experiment name', 'Run number', and 'Fitness'\n",
    "df_max_fitness = df.groupby(['Experiment name', 'Run number']).agg({'Fitness': 'max'}).reset_index()\n",
    "print(df_max_fitness.head(5))\n",
    "# Step 1: Create a box plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Use seaborn to create a box plot, specifying 'x' as 'Experiment name' and 'y' as 'Fitness'\n",
    "sns.boxplot(data=df_max_fitness, x='Experiment name', y='Fitness')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Max Fitness per Experiment')\n",
    "plt.xlabel('Experiment Name')\n",
    "plt.ylabel('Max Fitness')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Set custom y-axis limits (adjust these values as needed)\n",
    "plt.ylim(0.8, 0.93)  # Example: set the y-axis limits from 0 to 100\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for i, experiment_name in enumerate(experiment_names):\n",
    "    df_i = df_max_fitness[df_max_fitness['Experiment name'] == experiment_name]\n",
    "    print(f\"Experiment: {experiment_name} Mean: {np.mean(df_i['Fitness'])} Max: {np.max(df_i['Fitness'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame 'df' with columns 'Experiment name', 'Run number', and 'Fitness'\n",
    "df_unique_evals = df[df['Fitness'] >= 0.11].groupby(['Experiment name', 'Run number']).agg({'Smart Phenotype': 'nunique'}).reset_index()\n",
    "print(df_unique_evals.head(5))\n",
    "# Step 1: Create a box plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Use seaborn to create a box plot, specifying 'x' as 'Experiment name' and 'y' as 'Fitness'\n",
    "sns.boxplot(data=df_unique_evals, x='Experiment name', y='Smart Phenotype')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Unique Evaluations per Experiment')\n",
    "plt.xlabel('Experiment Name')\n",
    "plt.ylabel('Unique Evaluations')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Set custom y-axis limits (adjust these values as needed)\n",
    "#plt.ylim(0.8, 0.93)  # Example: set the y-axis limits from 0 to 100\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#for i, experiment_name in enumerate(experiment_names):\n",
    "    #df_i = df_max_fitness[df_max_fitness['Experiment name'] == experiment_name]\n",
    "    #print(f\"{experiment_name} {np.mean(df_i['Fitness'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame 'df' with columns 'Experiment name', 'Run number', and 'Fitness'\n",
    "df_unique_evals = df[df['Fitness'] >= 0.5].groupby(['Experiment name', 'Run number']).agg({'Smart Phenotype': 'nunique'}).reset_index()\n",
    "print(df_unique_evals.head(5))\n",
    "# Step 1: Create a box plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Use seaborn to create a box plot, specifying 'x' as 'Experiment name' and 'y' as 'Fitness'\n",
    "sns.boxplot(data=df_unique_evals, x='Experiment name', y='Smart Phenotype')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Unique Evaluations (80+ Accuracy) per Experiment')\n",
    "plt.xlabel('Experiment Name')\n",
    "plt.ylabel('Unique Evaluations')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Set custom y-axis limits (adjust these values as needed)\n",
    "#plt.ylim(0.8, 0.93)  # Example: set the y-axis limits from 0 to 100\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for i, experiment_name in enumerate(experiment_names):\n",
    "    df_i = df_unique_evals[df_unique_evals['Experiment name'] == experiment_name]\n",
    "    print(f\"{experiment_name} {np.mean(df_i['Smart Phenotype'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a box plot\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "\n",
    "# Use seaborn to create a box plot, specifying 'x' as 'Experiment name' and 'y' as 'Fitness'\n",
    "sns.boxplot(data=df_mean_fitness, x='Experiment name', y='Generation')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Generations (in 4 hours) per Experiment')\n",
    "plt.xlabel('Experiment Name')\n",
    "plt.ylabel('Generations')\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Set custom y-axis limits (adjust these values as needed)\n",
    "#plt.ylim(0.8, 0.93)  # Example: set the y-axis limits from 0 to 100\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "for i, experiment_name in enumerate(experiment_names):\n",
    "    df_i = df_mean_fitness[df_unique_evals['Experiment name'] == experiment_name]\n",
    "    print(f\"{experiment_name} {np.mean(df_i['Generation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_results(results, run_number=run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, rows = (40, 10)\n",
    "plt.rcParams['figure.figsize'] = [columns, rows]\n",
    "plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])\n",
    "\n",
    "fit_floor = 0.0\n",
    "fit_ceil = 1.0\n",
    "gen_floor = 0.0\n",
    "gen_ceil = float(len(data['epochs']))\n",
    "pop_density_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list = []\n",
    "for i in run_number: \n",
    "    it = 1 \n",
    "    try:\n",
    "        while True:\n",
    "            archive = load_archive(path, i, it)\n",
    "            it += 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f\"loading archive {it - 1} for run {i}\")\n",
    "        archive = load_archive(path, i, it - 1)\n",
    "        for x in archive:\n",
    "            if 'fitness' in archive[x]:\n",
    "                archive_list.append([x, archive[x], archive[x]['fitness'], i])\n",
    "    except:\n",
    "        print(f\"Run {i} has no archive\")\n",
    "archive_list.sort(key=lambda x : x[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(archive_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "while it < 10:\n",
    "    print(archive_list[it])\n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def turn_to_expr(phenotype, tree):\n",
    "    if phenotype == \"\":\n",
    "        return tree\n",
    "    \n",
    "    if phenotype[0:9] == \"multiply(\":\n",
    "        #print(\"multiply\")\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"*\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:14] == \"divide_no_nan(\":\n",
    "        phenotype = phenotype[14:]\n",
    "        node = Node(\"/\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"add(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"+\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"pow(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"^\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"subtract(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"grad\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"grad\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"beta\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"beta\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"alpha\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"alpha\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sigma\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sigma\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"negative(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sqrt(\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sqrt\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:7] == \"square(\":\n",
    "        phenotype = phenotype[7:]\n",
    "        node = Node(\"square\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:2] == \", \":\n",
    "        phenotype = phenotype[2:]\n",
    "        return turn_to_expr(phenotype, tree)     \n",
    "    elif phenotype[0] == \")\":\n",
    "        phenotype = phenotype[1:]\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"constant(\":\n",
    "        if phenotype[9:12] == \"0.0\" or phenotype[9:13] == \"1.0)\" or phenotype[9:13] == \"1.0,\":\n",
    "            node = Node(phenotype[9:12], tree, 0)\n",
    "            phenotype = phenotype[12:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()           \n",
    "        else:\n",
    "            node = Node(phenotype[9:9+14], tree, 0)\n",
    "            phenotype = phenotype[9+14:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    else:\n",
    "        raise Exception(phenotype)\n",
    "        \n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string =functions[2][14:-2] \n",
    "    sigma_func_string =functions[3][21:-2] \n",
    "    grad_func_string = functions[-1][21:]\n",
    "    \n",
    "    for x in [alpha_func_string, beta_func_string, sigma_func_string, grad_func_string]:\n",
    "        print(x)    \n",
    "        turn_to_expr(x, Node(\"\", None, 1)).to_string()\n",
    "\n",
    "    return grad_func_string\n",
    "\n",
    "for indiv in data['indivs']:\n",
    "    math_phenotype(indiv['phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"multiply(\"\n",
    "print(a[0:9])\n",
    "print(a[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import csv\n",
    "from pickle import NONE\n",
    "from utils.data_functions import load_fashion_mnist_training, load_cifar10_training, load_mnist_training, select_fashion_mnist_training\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from optimizers.custom_optimizer import CustomOptimizer\n",
    "import datetime\n",
    "experiment_time = datetime.datetime.now()\n",
    "\n",
    "cached_dataset = None\n",
    "cached_model = None\n",
    "\n",
    "def train_model_tensorflow_cifar10(phen_params):\n",
    "    phen, params = phen_params\n",
    "    validation_size = params['VALIDATION_SIZE']\n",
    "    fitness_size =params['FITNESS_SIZE'] \n",
    "    batch_size = params['BATCH_SIZE']\n",
    "    epochs = params['EPOCHS']\n",
    "    patience = params['PATIENCE']\n",
    "\n",
    "    # Note that globals are borderline -- consider an object or a closure \n",
    "    # deliberately using globals() to make it ugly...\n",
    "    if globals()['cached_dataset'] == None:\n",
    "        globals()['cached_dataset'] = load_cifar10_training(validation_size=validation_size, test_size=fitness_size)\n",
    "    \n",
    "    if globals()['cached_model'] == None:\n",
    "        globals()['cached_model'] = load_model(params['MODEL'], compile=False)\n",
    "        \n",
    "    # we assume validation and test sets are deterministic\n",
    "    dataset = globals()['cached_dataset'] \n",
    "    model = tf.keras.models.clone_model(globals()['cached_model'])\n",
    "\n",
    "    weights = model.get_weights()\n",
    "    model.set_weights(weights)  \n",
    "\n",
    "    # optimizer is constant aslong as phen doesn't changed?\n",
    "    # -> opportunity to cache opt and compiled model\n",
    "    opt = CustomOptimizer(phen=phen, model=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    score = model.fit(dataset['x_train'], dataset['y_train'],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "        validation_steps= validation_size // batch_size,\n",
    "        callbacks=[\n",
    "            early_stop\n",
    "        ])\n",
    "\n",
    "    K.clear_session()\n",
    "    results = {}\n",
    "    for metric in score.history:\n",
    "        results[metric] = []\n",
    "        for n in score.history[metric]:\n",
    "            results[metric].append(n)\n",
    "    test_score = model.evaluate(x=dataset['x_test'],y=dataset[\"y_test\"], verbose=0, callbacks=[keras.callbacks.History()])\n",
    "    return test_score[-1], results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
