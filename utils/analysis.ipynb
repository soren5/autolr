{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import packages and set image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import platform\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['figure.figsize'] = [10,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this function reads results from 1 specific run for N iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_experiment_results(full_path, iterations):\n",
    "    results = []\n",
    "    for it in range(iterations):\n",
    "        filename = Path(os.path.join(full_path, ('iteration_' + str(it) + '.json')))\n",
    "        if(filename.is_file()):\n",
    "            with open(filename) as json_file:\n",
    "                if it % 10 == 0:\n",
    "                    print(it)\n",
    "                data = json.load(json_file)\n",
    "                results.append(data)\n",
    "        else:\n",
    "            print(\"Iteration \"+ str(it) + \" filename: \" + str(filename) + \" ->> Is missing\")\n",
    "    print(\"Finished reading \", full_path)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell you choose which folder to use to read the runs' results from (made it so it is system agnostic).\n",
    "\n",
    "It is necessary to:\n",
    "1. set the folder in result_folde_path_from_root as a list of all the folders starting from the root down to the one containing the runs\n",
    "2. set the number of runs to analyze as a range between 1 and N where n is the number of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = range(1,16)\n",
    "iterations = 100\n",
    "os_string = platform.system()\n",
    "result_folder_path_from_root = os.path.join(\"many_runs\",\"cif\")\n",
    "results = []\n",
    "path = os.path.join(os.path.dirname(os.path.abspath(os.curdir)), result_folder_path_from_root) \n",
    "print(path)\n",
    "\n",
    "for i in run_number: \n",
    "  file_path = os.path.join(path, \"run_\" + str(i))\n",
    "  results.append(read_experiment_results(file_path, iterations))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell finds and prints the best performing phenotypes across generation and across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 1\n",
    "it = 0\n",
    "best_indivs = {}\n",
    "averages = []\n",
    "best_indiv = None\n",
    "for generation in results[0]:\n",
    "    new_best = False \n",
    "    total_fits = 0\n",
    "    for indiv in generation:\n",
    "        total_fits += indiv[\"fitness\"]\n",
    "        if indiv[\"fitness\"] < best:\n",
    "            best = indiv[\"fitness\"]\n",
    "            best_indiv = indiv\n",
    "            best_indivs[it] = indiv\n",
    "            new_best = True\n",
    "    averages.append(total_fits/len(generation))\n",
    "    if new_best:\n",
    "        print(f\"[{it}] New Best: {best} {best_indiv['smart_phenotype']}\")\n",
    "    it += 1\n",
    "print(best_indiv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess this cell is used to execute the bayesian optimization of a given optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_constants_and_probe(phenotype):\n",
    "    probe = []\n",
    "    constant_strings = []\n",
    "    for tf_constant in re.findall(\"tf.constant\\([0-9]\\.[0-9]+e.0[0-9], shape=shape, dtype=tf.float32\\)\", phenotype):\n",
    "        value = re.findall(\"[0-9]\\.[0-9]+e.0[0-9]\", tf_constant)\n",
    "        constant_strings.append(tf_constant)\n",
    "        probe.append(float(value[0]))\n",
    "    return constant_strings, probe\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "def create_evaluate_optimizer_function(phenotype, params):\n",
    "    def evaluate_optimizer(**kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            phenotype.replace(key, f\"tf.constant({value}, shape=shape, dtype=tf.float32)\")\n",
    "        from evaluators.adaptive_optimizer_evaluator_f_race import train_model\n",
    "        fitness, other_info = train_model((phenotype, params)) \n",
    "        return fitness\n",
    "    return evaluate_optimizer\n",
    "\n",
    "\n",
    "def tune_optimizer(n_iter, init_points, phenotype, params):\n",
    "    constants, probes = get_constants_and_probe(phenotype)\n",
    "    f = create_evaluate_optimizer_function(phenotype, params)\n",
    "    pbounds = {}\n",
    "    params = {}\n",
    "    i = 0\n",
    "    for constant, probe_value in zip(constants, probes):\n",
    "        param_key = 'param_' + str(i)\n",
    "        pbounds[param_key] = (0, 1)\n",
    "        params[param_key] = probe_value\n",
    "        phenotype.replace(constant, param_key, 1)\n",
    "        i += 1\n",
    "\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=f,\n",
    "        pbounds=pbounds,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    optimizer.probe(params=params\n",
    "    )\n",
    "    \n",
    "    optimizer.maximize(\n",
    "        init_points=init_points,\n",
    "        n_iter=n_iter,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "params = {\n",
    "    \"parameters\": \"parameters/adaptive_autolr_mutation_level_fmni.yml\", \n",
    "    \"popsize\": 100, \n",
    "    \"generations\": 100, \n",
    "    \"elitism\": 1, \n",
    "    \"prob_crossover\": 0.0, \n",
    "    \"prob_mutation\": {\n",
    "        \"0\": 0.0, \n",
    "        \"1\": 0.01, \n",
    "        \"2\": 0.01, \n",
    "        \"3\": 0.01, \n",
    "        \"4\": 0.05, \n",
    "        \"5\": 0.15, \n",
    "        \"6\": 0.01, \n",
    "        \"7\": 0.01, \n",
    "        \"8\": 0.01, \n",
    "        \"9\": 0.05, \"10\": 0.15, \"11\": 0.01, \"12\": 0.01, \"13\": 0.01, \"14\": 0.05, \"15\": 0.15, \"16\": 0.01, \"17\": 0.01, \"18\": 0.05, \"19\": 0.15}, \"tsize\": 2, \"grammar\": \"grammars/adaptive_autolr_grammar_mutate_level.txt\", \"experiment_name\": \"dumps/fmni\", \"run\": 1, \"save_step\": 1, \"min_tree_depth\": 6, \"max_tree_depth\": 17, \"model\": \"models/mnist_model.h5\", \"validation_size\": 3500, \"fitness_size\": 50000, \"batch_size\": 1000, \"epochs\": 100, \"patience\": 5, \"fitness_floor\": 0, }\n",
    "\n",
    "tune_optimizer(90, 10, best_indiv['phenotype'], params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that best fitness and average fitness improve together until the best individual in generation 124.\n",
    "After this generation, average fitness descreases, despite the improvements of the best individual.\n",
    "Let's take a look at the best individuals, why is this happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[44] {best_indivs[44]['smart_phenotype']} {averages[85]}\")\n",
    "print(f\"[86] {best_indivs[86]['smart_phenotype']} {averages[87]}\")\n",
    "print(f\"[88] {best_indivs[88]['smart_phenotype']} {averages[97]}\")\n",
    "print(f\"[98] {best_indivs[98]['smart_phenotype']} {averages[102]}\")\n",
    "print(f\"[103] {best_indivs[103]['smart_phenotype']} {averages[111]}\")\n",
    "print(f\"[112] {best_indivs[112]['smart_phenotype']} {averages[123]}\")\n",
    "print(f\"[124] {best_indivs[124]['smart_phenotype']} {averages[139]}\")\n",
    "print(f\"[140] {best_indivs[140]['smart_phenotype']} {averages[238]}\")\n",
    "print(f\"[239] {best_indivs[239]['smart_phenotype']} {averages[493]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.set_facecolor(color=\"#eff2f1\")\n",
    "ax.spines['bottom'].set_color('#08415c')\n",
    "ax.spines['top'].set_color('#08415c')\n",
    "ax.spines['left'].set_color('#08415c')\n",
    "ax.spines['right'].set_color('#08415c')\n",
    "ax.xaxis.label.set_color('#08415c')\n",
    "ax.yaxis.label.set_color('#08415c')\n",
    "ax.tick_params(axis='x', colors='#08415c')\n",
    "ax.tick_params(axis='y', colors=\"#08415c\")\n",
    "plt.plot([x for x in range(len(averages[:250]))], averages[:250], label='population average', color=\"#7796cb\")\n",
    "for x in best_indivs:\n",
    "    plt.axvline(x, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_phenotype import readable_phenotype\n",
    "print(readable_phenotype(best_indivs[44]['phenotype']))\n",
    "print(\"---\")\n",
    "print(readable_phenotype(best_indivs[86]['phenotype']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum term and learning rate are the same values. Mutations in this value are likely very destructive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "daaf6ac28b1c18339a668ed13dbb2d52ab7f39bbae5e6ab3d06f92e732bf9ed2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
