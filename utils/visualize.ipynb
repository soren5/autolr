{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import platform\n",
    "\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['figure.figsize'] = [20,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prot_div(left, right):\n",
    "    if right == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return left / right\n",
    "\n",
    "def if_func(condition, state1, state2):\n",
    "    if condition:\n",
    "        return state1\n",
    "    else:\n",
    "        return state2\n",
    "\n",
    "def read_experiment_results(full_path):\n",
    "    dir_name = full_path\n",
    "    results = []\n",
    "    it = 0\n",
    "    try:\n",
    "        while True:\n",
    "            with open(dir_name + 'iteration_' + str(it) + '.json') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if it % 1 == 0:\n",
    "                    print(it)\n",
    "                results.append(data)\n",
    "            it += 1\n",
    "    except:\n",
    "        print(\"Finished reading \", full_path)\n",
    "    return results\n",
    "\n",
    "#extract number from file\n",
    "def extract_number(f):\n",
    "    s = re.findall(\"\\d+$\",f)\n",
    "    return (int(s[0]) if s else -1,f)\n",
    "\n",
    "'''Human sorting of files '''\n",
    "'''From https://nedbatchelder.com/blog/200712/human_sorting.html '''\n",
    "def tryint(s):\n",
    "    \"\"\"\n",
    "    Return an int if possible, or `s` unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\"\n",
    "    Turn a string into a list of string and number chunks.\n",
    "\n",
    "    >>> alphanum_key(\"z23a\")\n",
    "    [\"z\", 23, \"a\"]\n",
    "\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def human_sort(l):\n",
    "    \"\"\"\n",
    "    Sort a list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "\n",
    "def read_experiment_results_agnostic(full_path):\n",
    "    results = []\n",
    "    filenames = glob.glob(pathname = 'iteration_?*', root_dir = full_path)\n",
    "    filenames_ordered = human_sort(filenames)\n",
    "    try:\n",
    "        for file in filenames:            \n",
    "            json_file = open(Path(os.path.join(full_path, file)))\n",
    "            data = json.load(json_file)\n",
    "            if extract_number(file)[0] % 1 == 0:\n",
    "                print(file)\n",
    "            results.append(data)\n",
    "    except:\n",
    "        print(\"Error in reading results \", full_path)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is where you specify where to get results from (not system agnostic)\n",
    "1. Select the run numbers you want to analyse and include them in the `run_number` list.\n",
    "2. Make sure os_string matches your operating system, this avoid weird bugs when creating paths\n",
    "3. Specify the folder where the runs you selected are found. Make sure to end with `run_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = range(15,16)\n",
    "\n",
    "\n",
    "os_string = \"w10\"\n",
    "results = []\n",
    "if os_string == \"unix\":\n",
    "    path = \"/Users/soren/Downloads/run_\"\n",
    "elif os_string == \"w10\":\n",
    "    path = \"c:\\\\Users\\\\p288427\\\\Github\\\\autolr\\\\many_runs\\\\cif\\\\run_\"\n",
    "for i in run_number: \n",
    "    print((path + str(i) + '/'))\n",
    "    results.append(read_experiment_results(path +  str(i) + '/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this cell you choose which folder to use to read the runs' results from (made it so it is system agnostic).\n",
    "\n",
    "It is necessary to:\n",
    "1. set the folder in `result_folde_path_from_root` as a list of all the folders starting from the root down to the one containing the runs\n",
    "2. set the runs numbers to analyze as a range `run_number` between 1 and N where n is the number of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p288427\\Github\\autolr\\many_runs\\fmni\n",
      "Error in reading results  c:\\Users\\p288427\\Github\\autolr\\many_runs\\fmni\\run_15\n"
     ]
    }
   ],
   "source": [
    "run_number = range(15,16)\n",
    "os_string = platform.system()\n",
    "result_folder_path_from_root = os.path.join(\"many_runs\",\"fmni\")\n",
    "results_agnostic = []\n",
    "path = os.path.join(os.path.dirname(os.path.abspath(os.curdir)), result_folder_path_from_root) \n",
    "print(path)\n",
    "\n",
    "for i in run_number: \n",
    "  file_path = os.path.join(path, \"run_\" + str(i))\n",
    "  results_agnostic.append(read_experiment_results_agnostic(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defintion of functions to plot data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genealogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_phenotype import smart_phenotype, readable_phenotype\n",
    "import random\n",
    "def genealogy_string(results):\n",
    "    import graphviz\n",
    "    epochs = np.arange(len(results[0]))\n",
    "    lineage = []\n",
    "    fitness_color = []\n",
    "    occurences = {}\n",
    "    rendered = set()\n",
    "    prune_cutoff = 20\n",
    "    string = \"\"\"digraph genealogy{\n",
    "fontname=\"Helvetica,Arial,sans-serif\"\n",
    "node [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "edge [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "# page = \"8.2677165,11.692913\" ;\n",
    "ratio = \"auto\" ;\n",
    "mincross = 2.0 ;\n",
    "label = \"Genealogy\" ;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    connections_string = \"\"\n",
    "    for iteration in epochs:     \n",
    "        for result in results:\n",
    "            for indiv in result[iteration]:\n",
    "                if \"parent\" in indiv:\n",
    "                    for parent in indiv[\"parent\"]:\n",
    "                        if parent in occurences:\n",
    "                            occurences[parent] += 1\n",
    "                        else: \n",
    "                            occurences[parent] = 1\n",
    "                        if indiv['id'] in occurences:\n",
    "                            occurences[indiv['id']] += 1\n",
    "                        else: \n",
    "                            occurences[indiv['id']] = 1  \n",
    "                        lineage.append((parent, indiv['id'], indiv['fitness'] * -1))\n",
    "                fitness_color.append((indiv['id'], indiv['fitness'] * -1))\n",
    "    for parent, child, fitness in set(lineage):\n",
    "        if fitness > 0.12 and occurences[parent] > prune_cutoff and occurences[child] > prune_cutoff:\n",
    "            connections_string+=(f'\\n \"{parent}\" -> \"{child}\" ;')    \n",
    "            rendered.add(parent)\n",
    "            rendered.add(child)\n",
    "    for id, fitness in set(fitness_color):\n",
    "        if fitness > 0.12 and id in rendered:\n",
    "            string+=(f'\\n \"{id}\" [style=filled,fillcolor=\"#{format(int(255-fitness*255), \"x\")}{format(int(255-fitness*255), \"x\")}ff\", width={fitness*10}, height={fitness*10}] ;')\n",
    "\n",
    "    string += connections_string + \"\\n }\"\n",
    "    with open(\"graph.dot\", \"w\") as f:\n",
    "        print(string,file=f)\n",
    "    src = graphviz.Source(string)\n",
    "    src.render('doctest-output/graph.gv', view=True).replace('\\\\', '/')\n",
    "    return string\n",
    "\n",
    "#print(genealogy_string(results))\n",
    "def load_archive(path, run_number, generation):\n",
    "    with open(path + str(run_number) + '\\\\z-archive_' + str(generation) + \".json\", 'r') as f:\n",
    "        archive = json.load(f)\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap and phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "def trim_phenotype(phenotype):\n",
    "    if \"shape\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", shape=shape, dtype=tf.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.math.\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.\", \"\")\n",
    "        functions = phenotype.split(r'lambda shape,  alpha')\n",
    "\n",
    "    elif \"size\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", size=size, dtype=torch.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"torch.\", \"\")        \n",
    "        functions = phenotype.split(r'lambda size, alpha')\n",
    "    \n",
    "    else:\n",
    "        raise Exception()\n",
    "\n",
    "    return functions \n",
    "\n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string =functions[2][14:-2] \n",
    "    sigma_func_string =functions[3][21:-2] \n",
    "    grad_func_string = functions[-1][21:]\n",
    "    \n",
    "    return grad_func_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines class nodes, which contains process_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, symbol, parent, child_count):\n",
    "        self.symbol = symbol\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.child = None\n",
    "        self.parent = parent\n",
    "        self.child_count = child_count\n",
    "            \n",
    "    def insert(self, child):\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                self.left = child\n",
    "            elif self.left.is_full() == False:\n",
    "                #print(f\"inserting in {self.left.symbol}\")\n",
    "                self.left.insert(child)\n",
    "            elif self.right is None:\n",
    "                self.right = child\n",
    "            elif self.right.is_full() == False:\n",
    "                #print(f\"inserting in {self.right.symbol}\")\n",
    "                self.right.insert(child)\n",
    "            else:\n",
    "                raise Exception(f\"All two children are full:{self.symbol}({self.left.symbol}, {self.right.symbol}) [{self.get_root().to_string()}]\")\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                self.child = child\n",
    "            elif self.child.is_full() == False:\n",
    "                #print(f\"inserting in {self.child.symbol}\")\n",
    "                self.child.insert(child)\n",
    "            else:\n",
    "                raise Exception(f\"Child is full: {self.symbol}({self.child.symbol}) [{self.get_root().to_string()}]\")\n",
    "        else:\n",
    "            raise Exception(f\"Insert called on terminal: {self.symbol} [{self.get_root().to_string()}]\")\n",
    "            \n",
    "    def is_full(self):\n",
    "        #print(f\"Calling is full on {self.symbol}\")\n",
    "        full = 0\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                full = False\n",
    "            elif self.right is None:\n",
    "                full = False\n",
    "            elif self.left.is_full() and self.right.is_full():\n",
    "                full = True\n",
    "            else: \n",
    "                full = False\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                full = False\n",
    "            elif self.child.is_full():\n",
    "                full = True\n",
    "            else:\n",
    "                full = False\n",
    "        elif self.child_count == 0:\n",
    "            full = True\n",
    "        else:\n",
    "            raise Exception(f\"Symbol {self.symbol} does not 0, 1 or 2 children\")\n",
    "        return full\n",
    "        \n",
    "    def get_next(self):\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def to_string(self):\n",
    "        string = \"\"\n",
    "        if self.child_count == 2:\n",
    "            string +=\"(\" \n",
    "            if self.left is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.left.to_string()\n",
    "            string += self.symbol\n",
    "            if self.right is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.right.to_string()\n",
    "            string += \")\"\n",
    "            \n",
    "        elif self.child_count == 1:\n",
    "            string += self.symbol + \"(\" \n",
    "            if self.child is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.child.to_string()\n",
    "            string += \")\"\n",
    "        else:\n",
    "            string += self.symbol\n",
    "        return string\n",
    "\n",
    "    def get_root(self):\n",
    "        if self.parent is not None:\n",
    "            return self.parent.get_root()\n",
    "        else:\n",
    "            return self\n",
    "        \n",
    "        \n",
    "def process_results(results, negative_fit=True, run_number=None):\n",
    "    #print(epochs)\n",
    "    best_individuals = {}\n",
    "    averages_all = []\n",
    "    bests_all = []\n",
    "    stds_all = []\n",
    "    best_of_all = []\n",
    "    stds_best_all = [] \n",
    "    indivs = []\n",
    "    indiv_fits = []\n",
    "    indivs_epochs = []\n",
    "    indivs_per_epoch = []\n",
    "    boa_fit = 0\n",
    "    run_best = np.zeros(len(results))\n",
    "    \n",
    "    \n",
    "    #see the max n of gens in results\n",
    "    generations = np.arange(len(max(results, key=len)))\n",
    "    #loop over generations\n",
    "    for generation in generations:\n",
    "        averages_all.append([])\n",
    "        bests_all.append([])\n",
    "        stds_all.append([])\n",
    "        indivs_per_epoch.append([])\n",
    "        best_of_all.append(0)\n",
    "        stds_best_all.append(0)    \n",
    "        run = 0  \n",
    "\n",
    "        #loop over runs\n",
    "        for result in results:\n",
    "            all_fits = []\n",
    "            best = 0\n",
    "            if generation < len(result):\n",
    "                for indiv in result[generation]:\n",
    "                    if negative_fit:\n",
    "                        indiv[\"fitness\"] *= -1\n",
    "                    indiv['run'] = run\n",
    "                    if 'smart_phenotype' not in indiv:\n",
    "                        indiv['smart_phenotype'] = smart_phenotype(indiv[\"phenotype\"])\n",
    "                    indivs.append(indiv)\n",
    "                    indiv_fits.append(indiv['fitness'])\n",
    "                    indivs_epochs.append(generation)\n",
    "                    indivs_per_epoch[generation].append(indiv['fitness'])\n",
    "                    if indiv['fitness'] > run_best[run]:\n",
    "                        run_best[run] = indiv['fitness']\n",
    "                        if run_number is None:\n",
    "                            print(f'------NEW BEST IN RUN------\\n{generation}-{indiv[\"id\"]}-{boa_fit}\\n{smart_phenotype(indiv[\"phenotype\"])}\\n--------------------')\n",
    "                        else:\n",
    "                            print(f'------NEW BEST IN RUN {run_number[run]}------\\nEPOCH:{generation}\\nID:{indiv[\"id\"]}-{boa_fit}\\n{readable_phenotype(indiv[\"phenotype\"])}\\n--------------------')      \n",
    "                    if indiv['fitness'] > best:\n",
    "                        best = indiv['fitness']\n",
    "                        if indiv['fitness'] > boa_fit:\n",
    "                            boa_fit = best\n",
    "                            best_individuals[generation] = {\"fitness\": boa_fit, \"phenotype\": indiv[\"phenotype\"], \"smart_phenotype\": smart_phenotype(indiv[\"phenotype\"])}\n",
    "                    best = best if indiv['fitness'] < best else indiv['fitness']\n",
    "                    all_fits.append(indiv['fitness'])\n",
    "                averages_all[generation].append(np.average(all_fits))\n",
    "                stds_all[generation].append(np.std(all_fits))\n",
    "                bests_all[generation].append(best)\n",
    "            run += 1\n",
    "            \n",
    "        stds_best_all[generation] = np.std(bests_all[generation]) \n",
    "        stds_all[generation] = np.std(averages_all[generation])\n",
    "        averages_all[generation] = np.average(averages_all[generation])\n",
    "        best_of_all[generation] = np.max(bests_all[generation])  \n",
    "        bests_all[generation] = np.average(bests_all[generation])        \n",
    "    return {\"averages_all\": averages_all, \"bests_all\": bests_all, \"indivs\": indivs, \"indivs_epochs\": indivs_epochs, \"epochs\": generations}\n",
    "\n",
    "def plot_fit(epochs, averages_all, bests_all): \n",
    "    plt.figure(facecolor='#eff2f1')\n",
    "    \n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(color=\"#eff2f1\")\n",
    "    ax.spines['bottom'].set_color('#08415c')\n",
    "    ax.spines['top'].set_color('#08415c')\n",
    "    ax.spines['left'].set_color('#08415c')\n",
    "    ax.spines['right'].set_color('#08415c')\n",
    "    ax.xaxis.label.set_color('#08415c')\n",
    "    ax.yaxis.label.set_color('#08415c')\n",
    "    ax.tick_params(axis='x', colors='#08415c')\n",
    "    ax.tick_params(axis='y', colors=\"#08415c\")\n",
    "    plt.plot(epochs, averages_all, label='population average', color=\"#7796cb\")\n",
    "    #plt.fill_between(epochs, [i + j for i, j in zip(averages_all, stds_aall)], [i - j for i, j in zip(averages_all, stds_all)], alpha=0.2)\n",
    "    plt.plot(epochs, bests_all, label='best average', color=\"#EFA00B\")   \n",
    "    #plt.fill_between(epochs, [i + j for i, j in zip(bests_all, stds_best_all)], [i - j for i, j in zip(bests_all, stds_best_all)], alpha=0.2)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f'best_average_evolution{run_number}.png')\n",
    "    plt.savefig(f'best_average_evolution{run_number}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def pop_density_heatmap(epochs, indivs, rows=10, columns=10, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(heatmap_matrix, row_labels, col_labels=columns_labels, ax=ax, cbarlabel=\"indiv count\", cmap=\"Greys\")\n",
    "    texts = annotate_heatmap(im,valfmt=\"{x:.1E}\")\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Individuals Density Heatmap (Generations vs Fitness)')\n",
    "    plt.show()\n",
    "\n",
    "def unique_indivs_heatmap(epochs, indivs, rows=10, columns=10, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if indiv[\"smart_phenotype\"] not in unique_indivs_record[row_index][column_index]:\n",
    "                if epoch == epochs[-1]:\n",
    "                    #print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(indiv[\"smart_phenotype\"])\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(heatmap_matrix, row_labels, col_labels=columns_labels, ax=ax, cbarlabel=\"unique indiv count\", cmap=\"Greys\")\n",
    "    texts = annotate_heatmap(im)\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Unique Individuals Density Heatmap (Generations vs Fitness)')\n",
    "    plt.show()\n",
    "\n",
    "def unique_indivs_curve(epochs, indivs, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0):\n",
    "    rows = 1\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    columns = int(epoch_len)\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if indiv[\"smart_phenotype\"] not in unique_indivs_record[row_index][column_index]:\n",
    "                if epoch == epochs[-1]:\n",
    "                    #print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(indiv[\"smart_phenotype\"])\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    #print([heatmap_matrix[row] for row in range(len(heatmap_matrix))])\n",
    "    plt.plot([x for x in range(columns)], np.transpose([heatmap_matrix[row] for row in range(len(heatmap_matrix))]))\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Number of Uniques')\n",
    "    plt.title('Number of Unique Behaviours throughout Evolution')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This cell loads up and aggregates all the data, it might take a few minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agnostic = process_results(results_agnostic, run_number=run_number)\n",
    "# data = process_results(results, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots using the cell below\n",
    "## Available plots:\n",
    "[LINE PLOT] Show fitness over generations: \n",
    "\n",
    "`plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])`\n",
    "\n",
    "\n",
    "[HEAT MAP] Show the distribution of population fitness over generations: \n",
    "\n",
    "`pop_density_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "[LINE PLOT] Unique individuals over generation:\n",
    "\n",
    " `unique_indivs_curve(data[\"indivs_epochs\"], data[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "[HEAT MAP] Unique individuals distribution of fitness over generations:\n",
    "\n",
    "`unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "## You can filter the results in the last three plots using these settings:\n",
    "\n",
    "`fit_floor` - Only show results for individuals above this fitness\n",
    "\n",
    "`fit_ceil` - Only show results for individuals below this fitness\n",
    "\n",
    "`gen_floor` - Only show results after this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "`gen_ceiling` - Only show results before this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "You can also use `columns, rows` to adjust the ratio and detail of the heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, rows = (40, 10)\n",
    "plt.rcParams['figure.figsize'] = [columns, rows]\n",
    "#plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])\n",
    "\n",
    "fit_floor = 0.0\n",
    "fit_ceil = 1.0\n",
    "gen_floor = 0.0\n",
    "# gen_ceil = float(len(data['epochs']))\n",
    "gen_ceil = float(len(data_agnostic['epochs']))\n",
    "\n",
    "#unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "plot_fit(data_agnostic[\"epochs\"], data_agnostic['averages_all'], data_agnostic['bests_all'])\n",
    "pop_density_heatmap(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "unique_indivs_heatmap(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "unique_indivs_curve(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "#plt.vlines([0,2,6,9,11,16,23,29,30,31,35,36,42,45,47,54,55,75],0,100,colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond this point is code for archive analysis, this is not refined. Do not use unless necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list = []\n",
    "for i in run_number: \n",
    "    it = 1 \n",
    "    try:\n",
    "        while True:\n",
    "            archive = load_archive(path, i, it)\n",
    "            it += 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f\"loading archive {it - 1} for run {i}\")\n",
    "        archive = load_archive(path, i, it - 1)\n",
    "        for x in archive:\n",
    "            if 'fitness' in archive[x]:\n",
    "                archive_list.append([x, archive[x], archive[x]['fitness'], i])\n",
    "    except:\n",
    "        print(f\"Run {i} has no archive\")\n",
    "archive_list.sort(key=lambda x : x[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(archive_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "while it < 10:\n",
    "    print(archive_list[it])\n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def turn_to_expr(phenotype, tree):\n",
    "    if phenotype == \"\":\n",
    "        return tree\n",
    "    \n",
    "    if phenotype[0:9] == \"multiply(\":\n",
    "        #print(\"multiply\")\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"*\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:14] == \"divide_no_nan(\":\n",
    "        phenotype = phenotype[14:]\n",
    "        node = Node(\"/\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"add(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"+\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"pow(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"^\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"subtract(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"grad\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"grad\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"beta\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"beta\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"alpha\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"alpha\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sigma\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sigma\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"negative(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sqrt(\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sqrt\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:7] == \"square(\":\n",
    "        phenotype = phenotype[7:]\n",
    "        node = Node(\"square\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:2] == \", \":\n",
    "        phenotype = phenotype[2:]\n",
    "        return turn_to_expr(phenotype, tree)     \n",
    "    elif phenotype[0] == \")\":\n",
    "        phenotype = phenotype[1:]\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"constant(\":\n",
    "        if phenotype[9:12] == \"0.0\" or phenotype[9:13] == \"1.0)\" or phenotype[9:13] == \"1.0,\":\n",
    "            node = Node(phenotype[9:12], tree, 0)\n",
    "            phenotype = phenotype[12:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()           \n",
    "        else:\n",
    "            node = Node(phenotype[9:9+14], tree, 0)\n",
    "            phenotype = phenotype[9+14:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    else:\n",
    "        raise Exception(phenotype)\n",
    "        \n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string =functions[2][14:-2] \n",
    "    sigma_func_string =functions[3][21:-2] \n",
    "    grad_func_string = functions[-1][21:]\n",
    "    \n",
    "    for x in [alpha_func_string, beta_func_string, sigma_func_string, grad_func_string]:\n",
    "        print(x)    \n",
    "        turn_to_expr(x, Node(\"\", None, 1)).to_string()\n",
    "\n",
    "    return grad_func_string\n",
    "\n",
    "for indiv in data['indivs']:\n",
    "    math_phenotype(indiv['phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"multiply(\"\n",
    "print(a[0:9])\n",
    "print(a[9:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "daaf6ac28b1c18339a668ed13dbb2d52ab7f39bbae5e6ab3d06f92e732bf9ed2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
