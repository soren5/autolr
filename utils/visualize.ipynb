{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "#matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "#plt.rcParams[\"figure.figsize\"] = [20, 20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions to read data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prot_div(left, right):\n",
    "    if right == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return left / right\n",
    "\n",
    "\n",
    "def if_func(condition, state1, state2):\n",
    "    if condition:\n",
    "        return state1\n",
    "    else:\n",
    "        return state2\n",
    "\n",
    "\n",
    "def read_experiment_results(full_path):\n",
    "    dir_name = full_path\n",
    "    results = []\n",
    "    it = 0\n",
    "    try:\n",
    "        while True:\n",
    "            with open(dir_name + \"iteration_\" + str(it) + \".json\") as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if it % 1 == 0:\n",
    "                    print(it)\n",
    "                results.append(data)\n",
    "            it += 1\n",
    "    except:\n",
    "        print(\"Finished reading \", full_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "# extract number from file\n",
    "def extract_number(f):\n",
    "    s = re.findall(\"\\d+$\", f)\n",
    "    return (int(s[0]) if s else -1, f)\n",
    "\n",
    "\n",
    "\"\"\"Human sorting of files \"\"\"\n",
    "\"\"\"From https://nedbatchelder.com/blog/200712/human_sorting.html \"\"\"\n",
    "\n",
    "\n",
    "def tryint(s):\n",
    "    \"\"\"\n",
    "    Return an int if possible, or `s` unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\"\n",
    "    Turn a string into a list of string and number chunks.\n",
    "\n",
    "    >>> alphanum_key(\"z23a\")\n",
    "    [\"z\", 23, \"a\"]\n",
    "\n",
    "    \"\"\"\n",
    "    return [tryint(c) for c in re.split(\"([0-9]+)\", s)]\n",
    "\n",
    "\n",
    "def human_sort(l):\n",
    "    \"\"\"\n",
    "    Sort a list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "\n",
    "\n",
    "def read_experiment_results_agnostic(full_path):\n",
    "    results = []\n",
    "    filenames = glob.glob(pathname=\"iteration_?*\", root_dir=full_path)\n",
    "    filenames_ordered = human_sort(filenames)\n",
    "    try:\n",
    "        for file in filenames:\n",
    "            json_file = open(Path(os.path.join(full_path, file)))\n",
    "            data = json.load(json_file)\n",
    "            if extract_number(file)[0] % 1 == 0:\n",
    "                print(file)\n",
    "            results.append(data)\n",
    "    except:\n",
    "        print(\"Error in reading results \", full_path)\n",
    "    return results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify where to get results from and load (system agnostic version).\n",
    "\n",
    "It is necessary to:\n",
    "\n",
    "1. set the folder in `result_folde_path_from_root` as a list of all the folders starting from the root down to the one containing the runs (assumes root is the parent dir of the dir containing this script)\n",
    "2. set the runs numbers to analyze as a range `run_number` between 1 and N where n is the number of runs\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming folder with data for different tasks is in root directory\n",
    "def load_results(folder, task, run_number):\n",
    "    result_folder_path_from_root = os.path.join(folder, task)\n",
    "    results_agnostic = []\n",
    "    path = os.path.join(\n",
    "        os.path.dirname(os.path.abspath(os.curdir)), result_folder_path_from_root\n",
    "    )\n",
    "    print(path)\n",
    "\n",
    "    for i in run_number:\n",
    "        file_path = os.path.join(path, \"run_\" + str(i))\n",
    "        results_agnostic.append(read_experiment_results_agnostic(file_path))\n",
    "    results_agnostic.append({\"task\": task})\n",
    "    return results_agnostic\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\p288427\\Github\\autolr\\utils\\visualize.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m task \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfmni\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmany_results\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmany_runs\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results_agnostic \u001b[39m=\u001b[39m load_results(folder\u001b[39m=\u001b[39mfolder, task\u001b[39m=\u001b[39mtask, run_number\u001b[39m=\u001b[39mrun_number)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_results' is not defined"
     ]
    }
   ],
   "source": [
    "run_number = range(1, 2)\n",
    "task = \"fmni\"\n",
    "folder = \"many_results\\\\many_runs\"\n",
    "\n",
    "results_agnostic = load_results(folder=folder, task=task, run_number=run_number)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defintion of extra functions to plot data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genealogy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_phenotype import smart_phenotype, readable_phenotype\n",
    "import random\n",
    "\n",
    "\n",
    "def genealogy_string(results):\n",
    "    import graphviz\n",
    "\n",
    "    epochs = np.arange(len(results[0]))\n",
    "    lineage = []\n",
    "    fitness_color = []\n",
    "    occurences = {}\n",
    "    rendered = set()\n",
    "    prune_cutoff = 20\n",
    "    string = \"\"\"digraph genealogy{\n",
    "fontname=\"Helvetica,Arial,sans-serif\"\n",
    "node [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "edge [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "# page = \"8.2677165,11.692913\" ;\n",
    "ratio = \"auto\" ;\n",
    "mincross = 2.0 ;\n",
    "label = \"Genealogy\" ;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    connections_string = \"\"\n",
    "    for iteration in epochs:\n",
    "        for result in results:\n",
    "            for indiv in result[iteration]:\n",
    "                if \"parent\" in indiv:\n",
    "                    for parent in indiv[\"parent\"]:\n",
    "                        if parent in occurences:\n",
    "                            occurences[parent] += 1\n",
    "                        else:\n",
    "                            occurences[parent] = 1\n",
    "                        if indiv[\"id\"] in occurences:\n",
    "                            occurences[indiv[\"id\"]] += 1\n",
    "                        else:\n",
    "                            occurences[indiv[\"id\"]] = 1\n",
    "                        lineage.append((parent, indiv[\"id\"], indiv[\"fitness\"] * -1))\n",
    "                fitness_color.append((indiv[\"id\"], indiv[\"fitness\"] * -1))\n",
    "    for parent, child, fitness in set(lineage):\n",
    "        if (\n",
    "            fitness > 0.12\n",
    "            and occurences[parent] > prune_cutoff\n",
    "            and occurences[child] > prune_cutoff\n",
    "        ):\n",
    "            connections_string += f'\\n \"{parent}\" -> \"{child}\" ;'\n",
    "            rendered.add(parent)\n",
    "            rendered.add(child)\n",
    "    for id, fitness in set(fitness_color):\n",
    "        if fitness > 0.12 and id in rendered:\n",
    "            string += f'\\n \"{id}\" [style=filled,fillcolor=\"#{format(int(255-fitness*255), \"x\")}{format(int(255-fitness*255), \"x\")}ff\", width={fitness*10}, height={fitness*10}] ;'\n",
    "\n",
    "    string += connections_string + \"\\n }\"\n",
    "    with open(\"graph.dot\", \"w\") as f:\n",
    "        print(string, file=f)\n",
    "    src = graphviz.Source(string)\n",
    "    src.render(\"doctest-output/graph.gv\", view=True).replace(\"\\\\\", \"/\")\n",
    "    return string\n",
    "\n",
    "\n",
    "# print(genealogy_string(results))\n",
    "def load_archive(path, run_number, generation):\n",
    "    with open(\n",
    "        path + str(run_number) + \"\\\\z-archive_\" + str(generation) + \".json\", \"r\"\n",
    "    ) as f:\n",
    "        archive = json.load(f)\n",
    "    return archive\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines class node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, symbol, parent, child_count):\n",
    "        self.symbol = symbol\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.child = None\n",
    "        self.parent = parent\n",
    "        self.child_count = child_count\n",
    "\n",
    "    def insert(self, child):\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                self.left = child\n",
    "            elif self.left.is_full() == False:\n",
    "                # print(f\"inserting in {self.left.symbol}\")\n",
    "                self.left.insert(child)\n",
    "            elif self.right is None:\n",
    "                self.right = child\n",
    "            elif self.right.is_full() == False:\n",
    "                # print(f\"inserting in {self.right.symbol}\")\n",
    "                self.right.insert(child)\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    f\"All two children are full:{self.symbol}({self.left.symbol}, {self.right.symbol}) [{self.get_root().to_string()}]\"\n",
    "                )\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                self.child = child\n",
    "            elif self.child.is_full() == False:\n",
    "                # print(f\"inserting in {self.child.symbol}\")\n",
    "                self.child.insert(child)\n",
    "            else:\n",
    "                raise Exception(\n",
    "                    f\"Child is full: {self.symbol}({self.child.symbol}) [{self.get_root().to_string()}]\"\n",
    "                )\n",
    "        else:\n",
    "            raise Exception(\n",
    "                f\"Insert called on terminal: {self.symbol} [{self.get_root().to_string()}]\"\n",
    "            )\n",
    "\n",
    "    def is_full(self):\n",
    "        # print(f\"Calling is full on {self.symbol}\")\n",
    "        full = 0\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                full = False\n",
    "            elif self.right is None:\n",
    "                full = False\n",
    "            elif self.left.is_full() and self.right.is_full():\n",
    "                full = True\n",
    "            else:\n",
    "                full = False\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                full = False\n",
    "            elif self.child.is_full():\n",
    "                full = True\n",
    "            else:\n",
    "                full = False\n",
    "        elif self.child_count == 0:\n",
    "            full = True\n",
    "        else:\n",
    "            raise Exception(f\"Symbol {self.symbol} does not 0, 1 or 2 children\")\n",
    "        return full\n",
    "\n",
    "    def get_next(self):\n",
    "        return self\n",
    "\n",
    "    def to_string(self):\n",
    "        string = \"\"\n",
    "        if self.child_count == 2:\n",
    "            string += \"(\"\n",
    "            if self.left is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.left.to_string()\n",
    "            string += self.symbol\n",
    "            if self.right is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.right.to_string()\n",
    "            string += \")\"\n",
    "\n",
    "        elif self.child_count == 1:\n",
    "            string += self.symbol + \"(\"\n",
    "            if self.child is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.child.to_string()\n",
    "            string += \")\"\n",
    "        else:\n",
    "            string += self.symbol\n",
    "        return string\n",
    "\n",
    "    def get_root(self):\n",
    "        if self.parent is not None:\n",
    "            return self.parent.get_root()\n",
    "        else:\n",
    "            return self\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate all the data, it might take a few minutes to run\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results, negative_fit=True, run_number=None):\n",
    "    # print(epochs)\n",
    "    best_individuals = {}\n",
    "    averages_all = []\n",
    "    averages = []\n",
    "    bests_all = []\n",
    "    bests = []\n",
    "    stds_all = []\n",
    "    best_of_all = []\n",
    "    stds_best_all = []\n",
    "    indivs = []\n",
    "    indiv_fits = []\n",
    "    indivs_epochs = []\n",
    "    indivs_per_epoch = []\n",
    "    unique_indivs = []\n",
    "    boa_fit = 0\n",
    "    run_best = np.zeros(len(results))\n",
    "\n",
    "    # make sure last elemt corresponds to the task on which the individuals evolved\n",
    "    # store the task to name the processed_results later\n",
    "    # and take it out from data\n",
    "    task = results[-1]\n",
    "    assert type(task) == dict\n",
    "    assert len(task) == 1\n",
    "    assert \"task\" in task\n",
    "    results = results[:-1]\n",
    "    assert type(results[-1]) != dict\n",
    "\n",
    "    # see the max n of gens in results\n",
    "    generations = np.arange(len(max(results, key=len)))\n",
    "\n",
    "    # loop over generations\n",
    "    processed_result = loop_over_generations(\n",
    "        results,\n",
    "        negative_fit,\n",
    "        run_number,\n",
    "        best_individuals,\n",
    "        averages_all,\n",
    "        averages,\n",
    "        bests_all,\n",
    "        bests,\n",
    "        stds_all,\n",
    "        best_of_all,\n",
    "        stds_best_all,\n",
    "        indivs,\n",
    "        indiv_fits,\n",
    "        indivs_epochs,\n",
    "        indivs_per_epoch,\n",
    "        boa_fit,\n",
    "        run_best,\n",
    "        generations,\n",
    "        unique_indivs\n",
    "    )\n",
    "\n",
    "    # name the data after the task\n",
    "    processed_result.update(task)\n",
    "\n",
    "    return processed_result\n",
    "\n",
    "\n",
    "def loop_over_generations(\n",
    "    results,\n",
    "    negative_fit,\n",
    "    run_number,\n",
    "    best_individuals,\n",
    "    averages_all,\n",
    "    averages,\n",
    "    bests_all,\n",
    "    bests,\n",
    "    stds_all,\n",
    "    best_of_all,\n",
    "    stds_best_all,\n",
    "    indivs,\n",
    "    indiv_fits,\n",
    "    indivs_epochs,\n",
    "    indivs_per_epoch,\n",
    "    boa_fit,\n",
    "    run_best,\n",
    "    generations,\n",
    "    unique_indivs\n",
    "):\n",
    "    for generation in generations:\n",
    "        averages.append([])\n",
    "        bests.append([])\n",
    "        stds_all.append([])\n",
    "        indivs_per_epoch.append([])\n",
    "        best_of_all.append(0)\n",
    "        stds_best_all.append(0)\n",
    "        run = 0\n",
    "\n",
    "        # loop over runs\n",
    "        for result in results:\n",
    "            all_fits = []\n",
    "            best = 0\n",
    "            if len(unique_indivs) == run:\n",
    "                unique_indivs.append([])\n",
    "            if generation < len(result):\n",
    "            # loop over inds\n",
    "                unique_inds_run = []\n",
    "                for indiv in result[generation]:\n",
    "                    indiv[\"run\"] = run\n",
    "                    if negative_fit:\n",
    "                        indiv[\"fitness\"] *= -1\n",
    "                    if \"smart_phenotype\" not in indiv:\n",
    "                        indiv[\"smart_phenotype\"] = smart_phenotype(indiv[\"phenotype\"])\n",
    "                    if indiv[\"smart_phenotype\"] not in unique_inds_run:\n",
    "                        unique_inds_run.append(indiv)\n",
    "                    indivs.append(indiv)\n",
    "                    indiv_fits.append(indiv[\"fitness\"])\n",
    "                    indivs_epochs.append(generation)\n",
    "                    indivs_per_epoch[generation].append(indiv[\"fitness\"])\n",
    "                    if indiv[\"fitness\"] > run_best[run]:\n",
    "                        run_best[run] = indiv[\"fitness\"]\n",
    "                    if indiv[\"fitness\"] > best:\n",
    "                        best = indiv[\"fitness\"]\n",
    "                        if indiv[\"fitness\"] > boa_fit:\n",
    "                            boa_fit = best\n",
    "                            best_individuals[generation] = {\n",
    "                                \"fitness\": boa_fit,\n",
    "                                \"phenotype\": indiv[\"phenotype\"],\n",
    "                                \"smart_phenotype\": indiv[\"smart_phenotype\"],\n",
    "                            }\n",
    "                    best = best if indiv[\"fitness\"] < best else indiv[\"fitness\"]\n",
    "                    all_fits.append(indiv[\"fitness\"])\n",
    "                averages[generation].append(np.average(all_fits))\n",
    "\n",
    "                unique_indivs[run].append([])    \n",
    "                unique_indivs[run][generation] = unique_inds_run\n",
    "\n",
    "                stds_all[generation].append(np.std(all_fits))\n",
    "                bests[generation].append(best)\n",
    "            run += 1\n",
    "\n",
    "        stds_best_all[generation] = np.std(bests[generation])\n",
    "        stds_all[generation] = np.std(averages[generation])\n",
    "        averages_all.append(np.average(averages[generation]))\n",
    "        best_of_all[generation] = np.max(bests[generation])\n",
    "        bests_all.append(np.average(bests[generation]))\n",
    "\n",
    "        processed_result = {\n",
    "            \"averages\": averages,\n",
    "            \"bests\": bests,\n",
    "            \"averages_all\": averages_all,\n",
    "            \"bests_all\": bests_all,\n",
    "            \"indivs\": indivs,\n",
    "            \"indivs_epochs\": indivs_epochs,\n",
    "            \"epochs\": generations,\n",
    "            \"unique_indivs\": unique_indivs\n",
    "        }\n",
    "\n",
    "    return processed_result\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def loop_over_runs(\n",
    "    results,\n",
    "    negative_fit,\n",
    "    run_number,\n",
    "    best_individuals,\n",
    "    averages_all,\n",
    "    averages,\n",
    "    bests_all,\n",
    "    bests,\n",
    "    stds_all,\n",
    "    best_of_all,\n",
    "    stds_best_all,\n",
    "    indivs,\n",
    "    indiv_fits,\n",
    "    indivs_epochs,\n",
    "    indivs_per_epoch,\n",
    "    boa_fit,\n",
    "    run_best,\n",
    "    unique_indivs\n",
    "):\n",
    "\n",
    "\n",
    "\n",
    "    # loop over runs\n",
    "    for result in results:\n",
    "        run = 0\n",
    "        unique_indivs.append([])\n",
    "\n",
    "        for generation in len(result):\n",
    "            \n",
    "            averages.append([])\n",
    "            bests.append([])\n",
    "            stds_all.append([])\n",
    "            indivs_per_epoch.append([])\n",
    "            best_of_all.append(0)\n",
    "            stds_best_all.append(0)\n",
    "            unique_indivs[run].append([])\n",
    "            all_fits = []\n",
    "            best = 0\n",
    "            if generation < len(result):\n",
    "            # loop over inds\n",
    "                for indiv in result[generation]:\n",
    "                    if negative_fit:\n",
    "                        indiv[\"fitness\"] *= -1\n",
    "                    indiv[\"run\"] = run\n",
    "                    if \"smart_phenotype\" not in indiv:\n",
    "                        indiv[\"smart_phenotype\"] = smart_phenotype(indiv[\"phenotype\"])\n",
    "                    if indiv[\"smart_phenotype\"] not in unique_indivs[run][generation]:\n",
    "                        unique_indivs[run][generation].append(indiv)\n",
    "                    indivs.append(indiv)\n",
    "                    indiv_fits.append(indiv[\"fitness\"])\n",
    "                    indivs_epochs.append(generation)\n",
    "                    indivs_per_epoch[generation].append(indiv[\"fitness\"])\n",
    "                    if indiv[\"fitness\"] > run_best[run]:\n",
    "                        run_best[run] = indiv[\"fitness\"]\n",
    "                    if indiv[\"fitness\"] > best:\n",
    "                        best = indiv[\"fitness\"]\n",
    "                        if indiv[\"fitness\"] > boa_fit:\n",
    "                            boa_fit = best\n",
    "                            best_individuals[generation] = {\n",
    "                                \"fitness\": boa_fit,\n",
    "                                \"phenotype\": indiv[\"phenotype\"],\n",
    "                                \"smart_phenotype\": indiv[\"smart_phenotype\"],\n",
    "                            }\n",
    "                    best = best if indiv[\"fitness\"] < best else indiv[\"fitness\"]\n",
    "                    all_fits.append(indiv[\"fitness\"])\n",
    "                averages[generation].append(np.average(all_fits))\n",
    "                stds_all[generation].append(np.std(all_fits))\n",
    "                bests[generation].append(best)\n",
    "                stds_best_all[generation] = np.std(bests[generation])\n",
    "                stds_all[generation] = np.std(averages[generation])\n",
    "                averages_all.append(np.average(averages[generation]))\n",
    "                best_of_all[generation] = np.max(bests[generation])\n",
    "                bests_all.append(np.average(bests[generation]))\n",
    "\n",
    "    processed_result = {\n",
    "        \"averages\": averages,\n",
    "        \"bests\": bests,\n",
    "        \"averages_all\": averages_all,\n",
    "        \"bests_all\": bests_all,\n",
    "        \"indivs\": indivs,\n",
    "        \"indivs_epochs\": indivs_epochs,\n",
    "        \"unique_indivs\": unique_indivs\n",
    "    }\n",
    "\n",
    "    return processed_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots using the cell below\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available plots:\n",
    "\n",
    "[LINE PLOT] Show fitness over generations:\n",
    "\n",
    "`plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])`\n",
    "\n",
    "[HEAT MAP] Show the distribution of population fitness over generations:\n",
    "\n",
    "`pop_density_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "[LINE PLOT] Unique individuals over generation:\n",
    "\n",
    "`unique_indivs_curve(data[\"indivs_epochs\"], data[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "[HEAT MAP] Unique individuals distribution of fitness over generations:\n",
    "\n",
    "`unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "## You can filter the results in the last three plots using these settings:\n",
    "\n",
    "`fit_floor` - Only show results for individuals above this fitness\n",
    "\n",
    "`fit_ceil` - Only show results for individuals below this fitness\n",
    "\n",
    "`gen_floor` - Only show results after this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "`gen_ceiling` - Only show results before this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "You can also use `columns, rows` to adjust the ratio and detail of the heatmaps.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1] + 1) - 0.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0] + 1) - 0.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle=\"-\", linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(\n",
    "    im,\n",
    "    data=None,\n",
    "    valfmt=\"{x:.2f}\",\n",
    "    textcolors=(\"black\", \"white\"),\n",
    "    threshold=None,\n",
    "    **textkw\n",
    "):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max()) / 2.0\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\", verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "def trim_phenotype(phenotype):\n",
    "    if \"shape\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", shape=shape, dtype=tf.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.math.\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.\", \"\")\n",
    "        functions = phenotype.split(r\"lambda shape,  alpha\")\n",
    "\n",
    "    elif \"size\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", size=size, dtype=torch.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"torch.\", \"\")\n",
    "        functions = phenotype.split(r\"lambda size, alpha\")\n",
    "\n",
    "    else:\n",
    "        raise Exception()\n",
    "\n",
    "    return functions\n",
    "\n",
    "\n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string = functions[2][14:-2]\n",
    "    sigma_func_string = functions[3][21:-2]\n",
    "    grad_func_string = functions[-1][21:]\n",
    "\n",
    "    return grad_func_string\n",
    "\n",
    "def plot_fit(epochs, averages_all, averages, bests_all, bests, task=None, folder=None):\n",
    "    \n",
    "    #fill unexistent values with 0s \n",
    "    max_len = len(max(averages, key = len))\n",
    "    for average_index in range(0, len(averages)):\n",
    "        if len(averages[average_index]) < max_len:\n",
    "            for index in range(len(averages[average_index]), max_len):\n",
    "                averages[average_index].append(0)\n",
    "                bests[average_index].append(0)\n",
    "\n",
    "    plt.figure(facecolor=\"#eff2f1\")\n",
    "\n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(color=\"#eff2f1\")\n",
    "    ax.spines[\"bottom\"].set_color(\"#08415c\")\n",
    "    ax.spines[\"top\"].set_color(\"#08415c\")\n",
    "    ax.spines[\"left\"].set_color(\"#08415c\")\n",
    "    ax.spines[\"right\"].set_color(\"#08415c\")\n",
    "    ax.xaxis.label.set_color(\"#08415c\")\n",
    "    ax.yaxis.label.set_color(\"#08415c\")\n",
    "    ax.tick_params(axis=\"x\", colors=\"#08415c\")\n",
    "    ax.tick_params(axis=\"y\", colors=\"#08415c\")\n",
    "    plt.plot(epochs, averages_all, label=\"average\", color=\"#7796cb\")\n",
    "    plt.plot(\n",
    "        epochs, averages, label=\"populations averages\", color=\"#5596cb\", linewidth=0.5\n",
    "    )\n",
    "    # plt.fill_between(epochs, [i + j for i, j in zip(averages_all, stds_aall)], [i - j for i, j in zip(averages_all, stds_all)], alpha=0.2)\n",
    "    plt.plot(epochs, bests_all, label=\"best average\", color=\"#EFA00B\")\n",
    "    plt.plot(epochs, bests, label=\"bests\", color=\"#EFA20B\", linewidth=0.5)\n",
    "    # plt.fill_between(epochs, [i + j for i, j in zip(bests_all, stds_best_all)], [i - j for i, j in zip(bests_all, stds_best_all)], alpha=0.2)\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.savefig(folder / f\"best_average_evolution{run_number}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def pop_density_heatmap(\n",
    "    epochs,\n",
    "    indivs,\n",
    "    rows=10,\n",
    "    columns=10,\n",
    "    fit_floor=0,\n",
    "    fit_ceil=1,\n",
    "    gen_floor=0.0,\n",
    "    gen_ceil=100.0,\n",
    "    task=None,\n",
    "    folder=None,\n",
    "):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [\n",
    "        f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\"\n",
    "        for x in range(rows)\n",
    "    ]\n",
    "    columns_labels = [\n",
    "        f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\"\n",
    "        for x in range(columns)\n",
    "    ]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if (\n",
    "            indiv[\"fitness\"] >= fit_floor\n",
    "            and indiv[\"fitness\"] <= fit_ceil\n",
    "            and epoch > gen_floor\n",
    "            and epoch < gen_ceil\n",
    "        ):\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(\n",
    "        heatmap_matrix,\n",
    "        row_labels,\n",
    "        col_labels=columns_labels,\n",
    "        ax=ax,\n",
    "        cbarlabel=\"indiv count\",\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    texts = annotate_heatmap(im, valfmt=\"{x:.1E}\")\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.title(\"Individuals Density Heatmap (Generations vs Fitness)\")\n",
    "    plt.savefig(os.path.join(folder, f\"pop_density_evolution{run_number}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def unique_indivs_heatmap(\n",
    "    epochs,\n",
    "    indivs,\n",
    "    rows=10,\n",
    "    columns=10,\n",
    "    fit_floor=0,\n",
    "    fit_ceil=1,\n",
    "    gen_floor=0.0,\n",
    "    gen_ceil=100.0,\n",
    "    task=None,\n",
    "    folder=None,\n",
    "):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [\n",
    "        f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\"\n",
    "        for x in range(rows)\n",
    "    ]\n",
    "    columns_labels = [\n",
    "        f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\"\n",
    "        for x in range(columns)\n",
    "    ]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if (\n",
    "            indiv[\"fitness\"] >= fit_floor\n",
    "            and indiv[\"fitness\"] <= fit_ceil\n",
    "            and epoch > gen_floor\n",
    "            and epoch < gen_ceil\n",
    "        ):\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if (\n",
    "                indiv[\"smart_phenotype\"]\n",
    "                not in unique_indivs_record[row_index][column_index]\n",
    "            ):\n",
    "                if epoch == epochs[-1]:\n",
    "                    # print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(\n",
    "                    indiv[\"smart_phenotype\"]\n",
    "                )\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(\n",
    "        heatmap_matrix,\n",
    "        row_labels,\n",
    "        col_labels=columns_labels,\n",
    "        ax=ax,\n",
    "        cbarlabel=\"unique indiv count\",\n",
    "        cmap=\"Greys\",\n",
    "    )\n",
    "    texts = annotate_heatmap(im)\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.title(\"Unique Individuals Density Heatmap (Generations vs Fitness)\")\n",
    "    plt.savefig(os.path.join(folder, f\"pop_unique_ind_fit_evolution{run_number}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def unique_indivs_curve(\n",
    "    epochs,\n",
    "    indivs,\n",
    "    fit_floor=0,\n",
    "    fit_ceil=1,\n",
    "    gen_floor=0.0,\n",
    "    gen_ceil=100.0,\n",
    "    task=None,\n",
    "    folder=None,\n",
    "):\n",
    "    rows = 1\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    columns = int(epoch_len)\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [\n",
    "        f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\"\n",
    "        for x in range(rows)\n",
    "    ]\n",
    "    columns_labels = [\n",
    "        f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\"\n",
    "        for x in range(columns)\n",
    "    ]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if (\n",
    "            indiv[\"fitness\"] >= fit_floor\n",
    "            and indiv[\"fitness\"] <= fit_ceil\n",
    "            and epoch > gen_floor\n",
    "            and epoch < gen_ceil\n",
    "        ):\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if (\n",
    "                indiv[\"smart_phenotype\"]\n",
    "                not in unique_indivs_record[row_index][column_index]\n",
    "            ):\n",
    "                if epoch == epochs[-1]:\n",
    "                    # print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(\n",
    "                    indiv[\"smart_phenotype\"]\n",
    "                )\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    # print([heatmap_matrix[row] for row in range(len(heatmap_matrix))])\n",
    "    plt.plot(\n",
    "        [x for x in range(columns)],\n",
    "        np.transpose([heatmap_matrix[row] for row in range(len(heatmap_matrix))]),\n",
    "    )\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Number of Uniques\")\n",
    "    plt.title(\"Number of Unique Behaviours throughout Evolution\")\n",
    "    plt.savefig(os.path.join(folder, f\"unique_inds_evo{run_number}.png\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, rows = (40, 10)\n",
    "plt.rcParams[\"figure.figsize\"] = [columns, rows]\n",
    "# plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])\n",
    "\n",
    "fit_floor = 0.0\n",
    "fit_ceil = 1.0\n",
    "gen_floor = 0.0\n",
    "# gen_ceil = float(len(data['epochs']))\n",
    "gen_ceil = float(len(data_agnostic[\"epochs\"]))\n",
    "\n",
    "# unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "plot_fit(\n",
    "    data_agnostic[\"epochs\"],\n",
    "    data_agnostic[\"averages_all\"],\n",
    "    data_agnostic[\"bests_all\"],\n",
    "    data_agnostic[\"task\"],\n",
    ")\n",
    "pop_density_heatmap(\n",
    "    data_agnostic[\"indivs_epochs\"],\n",
    "    data_agnostic[\"indivs\"],\n",
    "    rows=rows,\n",
    "    columns=columns,\n",
    "    fit_floor=fit_floor,\n",
    "    fit_ceil=fit_ceil,\n",
    "    gen_floor=gen_floor,\n",
    "    gen_ceil=gen_ceil,\n",
    "    task=data_agnostic[\"task\"],\n",
    ")\n",
    "unique_indivs_heatmap(\n",
    "    data_agnostic[\"indivs_epochs\"],\n",
    "    data_agnostic[\"indivs\"],\n",
    "    rows=rows,\n",
    "    columns=columns,\n",
    "    fit_floor=fit_floor,\n",
    "    fit_ceil=fit_ceil,\n",
    "    gen_floor=gen_floor,\n",
    "    gen_ceil=gen_ceil,\n",
    "    task=data_agnostic[\"task\"],\n",
    ")\n",
    "unique_indivs_curve(\n",
    "    data_agnostic[\"indivs_epochs\"],\n",
    "    data_agnostic[\"indivs\"],\n",
    "    fit_floor=fit_floor,\n",
    "    fit_ceil=fit_ceil,\n",
    "    gen_floor=gen_floor,\n",
    "    gen_ceil=gen_ceil,\n",
    "    task=data_agnostic[\"task\"],\n",
    ")\n",
    "# plt.vlines([0,2,6,9,11,16,23,29,30,31,35,36,42,45,47,54,55,75],0,100,colors='red')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data and plot in one go\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loop(run_number, tasks, folders, over_folder):\n",
    "    for folder in folders:\n",
    "        for task in tasks:\n",
    "            folder_path = os.path.join(over_folder, folder)\n",
    "            subfold_path = Path(folder_path, task)\n",
    "            subfold_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            results = load_results(folder=folder_path, task=task, run_number=run_number)\n",
    "            data = process_results(results=results, run_number=run_number)\n",
    "\n",
    "            columns, rows = (40, 10)\n",
    "            plt.rcParams[\"figure.figsize\"] = [columns, rows]\n",
    "\n",
    "            fit_floor = 0.15\n",
    "            fit_ceil = 1.0\n",
    "            gen_floor = 0.0\n",
    "            gen_ceil = float(len(data[\"epochs\"]))\n",
    "\n",
    "            plot_fit(\n",
    "                data[\"epochs\"],\n",
    "                data[\"averages_all\"],\n",
    "                data[\"averages\"],\n",
    "                data[\"bests_all\"],\n",
    "                data[\"bests\"],\n",
    "                data[\"task\"],\n",
    "                folder=subfold_path,\n",
    "            )\n",
    "            pop_density_heatmap(\n",
    "                data[\"indivs_epochs\"],\n",
    "                data[\"indivs\"],\n",
    "                rows=rows,\n",
    "                columns=columns,\n",
    "                fit_floor=fit_floor,\n",
    "                fit_ceil=fit_ceil,\n",
    "                gen_floor=gen_floor,\n",
    "                gen_ceil=gen_ceil,\n",
    "                task=data[\"task\"],\n",
    "                folder=subfold_path,\n",
    "            )\n",
    "            unique_indivs_heatmap(\n",
    "                data[\"indivs_epochs\"],\n",
    "                data[\"indivs\"],\n",
    "                rows=rows,\n",
    "                columns=columns,\n",
    "                fit_floor=fit_floor,\n",
    "                fit_ceil=fit_ceil,\n",
    "                gen_floor=gen_floor,\n",
    "                gen_ceil=gen_ceil,\n",
    "                task=data[\"task\"],\n",
    "                folder=subfold_path,\n",
    "            )\n",
    "    # unique_indivs_curve(data[\"indivs_epochs\"], data[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data['task'], folder = folder)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = range(1, 31) #upper limit is number of runs + 1, assumes they exist\n",
    "folders = [\"many_runs_no_crossover\"] #this has to correspond to the name of the folders\n",
    "tasks = [\"fmni\"] #this has to correspond to the name of the folders\n",
    "over_folder = \"many_results\\\\\"\n",
    "\n",
    "plot_loop(run_number, tasks, folders, over_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run t-tests \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = range(1, 31)\n",
    "task1 = \"fmni\"\n",
    "folder1 = \"many_results\\\\many_runs\"\n",
    "folder2 = \"many_results\\\\many_runs_old_mut\"\n",
    "folder3 = \"many_results\\\\many_runs_no_crossover\"\n",
    "folder4 = \"many_results\\\\many_runs_new_crossover\"\n",
    "\n",
    "data_f1_t1 = process_results(\n",
    "    load_results(folder=folder1, task=task1, run_number=run_number)\n",
    ")\n",
    "data_f2_t1 = process_results(load_results(folder=folder2, task=task1 ,run_number=run_number))\n",
    "data_f3_t1 = process_results(load_results(folder=folder3, task=task1 ,run_number=run_number))\n",
    "data_f4_t1 = process_results(load_results(folder=folder4, task=task1 ,run_number=run_number))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on performance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run t-test using [this][link to test]\n",
    "\n",
    "[link to test]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_final = 200\n",
    "\n",
    "print(\"NEW\")\n",
    "print(\"Bests over runs\")\n",
    "print(data_f1_t1[\"bests\"][gen_final])\n",
    "print(\"Best average over runs\")\n",
    "print(data_f1_t1[\"bests_all\"][gen_final])\n",
    "print(\"Best of all\")\n",
    "print(max(data_f1_t1[\"bests\"][gen_final]))\n",
    "print(\n",
    "    \"run\"\n",
    "    + \"% s\"\n",
    "    % (data_f1_t1[\"bests\"][gen_final].index(max(data_f1_t1[\"bests\"][gen_final])) + 1)\n",
    ")\n",
    "print(\"NEW_+_CROSSOVER\")\n",
    "print(\"Bests over runs\")\n",
    "print(data_f4_t1[\"bests\"][gen_final])\n",
    "print(\"Best average over runs\")\n",
    "print(data_f4_t1[\"bests_all\"][gen_final])\n",
    "print(\"Best of all\")\n",
    "print(max(data_f4_t1[\"bests\"][gen_final]))\n",
    "print(\n",
    "    \"run\"\n",
    "    + \"% s\"\n",
    "    % (data_f4_t1[\"bests\"][gen_final].index(max(data_f4_t1[\"bests\"][gen_final])) + 1)\n",
    ")\n",
    "print(\"OLD\")\n",
    "print(\"Bests over runs\")\n",
    "print(data_f2_t1[\"bests\"][gen_final])\n",
    "print(\"Best average over runs\")\n",
    "print(data_f2_t1[\"bests_all\"][gen_final])\n",
    "print(\"Best of all\")\n",
    "print(max(data_f2_t1[\"bests\"][gen_final]))\n",
    "print(\n",
    "    \"run\"\n",
    "    + \"% s\"\n",
    "    % (data_f2_t1[\"bests\"][gen_final].index(max(data_f2_t1[\"bests\"][gen_final])) + 1)\n",
    ")\n",
    "print(\"OLD_NO_CROSSOVER\")\n",
    "print(\"Bests over runs\")\n",
    "print(data_f3_t1[\"bests\"][gen_final])\n",
    "print(\"Best average over runs\")\n",
    "print(data_f3_t1[\"bests_all\"][gen_final])\n",
    "print(\"Best of all\")\n",
    "print(max(data_f3_t1[\"bests\"][gen_final]))\n",
    "print(\n",
    "    \"run\"\n",
    "    + \"% s\"\n",
    "    % (data_f3_t1[\"bests\"][gen_final].index(max(data_f3_t1[\"bests\"][gen_final])) + 1)\n",
    ")\n",
    "\n",
    "# bests\n",
    "bests_fmni_new_vs_old = stats.ttest_ind(\n",
    "    data_f1_t1[\"bests\"][gen_final], data_f2_t1[\"bests\"][gen_final], equal_var=False\n",
    ")\n",
    "bests_fmni_new_vs_old_no_crossover = stats.ttest_ind(\n",
    "    data_f1_t1[\"bests\"][gen_final], data_f3_t1[\"bests\"][gen_final], equal_var=False\n",
    ")\n",
    "bests_fmni_new_cr_vs_old = stats.ttest_ind(\n",
    "    data_f4_t1[\"bests\"][gen_final], data_f2_t1[\"bests\"][gen_final], equal_var=False\n",
    ")\n",
    "bests_fmni_new_cr_vs_old_no_crossover = stats.ttest_ind(\n",
    "    data_f4_t1[\"bests\"][gen_final], data_f3_t1[\"bests\"][gen_final], equal_var=False\n",
    ")\n",
    "\n",
    "# averages\n",
    "avg_fmni_new_vs_old = stats.ttest_ind(\n",
    "    data_f1_t1[\"averages\"][gen_final],\n",
    "    data_f2_t1[\"averages\"][gen_final],\n",
    "    equal_var=False,\n",
    ")\n",
    "avg_fmni_new_vs_old_no_crossover = stats.ttest_ind(\n",
    "    data_f1_t1[\"averages\"][gen_final],\n",
    "    data_f3_t1[\"averages\"][gen_final],\n",
    "    equal_var=False,\n",
    ")\n",
    "avg_fmni_new_cr_vs_old = stats.ttest_ind(\n",
    "    data_f4_t1[\"averages\"][gen_final],\n",
    "    data_f2_t1[\"averages\"][gen_final],\n",
    "    equal_var=False,\n",
    ")\n",
    "avg_fmni_new_cr_vs_old_no_crossover = stats.ttest_ind(\n",
    "    data_f4_t1[\"averages\"][gen_final],\n",
    "    data_f3_t1[\"averages\"][gen_final],\n",
    "    equal_var=False,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-tests results\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_fmni_new_vs_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_fmni_new_vs_old_no_crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.9887119080090355, pvalue=0.3392886432356981)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests_fmni_new_cr_vs_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.010868437352302857, pvalue=0.9914065992871433)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bests_fmni_new_cr_vs_old_no_crossover\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### averages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fmni_new_vs_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fmni_new_vs_old_no_crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=18.335165565361386, pvalue=3.1753912265594224e-11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fmni_new_cr_vs_old\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=7.912822662232713, pvalue=2.8168746443433848e-09)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_fmni_new_cr_vs_old_no_crossover\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on diversity\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_inds_for_gen(data, gen_range, fit_floor):\n",
    "    indivs = data[\"indivs\"]\n",
    "    epochs = data[\"indivs_epochs\"]\n",
    "    ind_epochs = zip(epochs, indivs)\n",
    "    unique_counts = [0] * len(gen_range)\n",
    "    unique_phens = [[0]] * len(gen_range)\n",
    "\n",
    "    for epoch, indiv in ind_epochs:\n",
    "        if epoch in gen_range:\n",
    "            # offset index deepnding on first generation to be recorde so that it starts with 1\n",
    "            unique_index = epoch - gen_range.start\n",
    "            if indiv[\"smart_phenotype\"] not in unique_phens[unique_index]:\n",
    "                unique_phens[unique_index].append(indiv[\"smart_phenotype\"])\n",
    "                if indiv[\"fitness\"] >= fit_floor:\n",
    "                    unique_counts[unique_index] += 1\n",
    "\n",
    "    return unique_counts\n",
    "\n",
    "\n",
    "def find_last_unique_gen(data):\n",
    "    unique_indivs_1 = data[\"unique_indivs\"]\n",
    "    min_lengths = []\n",
    "    max_length = len(max(unique_indivs_1, key=len))\n",
    "\n",
    "    return min_lengths\n",
    "\n",
    "def find_last_unique_gen_in_common(data1, data2):\n",
    "    unique_indivs_1 = data1[\"unique_indivs\"]\n",
    "    unique_indivs_2 = data2[\"unique_indivs\"]\n",
    "    max_length = len(max(unique_indivs_1, key=len))\n",
    "    min_lengths = []\n",
    "    \n",
    "    # find minimum row in which number of elemnts is not the maximimu,\n",
    "    for run in range(0, len(unique_indivs_1)):\n",
    "        vecs = [unique_indivs_1[run], unique_indivs_2[run]]\n",
    "        min_lengths.append(min(len(min(vecs, key = len)), max_length) - 1)\n",
    "    return min_lengths\n",
    "\n",
    "def count_uniques_above_fitness_floor(unique_inds, min_lengths, fitness_floor):\n",
    "    count = []\n",
    "    for run, min_gen in zip(unique_inds, min_lengths):\n",
    "        run_count = 0\n",
    "        if min_gen < 0 :\n",
    "            continue\n",
    "        for indiv in run[min_gen]:\n",
    "            if indiv[\"fitness\"] > fitness_floor:\n",
    "                run_count += 1\n",
    "        count.append(run_count)\n",
    "    return count\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_floor =0.5\n",
    "\n",
    "fmni_new_vs_old = stats.ttest_ind(\n",
    "  count_uniques_above_fitness_floor(data_f1_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f1_t1, data_f2_t1), fitness_floor=fit_floor),\n",
    "  count_uniques_above_fitness_floor(data_f2_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f1_t1, data_f2_t1), fitness_floor=fit_floor),\n",
    "  equal_var=False\n",
    ")\n",
    "fmni_new_vs_old_no_crossover = stats.ttest_ind(\n",
    "  count_uniques_above_fitness_floor(data_f1_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f1_t1, data_f3_t1), fitness_floor=fit_floor),\n",
    "  count_uniques_above_fitness_floor(data_f3_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f1_t1, data_f3_t1), fitness_floor=fit_floor),\n",
    "  equal_var=False\n",
    ")\n",
    "fmni_new_cr_vs_old = stats.ttest_ind(\n",
    "  count_uniques_above_fitness_floor(data_f4_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f2_t1), fitness_floor=fit_floor),\n",
    "  count_uniques_above_fitness_floor(data_f2_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f2_t1), fitness_floor=fit_floor),\n",
    "  equal_var=False\n",
    ")\n",
    "fmni_new_cr_vs_old_no_crossover = stats.ttest_ind(\n",
    "  count_uniques_above_fitness_floor(data_f4_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f3_t1), fitness_floor=fit_floor),\n",
    "  count_uniques_above_fitness_floor(data_f3_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f3_t1), fitness_floor=fit_floor),\n",
    "  equal_var=False\n",
    ")\n",
    "fmni_new_cr_vs_new = stats.ttest_ind(\n",
    "  count_uniques_above_fitness_floor(data_f4_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f1_t1), fitness_floor=fit_floor),\n",
    "  count_uniques_above_fitness_floor(data_f1_t1[\"unique_indivs\"], find_last_unique_gen_in_common(data_f4_t1, data_f1_t1), fitness_floor=fit_floor),\n",
    "  equal_var=False\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmni_new_vs_old_no_crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmni_new_vs_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy(paths, labels, styles):\n",
    "    for path, label, style in zip(paths, labels, styles):\n",
    "        data = pd.read_csv(path)\n",
    "        data=data[data['epochs']<1000]\n",
    "        data['loss'].groupby(data['epochs']).mean().plot(label=label + \" Loss\", style=style, xlabel=\"Epochs\", ylabel=\"Loss\")\n",
    "        #data['accuracy'].groupby(data['epochs']).mean().plot(label=label + \" Training Accuracy\", style=style, ylim=(0,1), xlabel=\"Epochs\", ylabel=\"Training Accuracy\")\n",
    "        #data['val_accuracy'].groupby(data['epochs']).mean().plot(label=label + \" Validation Accuracy\", style=style, ylim=(0,1), xlabel=\"Epochs\", ylabel=\"Validation Accuracy\")\n",
    "        #plt.plot(data[\"epochs\"], data[\"accuracy\"], label=label + \" train\")\n",
    "        #plt.plot(data[\"epochs\"], data[\"val_accuracy\"].mean(axis=1), label=label + \" val\")\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(\"C:\\\\Users\\\\lamec\\\\WORK\\\\autolr\\\\results\\\\loss.pdf\")\n",
    "    plt.show()\n",
    "paths = [\n",
    "    \"C:\\\\Users\\\\lamec\\\\WORK\\\\autolr\\\\results\\\\ades_bo_cifar_results.csv\",\n",
    "    \"C:\\\\Users\\\\lamec\\\\WORK\\\\autolr\\\\results\\\\adam_bo_cifar_results.csv\",\n",
    "    \"C:\\\\Users\\\\lamec\\\\WORK\\\\autolr\\\\results\\\\nesterov_bo_cifar_results.csv\",\n",
    "\n",
    "]\n",
    "labels = [\n",
    "    \"ADES\",\n",
    "    \"Adam\",\n",
    "    \"Nesterov\",\n",
    "]\n",
    "styles = [\"-\",\"--\",\":\"]\n",
    "plot_accuracy(paths, labels, styles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.164048758857058, pvalue=1.1775833611403655e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmni_new_cr_vs_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=4.012556482852693, pvalue=0.0008206598182154484)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmni_new_cr_vs_old_no_crossover\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.8228931379338051, pvalue=0.41821118880766694)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmni_new_cr_vs_new\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond this point is code for archive analysis, this is not refined. Do not use unless necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list = []\n",
    "for i in run_number:\n",
    "    it = 1\n",
    "    try:\n",
    "        while True:\n",
    "            archive = load_archive(path, i, it)\n",
    "            it += 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f\"loading archive {it - 1} for run {i}\")\n",
    "        archive = load_archive(path, i, it - 1)\n",
    "        for x in archive:\n",
    "            if \"fitness\" in archive[x]:\n",
    "                archive_list.append([x, archive[x], archive[x][\"fitness\"], i])\n",
    "    except:\n",
    "        print(f\"Run {i} has no archive\")\n",
    "archive_list.sort(key=lambda x: x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    json.dump(archive_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "while it < 10:\n",
    "    print(archive_list[it])\n",
    "    it += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def turn_to_expr(phenotype, tree):\n",
    "    if phenotype == \"\":\n",
    "        return tree\n",
    "\n",
    "    if phenotype[0:9] == \"multiply(\":\n",
    "        # print(\"multiply\")\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"*\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:14] == \"divide_no_nan(\":\n",
    "        phenotype = phenotype[14:]\n",
    "        node = Node(\"/\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"add(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"+\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"pow(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"^\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"subtract(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"grad\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"grad\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"beta\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"beta\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"alpha\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"alpha\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sigma\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sigma\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"negative(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sqrt(\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sqrt\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:7] == \"square(\":\n",
    "        phenotype = phenotype[7:]\n",
    "        node = Node(\"square\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:2] == \", \":\n",
    "        phenotype = phenotype[2:]\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0] == \")\":\n",
    "        phenotype = phenotype[1:]\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"constant(\":\n",
    "        if (\n",
    "            phenotype[9:12] == \"0.0\"\n",
    "            or phenotype[9:13] == \"1.0)\"\n",
    "            or phenotype[9:13] == \"1.0,\"\n",
    "        ):\n",
    "            node = Node(phenotype[9:12], tree, 0)\n",
    "            phenotype = phenotype[12:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()\n",
    "        else:\n",
    "            node = Node(phenotype[9 : 9 + 14], tree, 0)\n",
    "            phenotype = phenotype[9 + 14 :]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    else:\n",
    "        raise Exception(phenotype)\n",
    "\n",
    "\n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string = functions[2][14:-2]\n",
    "    sigma_func_string = functions[3][21:-2]\n",
    "    grad_func_string = functions[-1][21:]\n",
    "\n",
    "    for x in [alpha_func_string, beta_func_string, sigma_func_string, grad_func_string]:\n",
    "        print(x)\n",
    "        turn_to_expr(x, Node(\"\", None, 1)).to_string()\n",
    "\n",
    "    return grad_func_string\n",
    "\n",
    "\n",
    "for indiv in data[\"indivs\"]:\n",
    "    math_phenotype(indiv[\"phenotype\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"multiply(\"\n",
    "print(a[0:9])\n",
    "print(a[9:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import csv\n",
    "from pickle import NONE\n",
    "from utils.data_functions import (\n",
    "    load_fashion_mnist_training,\n",
    "    load_cifar10_training,\n",
    "    load_mnist_training,\n",
    "    select_fashion_mnist_training,\n",
    ")\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from optimizers.custom_optimizer import CustomOptimizer\n",
    "import datetime\n",
    "\n",
    "experiment_time = datetime.datetime.now()\n",
    "\n",
    "cached_dataset = None\n",
    "cached_model = None\n",
    "\n",
    "\n",
    "def train_model_tensorflow_cifar10(phen_params):\n",
    "    phen, params = phen_params\n",
    "    validation_size = params[\"VALIDATION_SIZE\"]\n",
    "    fitness_size = params[\"FITNESS_SIZE\"]\n",
    "    batch_size = params[\"BATCH_SIZE\"]\n",
    "    epochs = params[\"EPOCHS\"]\n",
    "    patience = params[\"PATIENCE\"]\n",
    "\n",
    "    # Note that globals are borderline -- consider an object or a closure\n",
    "    # deliberately using globals() to make it ugly...\n",
    "    if globals()[\"cached_dataset\"] == None:\n",
    "        globals()[\"cached_dataset\"] = load_cifar10_training(\n",
    "            validation_size=validation_size, test_size=fitness_size\n",
    "        )\n",
    "\n",
    "    if globals()[\"cached_model\"] == None:\n",
    "        globals()[\"cached_model\"] = load_model(params[\"MODEL\"], compile=False)\n",
    "\n",
    "    # we assume validation and test sets are deterministic\n",
    "    dataset = globals()[\"cached_dataset\"]\n",
    "    model = tf.keras.models.clone_model(globals()[\"cached_model\"])\n",
    "\n",
    "    weights = model.get_weights()\n",
    "    model.set_weights(weights)\n",
    "\n",
    "    # optimizer is constant aslong as phen doesn't changed?\n",
    "    # -> opportunity to cache opt and compiled model\n",
    "    opt = CustomOptimizer(phen=phen, model=model)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    early_stop = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\", patience=patience, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    score = model.fit(\n",
    "        dataset[\"x_train\"],\n",
    "        dataset[\"y_train\"],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        validation_data=(dataset[\"x_val\"], dataset[\"y_val\"]),\n",
    "        validation_steps=validation_size // batch_size,\n",
    "        callbacks=[early_stop],\n",
    "    )\n",
    "\n",
    "    K.clear_session()\n",
    "    results = {}\n",
    "    for metric in score.history:\n",
    "        results[metric] = []\n",
    "        for n in score.history[metric]:\n",
    "            results[metric].append(n)\n",
    "    test_score = model.evaluate(\n",
    "        x=dataset[\"x_test\"],\n",
    "        y=dataset[\"y_test\"],\n",
    "        verbose=0,\n",
    "        callbacks=[keras.callbacks.History()],\n",
    "    )\n",
    "    return test_score[-1], results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "0357653c69581ed709ad33b04b35df511a3a4051acb4aa15a7fef2257addd2ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
