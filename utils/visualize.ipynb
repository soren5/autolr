{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['figure.figsize'] = [20,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prot_div(left, right):\n",
    "    if right == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return left / right\n",
    "\n",
    "def if_func(condition, state1, state2):\n",
    "    if condition:\n",
    "        return state1\n",
    "    else:\n",
    "        return state2\n",
    "\n",
    "def read_experiment_results(full_path):\n",
    "    dir_name = full_path\n",
    "    results = []\n",
    "    it = 0\n",
    "    try:\n",
    "        while True:\n",
    "            with open(dir_name + 'iteration_' + str(it) + '.json') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if it % 1 == 0:\n",
    "                    print(it)\n",
    "                results.append(data)\n",
    "            it += 1\n",
    "    except:\n",
    "        print(\"Finished reading \", full_path)\n",
    "    return results\n",
    "\n",
    "#extract number from file\n",
    "def extract_number(f):\n",
    "    s = re.findall(\"\\d+$\",f)\n",
    "    return (int(s[0]) if s else -1,f)\n",
    "\n",
    "'''Human sorting of files '''\n",
    "'''From https://nedbatchelder.com/blog/200712/human_sorting.html '''\n",
    "def tryint(s):\n",
    "    \"\"\"\n",
    "    Return an int if possible, or `s` unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "\n",
    "def alphanum_key(s):\n",
    "    \"\"\"\n",
    "    Turn a string into a list of string and number chunks.\n",
    "\n",
    "    >>> alphanum_key(\"z23a\")\n",
    "    [\"z\", 23, \"a\"]\n",
    "\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def human_sort(l):\n",
    "    \"\"\"\n",
    "    Sort a list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "\n",
    "def read_experiment_results_agnostic(full_path):\n",
    "    results = []\n",
    "    filenames = glob.glob(pathname = 'iteration_?*', root_dir = full_path)\n",
    "    filenames_ordered = human_sort(filenames)\n",
    "    try:\n",
    "        for file in filenames:            \n",
    "            json_file = open(Path(os.path.join(full_path, file)))\n",
    "            data = json.load(json_file)\n",
    "            if extract_number(file)[0] % 1 == 0:\n",
    "                print(file)\n",
    "            results.append(data)\n",
    "    except:\n",
    "        print(\"Error in reading results \", full_path)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify where to get results from (not system agnostic version)\n",
    "1. Select the run numbers you want to analyse and include them in the `run_number` list.\n",
    "2. Make sure os_string matches your operating system, this avoid weird bugs when creating paths\n",
    "3. Specify the folder where the runs you selected are found. Make sure to end with `run_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p288427\\Github\\autolr\\many_runs\\cif\\run_15/\n",
      "Finished reading  c:\\Users\\p288427\\Github\\autolr\\many_runs\\cif\\run_15/\n"
     ]
    }
   ],
   "source": [
    "run_number = range(15,16)\n",
    "\n",
    "\n",
    "os_string = \"w10\"\n",
    "results = []\n",
    "if os_string == \"unix\":\n",
    "    path = \"/Users/soren/Downloads/run_\"\n",
    "elif os_string == \"w10\":\n",
    "    path = \"c:\\\\Users\\\\p288427\\\\Github\\\\autolr\\\\many_runs\\\\cif\\\\run_\"\n",
    "for i in run_number: \n",
    "    print((path + str(i) + '/'))\n",
    "    results.append(read_experiment_results(path +  str(i) + '/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify where to get results from and load (system agnostic version).\n",
    "\n",
    "It is necessary to:\n",
    "1. set the folder in `result_folde_path_from_root` as a list of all the folders starting from the root down to the one containing the runs (assumes root is the parent dir of the dir containing this script)\n",
    "2. set the runs numbers to analyze as a range `run_number` between 1 and N where n is the number of runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assuming folder with data for different tasks is in root directory\n",
    "def load_results(folder, task, run_number):\n",
    "  result_folder_path_from_root = os.path.join(folder, task)\n",
    "  results_agnostic = []\n",
    "  path = os.path.join(os.path.dirname(os.path.abspath(os.curdir)), result_folder_path_from_root) \n",
    "  print(path)\n",
    "\n",
    "  for i in run_number: \n",
    "    file_path = os.path.join(path, \"run_\" + str(i))\n",
    "    results_agnostic.append(read_experiment_results_agnostic(file_path))\n",
    "  results_agnostic.append({'task': task})\n",
    "  return results_agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "run_number = range(1,12)\n",
    "task = \"cif_from_fmni\"\n",
    "folder = \"many_runs\"\n",
    "\n",
    "results_agnostic = load_results(folder=folder, task=task,run_number=run_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defintion of functions to plot data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genealogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_phenotype import smart_phenotype, readable_phenotype\n",
    "import random\n",
    "def genealogy_string(results):\n",
    "    import graphviz\n",
    "    epochs = np.arange(len(results[0]))\n",
    "    lineage = []\n",
    "    fitness_color = []\n",
    "    occurences = {}\n",
    "    rendered = set()\n",
    "    prune_cutoff = 20\n",
    "    string = \"\"\"digraph genealogy{\n",
    "fontname=\"Helvetica,Arial,sans-serif\"\n",
    "node [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "edge [fontname=\"Helvetica,Arial,sans-serif\"]\n",
    "# page = \"8.2677165,11.692913\" ;\n",
    "ratio = \"auto\" ;\n",
    "mincross = 2.0 ;\n",
    "label = \"Genealogy\" ;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    connections_string = \"\"\n",
    "    for iteration in epochs:     \n",
    "        for result in results:\n",
    "            for indiv in result[iteration]:\n",
    "                if \"parent\" in indiv:\n",
    "                    for parent in indiv[\"parent\"]:\n",
    "                        if parent in occurences:\n",
    "                            occurences[parent] += 1\n",
    "                        else: \n",
    "                            occurences[parent] = 1\n",
    "                        if indiv['id'] in occurences:\n",
    "                            occurences[indiv['id']] += 1\n",
    "                        else: \n",
    "                            occurences[indiv['id']] = 1  \n",
    "                        lineage.append((parent, indiv['id'], indiv['fitness'] * -1))\n",
    "                fitness_color.append((indiv['id'], indiv['fitness'] * -1))\n",
    "    for parent, child, fitness in set(lineage):\n",
    "        if fitness > 0.12 and occurences[parent] > prune_cutoff and occurences[child] > prune_cutoff:\n",
    "            connections_string+=(f'\\n \"{parent}\" -> \"{child}\" ;')    \n",
    "            rendered.add(parent)\n",
    "            rendered.add(child)\n",
    "    for id, fitness in set(fitness_color):\n",
    "        if fitness > 0.12 and id in rendered:\n",
    "            string+=(f'\\n \"{id}\" [style=filled,fillcolor=\"#{format(int(255-fitness*255), \"x\")}{format(int(255-fitness*255), \"x\")}ff\", width={fitness*10}, height={fitness*10}] ;')\n",
    "\n",
    "    string += connections_string + \"\\n }\"\n",
    "    with open(\"graph.dot\", \"w\") as f:\n",
    "        print(string,file=f)\n",
    "    src = graphviz.Source(string)\n",
    "    src.render('doctest-output/graph.gv', view=True).replace('\\\\', '/')\n",
    "    return string\n",
    "\n",
    "#print(genealogy_string(results))\n",
    "def load_archive(path, run_number, generation):\n",
    "    with open(path + str(run_number) + '\\\\z-archive_' + str(generation) + \".json\", 'r') as f:\n",
    "        archive = json.load(f)\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap and phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        A 2D numpy array of shape (M, N).\n",
    "    row_labels\n",
    "        A list or array of length M with the labels for the rows.\n",
    "    col_labels\n",
    "        A list or array of length N with the labels for the columns.\n",
    "    ax\n",
    "        A `matplotlib.axes.Axes` instance to which the heatmap is plotted.  If\n",
    "        not provided, use current axes or create a new one.  Optional.\n",
    "    cbar_kw\n",
    "        A dictionary with arguments to `matplotlib.Figure.colorbar`.  Optional.\n",
    "    cbarlabel\n",
    "        The label for the colorbar.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to `imshow`.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[1]), labels=col_labels)\n",
    "    ax.set_yticks(np.arange(data.shape[0]), labels=row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    ax.spines[:].set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "    \"\"\"\n",
    "    A function to annotate a heatmap.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im\n",
    "        The AxesImage to be labeled.\n",
    "    data\n",
    "        Data used to annotate.  If None, the image's data is used.  Optional.\n",
    "    valfmt\n",
    "        The format of the annotations inside the heatmap.  This should either\n",
    "        use the string format method, e.g. \"$ {x:.2f}\", or be a\n",
    "        `matplotlib.ticker.Formatter`.  Optional.\n",
    "    textcolors\n",
    "        A pair of colors.  The first is used for values below a threshold,\n",
    "        the second for those above.  Optional.\n",
    "    threshold\n",
    "        Value in data units according to which the colors from textcolors are\n",
    "        applied.  If None (the default) uses the middle of the colormap as\n",
    "        separation.  Optional.\n",
    "    **kwargs\n",
    "        All other arguments are forwarded to each call to `text` used to create\n",
    "        the text labels.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max())/2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "def trim_phenotype(phenotype):\n",
    "    if \"shape\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", shape=shape, dtype=tf.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.math.\", \"\")\n",
    "        phenotype = phenotype.replace(\"tf.\", \"\")\n",
    "        functions = phenotype.split(r'lambda shape,  alpha')\n",
    "\n",
    "    elif \"size\" in phenotype:\n",
    "        phenotype = phenotype.replace(\", size=size, dtype=torch.float32\", \"\")\n",
    "        phenotype = phenotype.replace(\"torch.\", \"\")        \n",
    "        functions = phenotype.split(r'lambda size, alpha')\n",
    "    \n",
    "    else:\n",
    "        raise Exception()\n",
    "\n",
    "    return functions \n",
    "\n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string =functions[2][14:-2] \n",
    "    sigma_func_string =functions[3][21:-2] \n",
    "    grad_func_string = functions[-1][21:]\n",
    "    \n",
    "    return grad_func_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines class node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, symbol, parent, child_count):\n",
    "        self.symbol = symbol\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.child = None\n",
    "        self.parent = parent\n",
    "        self.child_count = child_count\n",
    "            \n",
    "    def insert(self, child):\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                self.left = child\n",
    "            elif self.left.is_full() == False:\n",
    "                #print(f\"inserting in {self.left.symbol}\")\n",
    "                self.left.insert(child)\n",
    "            elif self.right is None:\n",
    "                self.right = child\n",
    "            elif self.right.is_full() == False:\n",
    "                #print(f\"inserting in {self.right.symbol}\")\n",
    "                self.right.insert(child)\n",
    "            else:\n",
    "                raise Exception(f\"All two children are full:{self.symbol}({self.left.symbol}, {self.right.symbol}) [{self.get_root().to_string()}]\")\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                self.child = child\n",
    "            elif self.child.is_full() == False:\n",
    "                #print(f\"inserting in {self.child.symbol}\")\n",
    "                self.child.insert(child)\n",
    "            else:\n",
    "                raise Exception(f\"Child is full: {self.symbol}({self.child.symbol}) [{self.get_root().to_string()}]\")\n",
    "        else:\n",
    "            raise Exception(f\"Insert called on terminal: {self.symbol} [{self.get_root().to_string()}]\")\n",
    "            \n",
    "    def is_full(self):\n",
    "        #print(f\"Calling is full on {self.symbol}\")\n",
    "        full = 0\n",
    "        if self.child_count == 2:\n",
    "            if self.left is None:\n",
    "                full = False\n",
    "            elif self.right is None:\n",
    "                full = False\n",
    "            elif self.left.is_full() and self.right.is_full():\n",
    "                full = True\n",
    "            else: \n",
    "                full = False\n",
    "        elif self.child_count == 1:\n",
    "            if self.child is None:\n",
    "                full = False\n",
    "            elif self.child.is_full():\n",
    "                full = True\n",
    "            else:\n",
    "                full = False\n",
    "        elif self.child_count == 0:\n",
    "            full = True\n",
    "        else:\n",
    "            raise Exception(f\"Symbol {self.symbol} does not 0, 1 or 2 children\")\n",
    "        return full\n",
    "        \n",
    "    def get_next(self):\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def to_string(self):\n",
    "        string = \"\"\n",
    "        if self.child_count == 2:\n",
    "            string +=\"(\" \n",
    "            if self.left is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.left.to_string()\n",
    "            string += self.symbol\n",
    "            if self.right is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.right.to_string()\n",
    "            string += \")\"\n",
    "            \n",
    "        elif self.child_count == 1:\n",
    "            string += self.symbol + \"(\" \n",
    "            if self.child is None:\n",
    "                string += \"_\"\n",
    "            else:\n",
    "                string += self.child.to_string()\n",
    "            string += \")\"\n",
    "        else:\n",
    "            string += self.symbol\n",
    "        return string\n",
    "\n",
    "    def get_root(self):\n",
    "        if self.parent is not None:\n",
    "            return self.parent.get_root()\n",
    "        else:\n",
    "            return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate all the data, it might take a few minutes to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(results, negative_fit=True, run_number=None):\n",
    "    # print(epochs)\n",
    "    best_individuals = {}\n",
    "    averages_all = []\n",
    "    averages = []\n",
    "    bests_all = []\n",
    "    bests = []\n",
    "    stds_all = []\n",
    "    best_of_all = []\n",
    "    stds_best_all = []\n",
    "    indivs = []\n",
    "    indiv_fits = []\n",
    "    indivs_epochs = []\n",
    "    indivs_per_epoch = []\n",
    "    boa_fit = 0\n",
    "    run_best = np.zeros(len(results))\n",
    "\n",
    "    # make sure last elemt corresponds to the task on which the individuals evolved\n",
    "    # store the task to name the processed_results later\n",
    "    # and take it out from data\n",
    "    task = results[-1]\n",
    "    assert type(task) == dict\n",
    "    assert len(task) == 1\n",
    "    assert \"task\" in task\n",
    "    results = results[:-1]\n",
    "    assert type(results[-1]) != dict\n",
    "\n",
    "    # see the max n of gens in results\n",
    "    generations = np.arange(len(max(results, key=len)))\n",
    "\n",
    "    # loop over generations\n",
    "    for generation in generations:\n",
    "        averages.append([])\n",
    "        bests.append([])\n",
    "        stds_all.append([])\n",
    "        indivs_per_epoch.append([])\n",
    "        best_of_all.append(0)\n",
    "        stds_best_all.append(0)\n",
    "        run = 0\n",
    "\n",
    "        # loop over runs\n",
    "        for result in results:\n",
    "            all_fits = []\n",
    "            best = 0\n",
    "            if generation < len(result):\n",
    "                for indiv in result[generation]:\n",
    "                    if negative_fit:\n",
    "                        indiv[\"fitness\"] *= -1\n",
    "                    indiv[\"run\"] = run\n",
    "                    if \"smart_phenotype\" not in indiv:\n",
    "                        indiv[\"smart_phenotype\"] = smart_phenotype(indiv[\"phenotype\"])\n",
    "                    indivs.append(indiv)\n",
    "                    indiv_fits.append(indiv[\"fitness\"])\n",
    "                    indivs_epochs.append(generation)\n",
    "                    indivs_per_epoch[generation].append(indiv[\"fitness\"])\n",
    "                    if indiv[\"fitness\"] > run_best[run]:\n",
    "                        run_best[run] = indiv[\"fitness\"]\n",
    "                        if run_number is None:\n",
    "                            print(\n",
    "                                f'------NEW BEST IN RUN------\\n{generation}-{indiv[\"id\"]}-{boa_fit}\\n{smart_phenotype(indiv[\"phenotype\"])}\\n--------------------'\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                f'------NEW BEST IN RUN {run_number[run]}------\\nEPOCH:{generation}\\nID:{indiv[\"id\"]}-{boa_fit}\\n{readable_phenotype(indiv[\"phenotype\"])}\\n--------------------'\n",
    "                            )\n",
    "                    if indiv[\"fitness\"] > best:\n",
    "                        best = indiv[\"fitness\"]\n",
    "                        if indiv[\"fitness\"] > boa_fit:\n",
    "                            boa_fit = best\n",
    "                            best_individuals[generation] = {\n",
    "                                \"fitness\": boa_fit,\n",
    "                                \"phenotype\": indiv[\"phenotype\"],\n",
    "                                \"smart_phenotype\": smart_phenotype(indiv[\"phenotype\"]),\n",
    "                            }\n",
    "                    best = best if indiv[\"fitness\"] < best else indiv[\"fitness\"]\n",
    "                    all_fits.append(indiv[\"fitness\"])\n",
    "                averages[generation].append(np.average(all_fits))\n",
    "                stds_all[generation].append(np.std(all_fits))\n",
    "                bests[generation].append(best)\n",
    "            run += 1\n",
    "\n",
    "        stds_best_all[generation] = np.std(bests[generation])\n",
    "        stds_all[generation] = np.std(averages[generation])\n",
    "        averages_all.append(np.average(averages[generation]))\n",
    "        best_of_all[generation] = np.max(bests[generation])\n",
    "        bests_all.append(np.average(bests[generation]))\n",
    "        \n",
    "        processed_result = {\n",
    "            \"averages\": averages,\n",
    "            \"bests\": bests,\n",
    "            \"averages_all\": averages_all,\n",
    "            \"bests_all\": bests_all,\n",
    "            \"indivs\": indivs,\n",
    "            \"indivs_epochs\": indivs_epochs,\n",
    "            \"epochs\": generations,\n",
    "        }\n",
    "\n",
    "    # name the data after the task\n",
    "    processed_result.update(task)\n",
    "\n",
    "    return processed_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agnostic = process_results(results_agnostic, run_number=run_number)\n",
    "# data = process_results(results, run_number=run_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run quick t-test to see if average fitness of one generation in a task is significantly different from average fitness in fitness in another task at another generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\p288427\\Github\\autolr\\many_runs\\fmni\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\p288427\\Github\\autolr\\utils\\visualize.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m folder1 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmany_runs\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m folder2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmany_runs_old_mut\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data_f_n \u001b[39m=\u001b[39m process_results(load_results(folder\u001b[39m=\u001b[39;49mfolder1, task\u001b[39m=\u001b[39;49mtask1 ,run_number\u001b[39m=\u001b[39;49mrun_number))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data_f_o \u001b[39m=\u001b[39m process_results(load_results(folder\u001b[39m=\u001b[39mfolder2, task\u001b[39m=\u001b[39mtask1 ,run_number\u001b[39m=\u001b[39mrun_number))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data_c_n \u001b[39m=\u001b[39m process_results(load_results(folder\u001b[39m=\u001b[39mfolder1, task\u001b[39m=\u001b[39mtask2 ,run_number\u001b[39m=\u001b[39mrun_number))\n",
      "\u001b[1;32mc:\\Users\\p288427\\Github\\autolr\\utils\\visualize.ipynb Cell 26\u001b[0m in \u001b[0;36mprocess_results\u001b[1;34m(results, negative_fit, run_number)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtask\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m task\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m results \u001b[39m=\u001b[39m results[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mtype\u001b[39m(results[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]) \u001b[39m!=\u001b[39m \u001b[39mdict\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# see the max n of gens in results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/p288427/Github/autolr/utils/visualize.ipynb#X34sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m generations \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(\u001b[39mmax\u001b[39m(results, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m)))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "run_number = range(1,5)\n",
    "task1 = \"fmni\"\n",
    "task2 = \"cif\"\n",
    "folder1 = \"many_results\\\\many_runs\"\n",
    "folder2 = \"many_results\\\\many_runs_old_mut\"\n",
    "\n",
    "data_f_n = process_results(load_results(folder=folder1, task=task1 ,run_number=run_number))\n",
    "data_f_o = process_results(load_results(folder=folder2, task=task1 ,run_number=run_number))\n",
    "data_c_n = process_results(load_results(folder=folder1, task=task2 ,run_number=run_number))\n",
    "data_c_o = process_results(load_results(folder=folder2, task=task2 ,run_number=run_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run t-test using [this][link to test]\n",
    "\n",
    "[link to test]: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gens_from_start = 30\n",
    "gens_before_trasfer = 100\n",
    "\n",
    "\"\"\" bests_around_same_time = stats.ttest_ind(\n",
    "    data_1[\"bests\"][gens_from_start],\n",
    "    data_2[\"bests\"][gens_before_trasfer + gens_from_start],\n",
    "    equal_var= False\n",
    ")\n",
    " \"\"\"\n",
    "bests_start = stats.ttest_ind(\n",
    "    data_f_n[\"bests\"][gens_from_start],\n",
    "    data_f_o[\"bests\"][gens_from_start],\n",
    "    equal_var= False\n",
    ")\n",
    "\n",
    "\"\"\" inds_around_same_time = stats.ttest_ind(\n",
    "    data_1[\"averages\"][gens_from_start],\n",
    "    data_2[\"averages\"][gens_before_trasfer + gens_from_start],\n",
    "    equal_var= False\n",
    ") \"\"\"\n",
    "\n",
    "inds_start = stats.ttest_ind(\n",
    "    data_c_n[\"averages\"][gens_from_start],\n",
    "    data_c_o[\"averages\"][gens_from_start],\n",
    "    equal_var= False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-tests results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_around_same_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bests_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_around_same_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots using the cell below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for plotting\n",
    "\n",
    "### Available plots:\n",
    "[LINE PLOT] Show fitness over generations: \n",
    "\n",
    "`plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])`\n",
    "\n",
    "\n",
    "[HEAT MAP] Show the distribution of population fitness over generations: \n",
    "\n",
    "`pop_density_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "[LINE PLOT] Unique individuals over generation:\n",
    "\n",
    " `unique_indivs_curve(data[\"indivs_epochs\"], data[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "[HEAT MAP] Unique individuals distribution of fitness over generations:\n",
    "\n",
    "`unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)`\n",
    "\n",
    "\n",
    "## You can filter the results in the last three plots using these settings:\n",
    "\n",
    "`fit_floor` - Only show results for individuals above this fitness\n",
    "\n",
    "`fit_ceil` - Only show results for individuals below this fitness\n",
    "\n",
    "`gen_floor` - Only show results after this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "`gen_ceiling` - Only show results before this generation (THIS MUST BE A FLOAT)\n",
    "\n",
    "You can also use `columns, rows` to adjust the ratio and detail of the heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_fit(epochs, averages_all, bests_all, task = None): \n",
    "    plt.figure(facecolor='#eff2f1')\n",
    "    \n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(color=\"#eff2f1\")\n",
    "    ax.spines['bottom'].set_color('#08415c')\n",
    "    ax.spines['top'].set_color('#08415c')\n",
    "    ax.spines['left'].set_color('#08415c')\n",
    "    ax.spines['right'].set_color('#08415c')\n",
    "    ax.xaxis.label.set_color('#08415c')\n",
    "    ax.yaxis.label.set_color('#08415c')\n",
    "    ax.tick_params(axis='x', colors='#08415c')\n",
    "    ax.tick_params(axis='y', colors=\"#08415c\")\n",
    "    plt.plot(epochs, averages_all, label='population average', color=\"#7796cb\")\n",
    "    #plt.fill_between(epochs, [i + j for i, j in zip(averages_all, stds_aall)], [i - j for i, j in zip(averages_all, stds_all)], alpha=0.2)\n",
    "    plt.plot(epochs, bests_all, label='best average', color=\"#EFA00B\")   \n",
    "    #plt.fill_between(epochs, [i + j for i, j in zip(bests_all, stds_best_all)], [i - j for i, j in zip(bests_all, stds_best_all)], alpha=0.2)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.savefig(f'{task}_best_average_evolution{run_number}.png')\n",
    "    plt.savefig(f'{task}_best_average_evolution{run_number}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def pop_density_heatmap(epochs, indivs, rows=10, columns=10, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0, task = None):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(heatmap_matrix, row_labels, col_labels=columns_labels, ax=ax, cbarlabel=\"indiv count\", cmap=\"Greys\")\n",
    "    texts = annotate_heatmap(im,valfmt=\"{x:.1E}\")\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Individuals Density Heatmap (Generations vs Fitness)')\n",
    "    plt.savefig(f'{task}_pop_density_evolution{run_number}.png')\n",
    "    plt.savefig(f'{task}_pop_density_evolution{run_number}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def unique_indivs_heatmap(epochs, indivs, rows=10, columns=10, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0, task = None):\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if indiv[\"smart_phenotype\"] not in unique_indivs_record[row_index][column_index]:\n",
    "                if epoch == epochs[-1]:\n",
    "                    #print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(indiv[\"smart_phenotype\"])\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    fig, ax = plt.subplots()\n",
    "    im, cbar = heatmap(heatmap_matrix, row_labels, col_labels=columns_labels, ax=ax, cbarlabel=\"unique indiv count\", cmap=\"Greys\")\n",
    "    texts = annotate_heatmap(im)\n",
    "    fig.tight_layout()\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Unique Individuals Density Heatmap (Generations vs Fitness)')\n",
    "    plt.savefig(f'{task}_pop_unique_ind_fit_evolution{run_number}.png')\n",
    "    plt.savefig(f'{task}_pop_unique_ind_fit_evolution{run_number}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def unique_indivs_curve(epochs, indivs, fit_floor=0, fit_ceil=1, gen_floor=0.0, gen_ceil=100.0, task = None):\n",
    "    rows = 1\n",
    "    epoch_len = gen_ceil - gen_floor\n",
    "    columns = int(epoch_len)\n",
    "    heatmap_matrix = np.zeros((rows, columns), dtype=np.int32)\n",
    "    unique_indivs_record = {}\n",
    "    fit_range = fit_ceil - fit_floor\n",
    "    row_labels = [f\"{(fit_range) / rows * x + fit_floor:.2f},{(fit_range) / rows * (x + 1) + fit_floor:.2f}\" for x in range(rows)]\n",
    "    columns_labels = [f\"{int((epoch_len) / columns * x)},{int((epoch_len) / columns * (x + 1))}\" for x in range(columns)]\n",
    "    for epoch, indiv in zip(epochs, indivs):\n",
    "        if indiv[\"fitness\"] >= fit_floor and indiv[\"fitness\"] <= fit_ceil and epoch > gen_floor and epoch < gen_ceil:\n",
    "            row_index = int((indiv[\"fitness\"] - fit_floor) / fit_range * rows)\n",
    "            column_index = int(float(epoch) / float(epoch_len) * columns)\n",
    "            if row_index not in unique_indivs_record:\n",
    "                unique_indivs_record[row_index] = {}\n",
    "            if column_index not in unique_indivs_record[row_index]:\n",
    "                unique_indivs_record[row_index][column_index] = []\n",
    "            if indiv[\"smart_phenotype\"] not in unique_indivs_record[row_index][column_index]:\n",
    "                if epoch == epochs[-1]:\n",
    "                    #print(indiv[\"smart_phenotype\"])\n",
    "                    pass\n",
    "                unique_indivs_record[row_index][column_index].append(indiv[\"smart_phenotype\"])\n",
    "                heatmap_matrix[row_index][column_index] += 1\n",
    "    #print([heatmap_matrix[row] for row in range(len(heatmap_matrix))])\n",
    "    plt.plot([x for x in range(columns)], np.transpose([heatmap_matrix[row] for row in range(len(heatmap_matrix))]))\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Number of Uniques')\n",
    "    plt.title('Number of Unique Behaviours throughout Evolution')\n",
    "    plt.savefig(f'{task}_unique_inds_evo{run_number}.png')\n",
    "    plt.savefig(f'{task}_unique_inds_evo{run_number}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns, rows = (40, 10)\n",
    "plt.rcParams['figure.figsize'] = [columns, rows]\n",
    "#plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'])\n",
    "\n",
    "fit_floor = 0.0\n",
    "fit_ceil = 1.0\n",
    "gen_floor = 0.0\n",
    "# gen_ceil = float(len(data['epochs']))\n",
    "gen_ceil = float(len(data_agnostic['epochs']))\n",
    "\n",
    "#unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil)\n",
    "plot_fit(data_agnostic[\"epochs\"], data_agnostic['averages_all'], data_agnostic['bests_all'], data_agnostic['task'])\n",
    "pop_density_heatmap(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data_agnostic['task'])\n",
    "unique_indivs_heatmap(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data_agnostic['task'])\n",
    "unique_indivs_curve(data_agnostic[\"indivs_epochs\"], data_agnostic[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data_agnostic['task'])\n",
    "#plt.vlines([0,2,6,9,11,16,23,29,30,31,35,36,42,45,47,54,55,75],0,100,colors='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the data and plot in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_number = range(1,4)\n",
    "tasks = [\"fmni\", \"cif\"]\n",
    "folder = \"many_runs_old_mut\"\n",
    "\n",
    "for task in tasks:\n",
    "  results = load_results(folder=folder, task=task, run_number=run_number)\n",
    "  data = process_results(results= results, run_number=run_number)\n",
    "\n",
    "  columns, rows = (40, 10)\n",
    "  plt.rcParams['figure.figsize'] = [columns, rows]\n",
    "\n",
    "  fit_floor = 0.0\n",
    "  fit_ceil = 1.0\n",
    "  gen_floor = 0.0\n",
    "  gen_ceil = float(len(data['epochs']))\n",
    "\n",
    "  plot_fit(data[\"epochs\"], data['averages_all'], data['bests_all'], data['task'])\n",
    "  pop_density_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data['task'])\n",
    "  unique_indivs_heatmap(data[\"indivs_epochs\"], data[\"indivs\"], rows=rows, columns=columns, fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data['task'])\n",
    "  unique_indivs_curve(data[\"indivs_epochs\"], data[\"indivs\"], fit_floor=fit_floor, fit_ceil=fit_ceil, gen_floor=gen_floor, gen_ceil=gen_ceil, task = data['task'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beyond this point is code for archive analysis, this is not refined. Do not use unless necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list = []\n",
    "for i in run_number: \n",
    "    it = 1 \n",
    "    try:\n",
    "        while True:\n",
    "            archive = load_archive(path, i, it)\n",
    "            it += 1\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print(f\"loading archive {it - 1} for run {i}\")\n",
    "        archive = load_archive(path, i, it - 1)\n",
    "        for x in archive:\n",
    "            if 'fitness' in archive[x]:\n",
    "                archive_list.append([x, archive[x], archive[x]['fitness'], i])\n",
    "    except:\n",
    "        print(f\"Run {i} has no archive\")\n",
    "archive_list.sort(key=lambda x : x[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_list\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(archive_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "while it < 10:\n",
    "    print(archive_list[it])\n",
    "    it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def turn_to_expr(phenotype, tree):\n",
    "    if phenotype == \"\":\n",
    "        return tree\n",
    "    \n",
    "    if phenotype[0:9] == \"multiply(\":\n",
    "        #print(\"multiply\")\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"*\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:14] == \"divide_no_nan(\":\n",
    "        phenotype = phenotype[14:]\n",
    "        node = Node(\"/\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"add(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"+\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"pow(\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"^\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"subtract(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 2)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"grad\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"grad\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:4] == \"beta\":\n",
    "        phenotype = phenotype[4:]\n",
    "        node = Node(\"beta\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"alpha\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"alpha\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sigma\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sigma\", tree, 0)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"negative(\":\n",
    "        phenotype = phenotype[9:]\n",
    "        node = Node(\"-\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:5] == \"sqrt(\":\n",
    "        phenotype = phenotype[5:]\n",
    "        node = Node(\"sqrt\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:7] == \"square(\":\n",
    "        phenotype = phenotype[7:]\n",
    "        node = Node(\"square\", tree, 1)\n",
    "        tree.insert(node)\n",
    "        tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:2] == \", \":\n",
    "        phenotype = phenotype[2:]\n",
    "        return turn_to_expr(phenotype, tree)     \n",
    "    elif phenotype[0] == \")\":\n",
    "        phenotype = phenotype[1:]\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    elif phenotype[0:9] == \"constant(\":\n",
    "        if phenotype[9:12] == \"0.0\" or phenotype[9:13] == \"1.0)\" or phenotype[9:13] == \"1.0,\":\n",
    "            node = Node(phenotype[9:12], tree, 0)\n",
    "            phenotype = phenotype[12:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()           \n",
    "        else:\n",
    "            node = Node(phenotype[9:9+14], tree, 0)\n",
    "            phenotype = phenotype[9+14:]\n",
    "            tree.insert(node)\n",
    "            tree = tree.get_next()\n",
    "        return turn_to_expr(phenotype, tree)\n",
    "    else:\n",
    "        raise Exception(phenotype)\n",
    "        \n",
    "def math_phenotype(phenotype):\n",
    "    functions = trim_phenotype(phenotype)\n",
    "    alpha_func_string = functions[1][8:-2]\n",
    "    beta_func_string =functions[2][14:-2] \n",
    "    sigma_func_string =functions[3][21:-2] \n",
    "    grad_func_string = functions[-1][21:]\n",
    "    \n",
    "    for x in [alpha_func_string, beta_func_string, sigma_func_string, grad_func_string]:\n",
    "        print(x)    \n",
    "        turn_to_expr(x, Node(\"\", None, 1)).to_string()\n",
    "\n",
    "    return grad_func_string\n",
    "\n",
    "for indiv in data['indivs']:\n",
    "    math_phenotype(indiv['phenotype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"multiply(\"\n",
    "print(a[0:9])\n",
    "print(a[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import csv\n",
    "from pickle import NONE\n",
    "from utils.data_functions import load_fashion_mnist_training, load_cifar10_training, load_mnist_training, select_fashion_mnist_training\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "from keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from optimizers.custom_optimizer import CustomOptimizer\n",
    "import datetime\n",
    "experiment_time = datetime.datetime.now()\n",
    "\n",
    "cached_dataset = None\n",
    "cached_model = None\n",
    "\n",
    "def train_model_tensorflow_cifar10(phen_params):\n",
    "    phen, params = phen_params\n",
    "    validation_size = params['VALIDATION_SIZE']\n",
    "    fitness_size =params['FITNESS_SIZE'] \n",
    "    batch_size = params['BATCH_SIZE']\n",
    "    epochs = params['EPOCHS']\n",
    "    patience = params['PATIENCE']\n",
    "\n",
    "    # Note that globals are borderline -- consider an object or a closure \n",
    "    # deliberately using globals() to make it ugly...\n",
    "    if globals()['cached_dataset'] == None:\n",
    "        globals()['cached_dataset'] = load_cifar10_training(validation_size=validation_size, test_size=fitness_size)\n",
    "    \n",
    "    if globals()['cached_model'] == None:\n",
    "        globals()['cached_model'] = load_model(params['MODEL'], compile=False)\n",
    "        \n",
    "    # we assume validation and test sets are deterministic\n",
    "    dataset = globals()['cached_dataset'] \n",
    "    model = tf.keras.models.clone_model(globals()['cached_model'])\n",
    "\n",
    "    weights = model.get_weights()\n",
    "    model.set_weights(weights)  \n",
    "\n",
    "    # optimizer is constant aslong as phen doesn't changed?\n",
    "    # -> opportunity to cache opt and compiled model\n",
    "    opt = CustomOptimizer(phen=phen, model=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    early_stop = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=patience, restore_best_weights=True)\n",
    "\n",
    "    score = model.fit(dataset['x_train'], dataset['y_train'],\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=2,\n",
    "        validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "        validation_steps= validation_size // batch_size,\n",
    "        callbacks=[\n",
    "            early_stop\n",
    "        ])\n",
    "\n",
    "    K.clear_session()\n",
    "    results = {}\n",
    "    for metric in score.history:\n",
    "        results[metric] = []\n",
    "        for n in score.history[metric]:\n",
    "            results[metric].append(n)\n",
    "    test_score = model.evaluate(x=dataset['x_test'],y=dataset[\"y_test\"], verbose=0, callbacks=[keras.callbacks.History()])\n",
    "    return test_score[-1], results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "daaf6ac28b1c18339a668ed13dbb2d52ab7f39bbae5e6ab3d06f92e732bf9ed2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
